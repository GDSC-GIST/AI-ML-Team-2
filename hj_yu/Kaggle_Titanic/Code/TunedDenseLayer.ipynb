{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DenseLayer Titanic",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "HR8N2yrEK7kW"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "from matplotlib import pyplot as plt\n",
        "from matplotlib import style\n",
        "\n",
        "from sklearn import linear_model\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import Perceptron\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC, LinearSVC\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "\n",
        "import sys\n",
        "import os\n",
        "import sklearn\n",
        "\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from keras.utils import np_utils\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "데이터 전처리 참고\n",
        "https://towardsdatascience.com/predicting-the-survival-of-titanic-passengers-30870ccc7e8"
      ],
      "metadata": {
        "id": "rF8DZCqOJlHY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = pd.read_csv(\"train.csv\")\n",
        "train_df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bc0fOOPRLEho",
        "outputId": "a006f7d9-0b8c-402e-8670-c5e7ce3efe07"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 891 entries, 0 to 890\n",
            "Data columns (total 12 columns):\n",
            " #   Column       Non-Null Count  Dtype  \n",
            "---  ------       --------------  -----  \n",
            " 0   PassengerId  891 non-null    int64  \n",
            " 1   Survived     891 non-null    int64  \n",
            " 2   Pclass       891 non-null    int64  \n",
            " 3   Name         891 non-null    object \n",
            " 4   Sex          891 non-null    object \n",
            " 5   Age          714 non-null    float64\n",
            " 6   SibSp        891 non-null    int64  \n",
            " 7   Parch        891 non-null    int64  \n",
            " 8   Ticket       891 non-null    object \n",
            " 9   Fare         891 non-null    float64\n",
            " 10  Cabin        204 non-null    object \n",
            " 11  Embarked     889 non-null    object \n",
            "dtypes: float64(2), int64(5), object(5)\n",
            "memory usage: 83.7+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "RE2xzMP2LXXf",
        "outputId": "c95a5968-173b-4bb5-e45d-2b0bceace2e6"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-7be66621-8f43-4389-a746-7c1438c8c6d5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Fare</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>891.000000</td>\n",
              "      <td>891.000000</td>\n",
              "      <td>891.000000</td>\n",
              "      <td>714.000000</td>\n",
              "      <td>891.000000</td>\n",
              "      <td>891.000000</td>\n",
              "      <td>891.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>446.000000</td>\n",
              "      <td>0.383838</td>\n",
              "      <td>2.308642</td>\n",
              "      <td>29.699118</td>\n",
              "      <td>0.523008</td>\n",
              "      <td>0.381594</td>\n",
              "      <td>32.204208</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>257.353842</td>\n",
              "      <td>0.486592</td>\n",
              "      <td>0.836071</td>\n",
              "      <td>14.526497</td>\n",
              "      <td>1.102743</td>\n",
              "      <td>0.806057</td>\n",
              "      <td>49.693429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.420000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>223.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>20.125000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>7.910400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>446.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>28.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>14.454200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>668.500000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>38.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>31.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>891.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>512.329200</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7be66621-8f43-4389-a746-7c1438c8c6d5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7be66621-8f43-4389-a746-7c1438c8c6d5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7be66621-8f43-4389-a746-7c1438c8c6d5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "       PassengerId    Survived      Pclass  ...       SibSp       Parch        Fare\n",
              "count   891.000000  891.000000  891.000000  ...  891.000000  891.000000  891.000000\n",
              "mean    446.000000    0.383838    2.308642  ...    0.523008    0.381594   32.204208\n",
              "std     257.353842    0.486592    0.836071  ...    1.102743    0.806057   49.693429\n",
              "min       1.000000    0.000000    1.000000  ...    0.000000    0.000000    0.000000\n",
              "25%     223.500000    0.000000    2.000000  ...    0.000000    0.000000    7.910400\n",
              "50%     446.000000    0.000000    3.000000  ...    0.000000    0.000000   14.454200\n",
              "75%     668.500000    1.000000    3.000000  ...    1.000000    0.000000   31.000000\n",
              "max     891.000000    1.000000    3.000000  ...    8.000000    6.000000  512.329200\n",
              "\n",
              "[8 rows x 7 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#비어 있는 데이터의 개수, %\n",
        "\n",
        "total = train_df.isnull().sum().sort_values(ascending=False)\n",
        "percent_1 = train_df.isnull().sum()/train_df.isnull().count()*100\n",
        "percent_2 = (round(percent_1, 1)).sort_values(ascending=False)\n",
        "missing_data = pd.concat([total, percent_2], axis = 1, keys = ['total','%'])\n",
        "missing_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        },
        "id": "tjE6lP6eLZcX",
        "outputId": "3cfc4a90-66f7-4f62-886a-b91f5cd634b1"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-d1c1471c-c57a-46f8-83b7-1f59e707cf1c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>total</th>\n",
              "      <th>%</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Cabin</th>\n",
              "      <td>687</td>\n",
              "      <td>77.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Age</th>\n",
              "      <td>177</td>\n",
              "      <td>19.9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Embarked</th>\n",
              "      <td>2</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Fare</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Ticket</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Parch</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SibSp</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Sex</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Name</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Pclass</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Survived</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PassengerId</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d1c1471c-c57a-46f8-83b7-1f59e707cf1c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d1c1471c-c57a-46f8-83b7-1f59e707cf1c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d1c1471c-c57a-46f8-83b7-1f59e707cf1c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "             total     %\n",
              "Cabin          687  77.1\n",
              "Age            177  19.9\n",
              "Embarked         2   0.2\n",
              "Fare             0   0.0\n",
              "Ticket           0   0.0\n",
              "Parch            0   0.0\n",
              "SibSp            0   0.0\n",
              "Sex              0   0.0\n",
              "Name             0   0.0\n",
              "Pclass           0   0.0\n",
              "Survived         0   0.0\n",
              "PassengerId      0   0.0"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.columns.values"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "enacBglTLbTt",
        "outputId": "8c13ef80-f7d0-4d71-b25f-e407ec5a5449"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',\n",
              "       'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# condition문을 이렇게 작성할 수 있음! 데이터프레임 반환\n",
        "\n",
        "women = train_df[train_df['Sex'] == 'female']\n",
        "women"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "W_tz75hoLdY2",
        "outputId": "5b277f70-6a0a-4dc3-96ba-1c1161732582"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-7c579861-f26e-4fdd-a63b-eb660e986787\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Name</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Ticket</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Cabin</th>\n",
              "      <th>Embarked</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
              "      <td>female</td>\n",
              "      <td>38.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>PC 17599</td>\n",
              "      <td>71.2833</td>\n",
              "      <td>C85</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>Heikkinen, Miss. Laina</td>\n",
              "      <td>female</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>STON/O2. 3101282</td>\n",
              "      <td>7.9250</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
              "      <td>female</td>\n",
              "      <td>35.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>113803</td>\n",
              "      <td>53.1000</td>\n",
              "      <td>C123</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)</td>\n",
              "      <td>female</td>\n",
              "      <td>27.0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>347742</td>\n",
              "      <td>11.1333</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>Nasser, Mrs. Nicholas (Adele Achem)</td>\n",
              "      <td>female</td>\n",
              "      <td>14.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>237736</td>\n",
              "      <td>30.0708</td>\n",
              "      <td>NaN</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>880</th>\n",
              "      <td>881</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>Shelley, Mrs. William (Imanita Parrish Hall)</td>\n",
              "      <td>female</td>\n",
              "      <td>25.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>230433</td>\n",
              "      <td>26.0000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>882</th>\n",
              "      <td>883</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Dahlberg, Miss. Gerda Ulrika</td>\n",
              "      <td>female</td>\n",
              "      <td>22.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7552</td>\n",
              "      <td>10.5167</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>885</th>\n",
              "      <td>886</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Rice, Mrs. William (Margaret Norton)</td>\n",
              "      <td>female</td>\n",
              "      <td>39.0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>382652</td>\n",
              "      <td>29.1250</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Q</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>887</th>\n",
              "      <td>888</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Graham, Miss. Margaret Edith</td>\n",
              "      <td>female</td>\n",
              "      <td>19.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>112053</td>\n",
              "      <td>30.0000</td>\n",
              "      <td>B42</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>888</th>\n",
              "      <td>889</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Johnston, Miss. Catherine Helen \"Carrie\"</td>\n",
              "      <td>female</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>W./C. 6607</td>\n",
              "      <td>23.4500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>314 rows × 12 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7c579861-f26e-4fdd-a63b-eb660e986787')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7c579861-f26e-4fdd-a63b-eb660e986787 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7c579861-f26e-4fdd-a63b-eb660e986787');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "     PassengerId  Survived  Pclass  ...     Fare Cabin  Embarked\n",
              "1              2         1       1  ...  71.2833   C85         C\n",
              "2              3         1       3  ...   7.9250   NaN         S\n",
              "3              4         1       1  ...  53.1000  C123         S\n",
              "8              9         1       3  ...  11.1333   NaN         S\n",
              "9             10         1       2  ...  30.0708   NaN         C\n",
              "..           ...       ...     ...  ...      ...   ...       ...\n",
              "880          881         1       2  ...  26.0000   NaN         S\n",
              "882          883         0       3  ...  10.5167   NaN         S\n",
              "885          886         0       3  ...  29.1250   NaN         Q\n",
              "887          888         1       1  ...  30.0000   B42         S\n",
              "888          889         0       3  ...  23.4500   NaN         S\n",
              "\n",
              "[314 rows x 12 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "survived = 'survived'\n",
        "not_survived = 'not survived'\n",
        "fig, axes = plt.subplots(nrows=1, ncols=2,figsize=(10, 4))\n",
        "\n",
        "# 여자 & 생존 / 여자 & 사망인원수를 체크하기 위해 2중 condition문으로 작성\n",
        "\n",
        "women = train_df[train_df['Sex']=='female']\n",
        "men = train_df[train_df['Sex']=='male']\n",
        "ax = sns.distplot(women[women['Survived']==1].Age.dropna(), bins=18, label = survived, ax = axes[0], kde =False)\n",
        "ax = sns.distplot(women[women['Survived']==0].Age.dropna(), bins=40, label = not_survived, ax = axes[0], kde =False)\n",
        "ax.legend()\n",
        "ax.set_title('Female')\n",
        "ax = sns.distplot(men[men['Survived']==1].Age.dropna(), bins=18, label = survived, ax = axes[1], kde = False)\n",
        "ax = sns.distplot(men[men['Survived']==0].Age.dropna(), bins=40, label = not_survived, ax = axes[1], kde = False)\n",
        "ax.legend()\n",
        "_ = ax.set_title('Male')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 460
        },
        "id": "b2LFwMHvL1dW",
        "outputId": "318b81ce-aada-4e01-b845-e5d8b062f5cc"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
            "  warnings.warn(msg, FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
            "  warnings.warn(msg, FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
            "  warnings.warn(msg, FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#embarked 기준으로 FacetGrid만 만들면 이렇게 됨\n",
        "\n",
        "FacetGrid = sns.FacetGrid(train_df, row='Embarked', size=4.5, aspect=1.6)\n",
        "FacetGrid.add_legend()\n",
        "FacetGrid"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "p26q_P8WMA5Y",
        "outputId": "34c75f4b-584c-42f7-a009-818b3d3c09a7"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seaborn/axisgrid.py:337: UserWarning: The `size` parameter has been renamed to `height`; please update your code.\n",
            "  warnings.warn(msg, UserWarning)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<seaborn.axisgrid.FacetGrid at 0x7fb58a57d710>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 526.4x972 with 3 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "FacetGrid = sns.FacetGrid(train_df, row='Embarked', size=4.5, aspect=1.6)\n",
        "FacetGrid.map(sns.pointplot, 'Pclass', 'Survived', 'Sex', palette=None,  order=None, hue_order=None )\n",
        "FacetGrid.add_legend()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "kFB0FEr_MdpO",
        "outputId": "f8be72f1-7482-4820-f9fd-428205858ef9"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seaborn/axisgrid.py:337: UserWarning: The `size` parameter has been renamed to `height`; please update your code.\n",
            "  warnings.warn(msg, UserWarning)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<seaborn.axisgrid.FacetGrid at 0x7fb580506690>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 588.9x972 with 3 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sns.barplot(x='Pclass', y='Survived', data=train_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "VAeoOJLbMnR2",
        "outputId": "c7152e1f-e8b8-4b17-c5de-4a49910728bf"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fb58051f790>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 두 가지 기준으로 FacetGrid 만들수도 있음!\n",
        "\n",
        "grid = sns.FacetGrid(train_df, col='Survived', row='Pclass', size=2.2, aspect=1.6)\n",
        "grid.map(plt.hist, 'Age', alpha=.5, bins=20)\n",
        "grid.add_legend();"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 522
        },
        "id": "dQeMYu-4NBnT",
        "outputId": "c578ab2a-13a7-4f35-a2da-621b739869c9"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seaborn/axisgrid.py:337: UserWarning: The `size` parameter has been renamed to `height`; please update your code.\n",
            "  warnings.warn(msg, UserWarning)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 514.88x475.2 with 6 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_df = pd.read_csv(\"test.csv\")"
      ],
      "metadata": {
        "id": "L3E6KXmrNEav"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = [train_df, test_df]\n",
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZxlJNkeENweg",
        "outputId": "a71e84cc-de99-4bf6-a6b0-81635d25c506"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[     PassengerId  Survived  Pclass  ...     Fare Cabin  Embarked\n",
              " 0              1         0       3  ...   7.2500   NaN         S\n",
              " 1              2         1       1  ...  71.2833   C85         C\n",
              " 2              3         1       3  ...   7.9250   NaN         S\n",
              " 3              4         1       1  ...  53.1000  C123         S\n",
              " 4              5         0       3  ...   8.0500   NaN         S\n",
              " ..           ...       ...     ...  ...      ...   ...       ...\n",
              " 886          887         0       2  ...  13.0000   NaN         S\n",
              " 887          888         1       1  ...  30.0000   B42         S\n",
              " 888          889         0       3  ...  23.4500   NaN         S\n",
              " 889          890         1       1  ...  30.0000  C148         C\n",
              " 890          891         0       3  ...   7.7500   NaN         Q\n",
              " \n",
              " [891 rows x 12 columns],      PassengerId  Pclass  ... Cabin Embarked\n",
              " 0            892       3  ...   NaN        Q\n",
              " 1            893       3  ...   NaN        S\n",
              " 2            894       2  ...   NaN        Q\n",
              " 3            895       3  ...   NaN        S\n",
              " 4            896       3  ...   NaN        S\n",
              " ..           ...     ...  ...   ...      ...\n",
              " 413         1305       3  ...   NaN        S\n",
              " 414         1306       1  ...  C105        C\n",
              " 415         1307       3  ...   NaN        S\n",
              " 416         1308       3  ...   NaN        S\n",
              " 417         1309       3  ...   NaN        C\n",
              " \n",
              " [418 rows x 11 columns]]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#데이터프레임에 새로운 열 추가하기 -> df['추가할 열 이름'] = 데이터(배열, 이미 있는 열 등등)\n",
        "\n",
        "train_df['relatives'] = train_df['SibSp'] + train_df['Parch']\n",
        "train_df.drop(['relatives'], axis = 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "DX8DNz9MN2nV",
        "outputId": "3b1a9260-4ea8-4d66-c603-9d64dd73f757"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-0722c855-bcd5-4651-81d7-3bddd23611e6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Name</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Ticket</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Cabin</th>\n",
              "      <th>Embarked</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Braund, Mr. Owen Harris</td>\n",
              "      <td>male</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>A/5 21171</td>\n",
              "      <td>7.2500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
              "      <td>female</td>\n",
              "      <td>38.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>PC 17599</td>\n",
              "      <td>71.2833</td>\n",
              "      <td>C85</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>Heikkinen, Miss. Laina</td>\n",
              "      <td>female</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>STON/O2. 3101282</td>\n",
              "      <td>7.9250</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
              "      <td>female</td>\n",
              "      <td>35.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>113803</td>\n",
              "      <td>53.1000</td>\n",
              "      <td>C123</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Allen, Mr. William Henry</td>\n",
              "      <td>male</td>\n",
              "      <td>35.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>373450</td>\n",
              "      <td>8.0500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>886</th>\n",
              "      <td>887</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>Montvila, Rev. Juozas</td>\n",
              "      <td>male</td>\n",
              "      <td>27.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>211536</td>\n",
              "      <td>13.0000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>887</th>\n",
              "      <td>888</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Graham, Miss. Margaret Edith</td>\n",
              "      <td>female</td>\n",
              "      <td>19.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>112053</td>\n",
              "      <td>30.0000</td>\n",
              "      <td>B42</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>888</th>\n",
              "      <td>889</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Johnston, Miss. Catherine Helen \"Carrie\"</td>\n",
              "      <td>female</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>W./C. 6607</td>\n",
              "      <td>23.4500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>889</th>\n",
              "      <td>890</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Behr, Mr. Karl Howell</td>\n",
              "      <td>male</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>111369</td>\n",
              "      <td>30.0000</td>\n",
              "      <td>C148</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>890</th>\n",
              "      <td>891</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Dooley, Mr. Patrick</td>\n",
              "      <td>male</td>\n",
              "      <td>32.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>370376</td>\n",
              "      <td>7.7500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Q</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>891 rows × 12 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0722c855-bcd5-4651-81d7-3bddd23611e6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0722c855-bcd5-4651-81d7-3bddd23611e6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0722c855-bcd5-4651-81d7-3bddd23611e6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "     PassengerId  Survived  Pclass  ...     Fare Cabin  Embarked\n",
              "0              1         0       3  ...   7.2500   NaN         S\n",
              "1              2         1       1  ...  71.2833   C85         C\n",
              "2              3         1       3  ...   7.9250   NaN         S\n",
              "3              4         1       1  ...  53.1000  C123         S\n",
              "4              5         0       3  ...   8.0500   NaN         S\n",
              "..           ...       ...     ...  ...      ...   ...       ...\n",
              "886          887         0       2  ...  13.0000   NaN         S\n",
              "887          888         1       1  ...  30.0000   B42         S\n",
              "888          889         0       3  ...  23.4500   NaN         S\n",
              "889          890         1       1  ...  30.0000  C148         C\n",
              "890          891         0       3  ...   7.7500   NaN         Q\n",
              "\n",
              "[891 rows x 12 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# for dataset in data:\n",
        "# data라는 리스트에 있는 1번째 데이터프레임, 2번째 데이터프레임에 각각 아래 구문을 실행!\n",
        "# for i in list와 같음\n",
        "\n",
        "for dataset in data:\n",
        "  dataset['relatives'] = dataset['SibSp'] + dataset['Parch']\n",
        "  dataset.loc[dataset['relatives'] > 0, 'not_alone'] = 0\n",
        "  dataset.loc[dataset['relatives'] == 0, 'not_alone'] = 1\n",
        "  dataset['not_alone'] = dataset['not_alone'].astype(int)\n",
        "\n",
        "train_df['not_alone'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k5_wPsxHN5nZ",
        "outputId": "81ac07c6-f5bf-49c8-e85d-6c37979b72af"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    537\n",
              "0    354\n",
              "Name: not_alone, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "axes = sns.factorplot('relatives','Survived', \n",
        "                      data=train_df, aspect = 2.5, )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        },
        "id": "2m2lvVUcOdfQ",
        "outputId": "5466a511-ebed-4a2e-c998-766ede4b4e11"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seaborn/categorical.py:3717: UserWarning: The `factorplot` function has been renamed to `catplot`. The original name will be removed in a future release. Please update your code. Note that the default `kind` in `factorplot` (`'point'`) has changed `'strip'` in `catplot`.\n",
            "  warnings.warn(msg)\n",
            "/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  FutureWarning\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 900x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = train_df.drop(['PassengerId'], axis = 1)"
      ],
      "metadata": {
        "id": "rMcRQSv5Pbyi"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#??\n",
        "\n",
        "import re\n",
        "deck = {\"A\": 1, \"B\": 2, \"C\": 3, \"D\": 4, \"E\": 5, \"F\": 6, \"G\": 7, \"U\": 8}\n",
        "data = [train_df, test_df]\n",
        "\n",
        "for dataset in data:\n",
        "    dataset['Cabin'] = dataset['Cabin'].fillna(\"U0\")\n",
        "    dataset['Deck'] = dataset['Cabin'].map(lambda x: re.compile(\"([a-zA-Z]+)\").search(x).group())\n",
        "    dataset['Deck'] = dataset['Deck'].map(deck)\n",
        "    dataset['Deck'] = dataset['Deck'].fillna(0)\n",
        "    dataset['Deck'] = dataset['Deck'].astype(int)\n",
        "# we can now drop the cabin feature\n",
        "train_df = train_df.drop(['Cabin'], axis=1)\n",
        "test_df = test_df.drop(['Cabin'], axis=1)"
      ],
      "metadata": {
        "id": "zpxXfvVQPkqW"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random_list = np.random.randint(1, 100, size = 10)\n",
        "random_list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uYTh0ru3SmeS",
        "outputId": "14cc117c-40c2-4899-ea39-d183992d6827"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([35, 83, 68, 80, 38, 94, 71, 78, 14, 19])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Pclass_slice = train_df['Pclass'].copy()\n",
        "Pclass_slice"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "26AwZ4ybSs8o",
        "outputId": "c96aec28-fe9a-41fa-9f51-c4de4ca4bb64"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      3\n",
              "1      1\n",
              "2      3\n",
              "3      1\n",
              "4      3\n",
              "      ..\n",
              "886    2\n",
              "887    1\n",
              "888    3\n",
              "889    1\n",
              "890    3\n",
              "Name: Pclass, Length: 891, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#데이터프레임에서 열 한 개의 값을 리스트의 값으로 바꾸고 싶을 때!\n",
        "#slice[] 대괄호 내부에는 인덱스 값 넣어야 함!\n",
        "\n",
        "Pclass_slice[0:10] = random_list\n",
        "Pclass_slice"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NENu9R1zS0Ww",
        "outputId": "c10da357-f40f-4b8d-86cc-a0883320094f"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      35\n",
              "1      83\n",
              "2      68\n",
              "3      80\n",
              "4      38\n",
              "       ..\n",
              "886     2\n",
              "887     1\n",
              "888     3\n",
              "889     1\n",
              "890     3\n",
              "Name: Pclass, Length: 891, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df['Embarked'].describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BlRkD5rCP3VW",
        "outputId": "ac85ab2f-b20b-4686-e1cf-97fb47dd04fa"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count     889\n",
              "unique      3\n",
              "top         S\n",
              "freq      644\n",
              "Name: Embarked, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "common_value = 'S'\n",
        "data = [train_df, test_df]\n",
        "\n",
        "for dataset in data:\n",
        "    dataset['Embarked'] = dataset['Embarked'].fillna(common_value)"
      ],
      "metadata": {
        "id": "kE9ejhD3Qk8m"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w__hwVlfQrXv",
        "outputId": "8892de93-862d-4c6b-db30-911ed9c20840"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 891 entries, 0 to 890\n",
            "Data columns (total 13 columns):\n",
            " #   Column     Non-Null Count  Dtype  \n",
            "---  ------     --------------  -----  \n",
            " 0   Survived   891 non-null    int64  \n",
            " 1   Pclass     891 non-null    int64  \n",
            " 2   Name       891 non-null    object \n",
            " 3   Sex        891 non-null    object \n",
            " 4   Age        714 non-null    float64\n",
            " 5   SibSp      891 non-null    int64  \n",
            " 6   Parch      891 non-null    int64  \n",
            " 7   Ticket     891 non-null    object \n",
            " 8   Fare       891 non-null    float64\n",
            " 9   Embarked   891 non-null    object \n",
            " 10  relatives  891 non-null    int64  \n",
            " 11  not_alone  891 non-null    int64  \n",
            " 12  Deck       891 non-null    int64  \n",
            "dtypes: float64(2), int64(7), object(4)\n",
            "memory usage: 90.6+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = [train_df, test_df]\n",
        "\n",
        "for dataset in data:\n",
        "    dataset['Fare'] = dataset['Fare'].fillna(0)\n",
        "    dataset['Fare'] = dataset['Fare'].astype(int)"
      ],
      "metadata": {
        "id": "M3stBbo-UN_e"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = [train_df, test_df]\n",
        "titles = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rare\": 5}\n",
        "\n",
        "for dataset in data:\n",
        "    # extract titles\n",
        "    dataset['Title'] = dataset.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)\n",
        "    # replace titles with a more common title or as Rare\n",
        "    dataset['Title'] = dataset['Title'].replace(['Lady', 'Countess','Capt', 'Col','Don', 'Dr',\\\n",
        "                                            'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n",
        "    dataset['Title'] = dataset['Title'].replace('Mlle', 'Miss')\n",
        "    dataset['Title'] = dataset['Title'].replace('Ms', 'Miss')\n",
        "    dataset['Title'] = dataset['Title'].replace('Mme', 'Mrs')\n",
        "    # convert titles into numbers\n",
        "    # 데이터프레임 열에 .map(dict형) 사용해서 텍스트 -> 숫자로 변환하기!\n",
        "    dataset['Title'] = dataset['Title'].map(titles)\n",
        "    # filling NaN with 0, to get safe\n",
        "    dataset['Title'] = dataset['Title'].fillna(0)\n",
        "\n",
        "train_df = train_df.drop(['Name'], axis=1)\n",
        "test_df = test_df.drop(['Name'], axis=1)"
      ],
      "metadata": {
        "id": "1-_rb5cNUWS-"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "genders = {'male':0, 'female':1}\n",
        "data = [train_df, test_df]\n",
        "\n",
        "for dataset in data:\n",
        "  dataset['Sex'] = dataset['Sex'].map(genders)"
      ],
      "metadata": {
        "id": "kkwo1A9cV_y-"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df['Ticket'].describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ijI7Q3UWNp2",
        "outputId": "cda39746-d0d3-4bd7-acd9-497162f6392e"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count          891\n",
              "unique         681\n",
              "top       CA. 2343\n",
              "freq             7\n",
              "Name: Ticket, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = train_df.drop(['Ticket'], axis=1)\n",
        "test_df = test_df.drop(['Ticket'], axis=1)"
      ],
      "metadata": {
        "id": "Uw8_K9WUWR1-"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embark = {'S':0, 'C':1, 'Q':2}\n",
        "data = [train_df, test_df]\n",
        "\n",
        "for dataset in data:\n",
        "  dataset['Embarked'] = dataset['Embarked'].map(embark)\n",
        "\n",
        "train_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "ODgVhcB3WT8_",
        "outputId": "c9906f49-ba35-4fd1-f83a-5d27af3ed252"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-d9bf6cae-4075-4b9c-8a75-f48ff7fdcd74\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Embarked</th>\n",
              "      <th>relatives</th>\n",
              "      <th>not_alone</th>\n",
              "      <th>Deck</th>\n",
              "      <th>Title</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>38.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>71</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>35.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>53</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>886</th>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>13</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>887</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>19.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>30</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>888</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>23</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>889</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>30</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>890</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>32.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>891 rows × 12 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d9bf6cae-4075-4b9c-8a75-f48ff7fdcd74')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d9bf6cae-4075-4b9c-8a75-f48ff7fdcd74 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d9bf6cae-4075-4b9c-8a75-f48ff7fdcd74');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "     Survived  Pclass  Sex   Age  ...  relatives  not_alone  Deck  Title\n",
              "0           0       3    0  22.0  ...          1          0     8      1\n",
              "1           1       1    1  38.0  ...          1          0     3      3\n",
              "2           1       3    1  26.0  ...          0          1     8      2\n",
              "3           1       1    1  35.0  ...          1          0     3      3\n",
              "4           0       3    0  35.0  ...          0          1     8      1\n",
              "..        ...     ...  ...   ...  ...        ...        ...   ...    ...\n",
              "886         0       2    0  27.0  ...          0          1     8      5\n",
              "887         1       1    1  19.0  ...          0          1     2      2\n",
              "888         0       3    1   NaN  ...          3          0     8      2\n",
              "889         1       1    0  26.0  ...          0          1     3      1\n",
              "890         0       3    0  32.0  ...          0          1     8      1\n",
              "\n",
              "[891 rows x 12 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Age변수 비어있는 칸 채우기!\n",
        "#이 블럭에서는 Age제외한 데이터프레임 만듦\n",
        "\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "# train\n",
        "impute_train = train_df[train_df.Age.isnull()].drop(['Age'], axis=1)\n",
        "impute_train.describe()\n",
        "# test\n",
        "impute_test = test_df[test_df.Age.isnull()].drop(['Age'], axis=1)\n",
        "impute_test.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "znNT--whWemu",
        "outputId": "5f043ef7-12c6-470c-e2f6-d4fc7467c0ba"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-149c0128-ce3b-4213-a2dd-8ddc20b143ca\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Sex</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Embarked</th>\n",
              "      <th>relatives</th>\n",
              "      <th>not_alone</th>\n",
              "      <th>Deck</th>\n",
              "      <th>Title</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>86.000000</td>\n",
              "      <td>86.000000</td>\n",
              "      <td>86.000000</td>\n",
              "      <td>86.000000</td>\n",
              "      <td>86.000000</td>\n",
              "      <td>86.000000</td>\n",
              "      <td>86.000000</td>\n",
              "      <td>86.000000</td>\n",
              "      <td>86.000000</td>\n",
              "      <td>86.000000</td>\n",
              "      <td>86.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>1102.186047</td>\n",
              "      <td>2.732558</td>\n",
              "      <td>0.290698</td>\n",
              "      <td>0.313953</td>\n",
              "      <td>0.372093</td>\n",
              "      <td>14.511628</td>\n",
              "      <td>0.790698</td>\n",
              "      <td>0.686047</td>\n",
              "      <td>0.779070</td>\n",
              "      <td>7.848837</td>\n",
              "      <td>1.546512</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>113.626997</td>\n",
              "      <td>0.640302</td>\n",
              "      <td>0.456748</td>\n",
              "      <td>0.973310</td>\n",
              "      <td>1.471666</td>\n",
              "      <td>14.171010</td>\n",
              "      <td>0.855656</td>\n",
              "      <td>1.953950</td>\n",
              "      <td>0.417307</td>\n",
              "      <td>0.711543</td>\n",
              "      <td>0.876584</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>902.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>1004.250000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>1105.500000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>7.500000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>1181.750000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>2.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1309.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>69.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>4.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-149c0128-ce3b-4213-a2dd-8ddc20b143ca')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-149c0128-ce3b-4213-a2dd-8ddc20b143ca button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-149c0128-ce3b-4213-a2dd-8ddc20b143ca');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "       PassengerId     Pclass        Sex  ...  not_alone       Deck      Title\n",
              "count    86.000000  86.000000  86.000000  ...  86.000000  86.000000  86.000000\n",
              "mean   1102.186047   2.732558   0.290698  ...   0.779070   7.848837   1.546512\n",
              "std     113.626997   0.640302   0.456748  ...   0.417307   0.711543   0.876584\n",
              "min     902.000000   1.000000   0.000000  ...   0.000000   4.000000   1.000000\n",
              "25%    1004.250000   3.000000   0.000000  ...   1.000000   8.000000   1.000000\n",
              "50%    1105.500000   3.000000   0.000000  ...   1.000000   8.000000   1.000000\n",
              "75%    1181.750000   3.000000   1.000000  ...   1.000000   8.000000   2.000000\n",
              "max    1309.000000   3.000000   1.000000  ...   1.000000   8.000000   4.000000\n",
              "\n",
              "[8 rows x 11 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Age를 제외한 나머지 특징들을 이용해서 KNN-Regressor으로 나이를 예측함\n",
        "\n",
        "# train\n",
        "knr = KNeighborsRegressor()\n",
        "titanic_knn_train = train_df[train_df.Age.notnull()]\n",
        "X_train = titanic_knn_train.drop(['Age'], axis = 1)\n",
        "y_train = titanic_knn_train.Age\n",
        "knr.fit(X_train, y_train)\n",
        "imputed_train_ages = knr.predict(impute_train)\n",
        "imputed_train_ages\n",
        "# test\n",
        "knr = KNeighborsRegressor()\n",
        "titanic_knn_test = test_df[test_df.Age.notnull()]\n",
        "X_test = titanic_knn_test.drop(['Age'], axis = 1)\n",
        "y_test = titanic_knn_test.Age\n",
        "X_test.isnull().sum()\n",
        "knr.fit(X_test, y_test)\n",
        "imputed_test_ages = knr.predict(impute_test)\n",
        "imputed_test_ages"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0cQiAq8tWzDe",
        "outputId": "ce016431-08fc-44e4-ec6e-3cdf3590aa8e"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([22.   , 40.4  , 39.6  , 39.6  , 28.9  , 28.4  , 34.4  , 31.6  ,\n",
              "       31.   , 27.2  , 33.3  , 25.6  , 21.   , 24.2  , 20.6  , 23.2  ,\n",
              "       24.2  , 25.   , 23.2  , 20.   , 20.   , 23.   , 19.7  , 20.9  ,\n",
              "       29.6  , 30.6  , 33.8  , 29.9  , 29.2  , 34.6  , 33.1  , 28.   ,\n",
              "       27.2  , 29.2  , 27.8  , 28.6  , 37.6  , 38.   , 22.2  , 19.866,\n",
              "       25.466, 26.666, 29.4  , 23.8  , 23.4  , 29.9  , 21.6  , 24.   ,\n",
              "       20.4  , 30.384, 23.5  , 25.1  , 25.1  , 18.   , 23.4  , 18.   ,\n",
              "       19.4  , 24.   , 19.55 , 18.15 , 21.95 , 29.4  , 30.2  , 30.2  ,\n",
              "       18.6  , 31.4  , 38.   , 34.6  , 20.766, 22.6  , 28.4  , 26.4  ,\n",
              "       34.5  , 24.4  , 28.8  , 28.8  , 30.3  , 30.2  , 22.8  , 29.4  ,\n",
              "       29.4  , 22.5  , 22.5  , 22.5  , 22.5  , 26.5  ])"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "imputed_train_ages"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NnVqZJ1DXBJ2",
        "outputId": "d53f7f32-8dd3-4fb1-ca76-cc591ef76123"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([39.8  , 31.6  , 19.   , 30.5  , 17.6  , 34.2  , 28.784, 17.6  ,\n",
              "       25.6  , 30.5  , 36.5  , 27.9  , 17.6  , 26.   , 50.4  , 50.2  ,\n",
              "       14.734, 34.2  , 36.5  , 17.6  , 36.5  , 36.5  , 34.2  , 31.   ,\n",
              "       22.   , 36.5  , 44.4  , 19.   , 23.2  , 34.2  , 36.5  , 29.8  ,\n",
              "       34.8  , 52.6  , 15.4  , 29.8  , 27.7  , 36.2  , 26.1  , 44.4  ,\n",
              "       17.6  , 29.8  , 39.3  , 34.2  , 17.8  , 28.6  , 26.5  , 18.9  ,\n",
              "       34.2  , 32.6  , 44.4  , 20.9  , 24.1  , 17.6  , 33.4  , 44.7  ,\n",
              "       50.2  , 37.4  , 17.6  , 24.4  , 30.3  , 36.5  , 28.   , 29.8  ,\n",
              "       23.2  , 37.6  , 34.2  , 21.6  , 50.4  , 30.5  , 17.6  , 17.6  ,\n",
              "       27.9  , 19.   , 17.6  , 30.   , 34.2  , 44.4  , 17.8  , 34.2  ,\n",
              "       42.   , 33.4  , 26.6  , 30.5  , 34.2  , 44.4  , 21.6  , 25.   ,\n",
              "       21.6  , 36.5  , 42.   , 44.4  , 36.5  , 33.4  , 44.4  , 34.2  ,\n",
              "       38.8  , 33.4  , 17.8  , 21.6  , 21.4  , 27.7  , 20.9  , 52.2  ,\n",
              "       36.5  , 35.6  , 30.5  , 30.5  , 28.4  , 30.5  , 20.2  , 25.   ,\n",
              "       31.6  , 44.4  , 30.8  , 44.4  , 36.5  , 24.   , 30.5  , 17.6  ,\n",
              "       27.9  , 37.3  , 36.5  , 24.5  , 22.2  , 30.5  , 34.2  , 30.   ,\n",
              "       34.2  , 18.9  , 44.4  , 44.4  , 33.4  , 28.6  , 29.6  , 34.2  ,\n",
              "       34.2  , 17.6  , 34.2  , 34.2  , 43.2  , 33.4  , 20.3  , 29.6  ,\n",
              "       17.6  , 14.734, 48.6  , 22.4  , 17.6  , 33.4  , 34.2  , 34.2  ,\n",
              "       43.3  , 25.   , 22.   , 31.4  , 30.5  , 40.1  , 44.4  , 15.6  ,\n",
              "       44.4  , 29.8  , 25.7  , 33.4  , 42.   , 33.6  , 42.9  , 30.5  ,\n",
              "       36.5  , 46.9  , 29.8  , 34.8  , 30.5  , 29.8  , 20.8  , 34.2  ,\n",
              "       20.4  ])"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "DS93BD4RaSXH",
        "outputId": "ad4c7606-0045-4f2e-c537-61bc45b4c9c4"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-a0800ee9-65db-49e0-b342-4f0f1d61b6da\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Embarked</th>\n",
              "      <th>relatives</th>\n",
              "      <th>not_alone</th>\n",
              "      <th>Deck</th>\n",
              "      <th>Title</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>38.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>71</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>35.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>53</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>886</th>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>13</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>887</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>19.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>30</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>888</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>23</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>889</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>30</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>890</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>32.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>891 rows × 12 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a0800ee9-65db-49e0-b342-4f0f1d61b6da')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a0800ee9-65db-49e0-b342-4f0f1d61b6da button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a0800ee9-65db-49e0-b342-4f0f1d61b6da');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "     Survived  Pclass  Sex   Age  ...  relatives  not_alone  Deck  Title\n",
              "0           0       3    0  22.0  ...          1          0     8      1\n",
              "1           1       1    1  38.0  ...          1          0     3      3\n",
              "2           1       3    1  26.0  ...          0          1     8      2\n",
              "3           1       1    1  35.0  ...          1          0     3      3\n",
              "4           0       3    0  35.0  ...          0          1     8      1\n",
              "..        ...     ...  ...   ...  ...        ...        ...   ...    ...\n",
              "886         0       2    0  27.0  ...          0          1     8      5\n",
              "887         1       1    1  19.0  ...          0          1     2      2\n",
              "888         0       3    1   NaN  ...          3          0     8      2\n",
              "889         1       1    0  26.0  ...          0          1     3      1\n",
              "890         0       3    0  32.0  ...          0          1     8      1\n",
              "\n",
              "[891 rows x 12 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Age중에서 nan인 인덱스에만 우리가 예측한 나이 값 리스트를 대입함!\n",
        "\n",
        "age_slice = train_df['Age'].copy()\n",
        "age_slice[np.isnan(age_slice)] = imputed_train_ages\n",
        "train_df['Age'] = age_slice\n",
        "train_df['Age'] = train_df['Age'].astype(int)\n",
        "\n",
        "age_slice2 = test_df['Age'].copy()\n",
        "age_slice2[np.isnan(age_slice2)] = imputed_test_ages\n",
        "test_df['Age'] = age_slice2\n",
        "test_df['Age'] = test_df['Age'].astype(int)\n",
        "\n",
        "\n",
        "train_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "pmjZ8pMsYjHP",
        "outputId": "142f6392-c71d-4c6c-9755-3348fdfca3a4"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-a3ddf857-3f96-405e-8f39-5c83774c594e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Embarked</th>\n",
              "      <th>relatives</th>\n",
              "      <th>not_alone</th>\n",
              "      <th>Deck</th>\n",
              "      <th>Title</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>22</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>38</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>71</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>26</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>35</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>53</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>35</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>886</th>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>27</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>13</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>887</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>19</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>30</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>888</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>20</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>23</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>889</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>26</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>30</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>890</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>32</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>891 rows × 12 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a3ddf857-3f96-405e-8f39-5c83774c594e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a3ddf857-3f96-405e-8f39-5c83774c594e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a3ddf857-3f96-405e-8f39-5c83774c594e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "     Survived  Pclass  Sex  Age  ...  relatives  not_alone  Deck  Title\n",
              "0           0       3    0   22  ...          1          0     8      1\n",
              "1           1       1    1   38  ...          1          0     3      3\n",
              "2           1       3    1   26  ...          0          1     8      2\n",
              "3           1       1    1   35  ...          1          0     3      3\n",
              "4           0       3    0   35  ...          0          1     8      1\n",
              "..        ...     ...  ...  ...  ...        ...        ...   ...    ...\n",
              "886         0       2    0   27  ...          0          1     8      5\n",
              "887         1       1    1   19  ...          0          1     2      2\n",
              "888         0       3    1   20  ...          3          0     8      2\n",
              "889         1       1    0   26  ...          0          1     3      1\n",
              "890         0       3    0   32  ...          0          1     8      1\n",
              "\n",
              "[891 rows x 12 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t4sSeksgaH29",
        "outputId": "298a3dd3-4a16-4556-9af8-0dc398e1cf0f"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 891 entries, 0 to 890\n",
            "Data columns (total 12 columns):\n",
            " #   Column     Non-Null Count  Dtype\n",
            "---  ------     --------------  -----\n",
            " 0   Survived   891 non-null    int64\n",
            " 1   Pclass     891 non-null    int64\n",
            " 2   Sex        891 non-null    int64\n",
            " 3   Age        891 non-null    int64\n",
            " 4   SibSp      891 non-null    int64\n",
            " 5   Parch      891 non-null    int64\n",
            " 6   Fare       891 non-null    int64\n",
            " 7   Embarked   891 non-null    int64\n",
            " 8   relatives  891 non-null    int64\n",
            " 9   not_alone  891 non-null    int64\n",
            " 10  Deck       891 non-null    int64\n",
            " 11  Title      891 non-null    int64\n",
            "dtypes: int64(12)\n",
            "memory usage: 83.7 KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Categorization\n",
        "\n",
        "data = [train_df, test_df]\n",
        "for dataset in data:\n",
        "    dataset['Age'] = dataset['Age'].astype(int)\n",
        "    dataset.loc[ dataset['Age'] <= 11, 'Age'] = 0\n",
        "    dataset.loc[(dataset['Age'] > 11) & (dataset['Age'] <= 18), 'Age'] = 1\n",
        "    dataset.loc[(dataset['Age'] > 18) & (dataset['Age'] <= 22), 'Age'] = 2\n",
        "    dataset.loc[(dataset['Age'] > 22) & (dataset['Age'] <= 27), 'Age'] = 3\n",
        "    dataset.loc[(dataset['Age'] > 27) & (dataset['Age'] <= 33), 'Age'] = 4\n",
        "    dataset.loc[(dataset['Age'] > 33) & (dataset['Age'] <= 40), 'Age'] = 5\n",
        "    dataset.loc[(dataset['Age'] > 40) & (dataset['Age'] <= 66), 'Age'] = 6\n",
        "    dataset.loc[ dataset['Age'] > 66, 'Age'] = 6\n",
        "\n",
        "# let's see how it's distributed \n",
        "train_df['Age'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ykRwgq_Pa2_1",
        "outputId": "b78cdf97-70f0-4fa7-cadc-cc059884484d"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6    176\n",
              "4    170\n",
              "5    147\n",
              "3    126\n",
              "2    110\n",
              "1     94\n",
              "0     68\n",
              "Name: Age, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#pandas qcut함수\n",
        "#6개의 범위로 연속형 데이터를 나눠줌. 각 범위에 들어가는 데이터의 수는 대강 비슷하게 맞춰줌!\n",
        "\n",
        "pd.qcut(train_df['Fare'], 6)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YHWEP658dQsp",
        "outputId": "f97a7831-617b-492e-be31-94dcc9b4856c"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      (-0.001, 7.0]\n",
              "1      (52.0, 512.0]\n",
              "2      (-0.001, 7.0]\n",
              "3      (52.0, 512.0]\n",
              "4         (7.0, 8.0]\n",
              "           ...      \n",
              "886      (8.0, 14.0]\n",
              "887     (26.0, 52.0]\n",
              "888     (14.0, 26.0]\n",
              "889     (26.0, 52.0]\n",
              "890    (-0.001, 7.0]\n",
              "Name: Fare, Length: 891, dtype: category\n",
              "Categories (6, interval[float64]): [(-0.001, 7.0] < (7.0, 8.0] < (8.0, 14.0] < (14.0, 26.0] <\n",
              "                                    (26.0, 52.0] < (52.0, 512.0]]"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = [train_df, test_df]\n",
        "\n",
        "for dataset in data:\n",
        "    dataset.loc[ dataset['Fare'] <= 7.00, 'Fare'] = 0\n",
        "    dataset.loc[(dataset['Fare'] > 7.00) & (dataset['Fare'] <= 8), 'Fare'] = 1\n",
        "    dataset.loc[(dataset['Fare'] > 8) & (dataset['Fare'] <= 14), 'Fare']   = 2\n",
        "    dataset.loc[(dataset['Fare'] > 14) & (dataset['Fare'] <= 26), 'Fare']   = 3\n",
        "    dataset.loc[(dataset['Fare'] > 26) & (dataset['Fare'] <= 52), 'Fare']   = 4\n",
        "    dataset.loc[ dataset['Fare'] > 52, 'Fare'] = 5\n",
        "    dataset['Fare'] = dataset['Fare'].astype(int)\n",
        "  \n",
        "train_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "n_01INSJdwk2",
        "outputId": "25638437-ca9e-438a-b9f6-c2f30d0233db"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-169800c1-7c20-4e4d-aa7e-d8c743168bfe\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Embarked</th>\n",
              "      <th>relatives</th>\n",
              "      <th>not_alone</th>\n",
              "      <th>Deck</th>\n",
              "      <th>Title</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>886</th>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>887</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>888</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>889</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>890</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>891 rows × 12 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-169800c1-7c20-4e4d-aa7e-d8c743168bfe')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-169800c1-7c20-4e4d-aa7e-d8c743168bfe button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-169800c1-7c20-4e4d-aa7e-d8c743168bfe');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "     Survived  Pclass  Sex  Age  ...  relatives  not_alone  Deck  Title\n",
              "0           0       3    0    2  ...          1          0     8      1\n",
              "1           1       1    1    5  ...          1          0     3      3\n",
              "2           1       3    1    3  ...          0          1     8      2\n",
              "3           1       1    1    5  ...          1          0     3      3\n",
              "4           0       3    0    5  ...          0          1     8      1\n",
              "..        ...     ...  ...  ...  ...        ...        ...   ...    ...\n",
              "886         0       2    0    3  ...          0          1     8      5\n",
              "887         1       1    1    2  ...          0          1     2      2\n",
              "888         0       3    1    2  ...          3          0     8      2\n",
              "889         1       1    0    3  ...          0          1     3      1\n",
              "890         0       3    0    4  ...          0          1     8      1\n",
              "\n",
              "[891 rows x 12 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.groupby(['Fare', 'Survived']).size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4omyoRpdfeN9",
        "outputId": "b5e151e1-427e-45e2-e44c-51bcf8b2e494"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Fare  Survived\n",
              "0     0           189\n",
              "      1            52\n",
              "1     0            60\n",
              "      1            10\n",
              "2     0            94\n",
              "      1            52\n",
              "3     0            85\n",
              "      1            80\n",
              "4     0            76\n",
              "      1            47\n",
              "5     0            45\n",
              "      1           101\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#새로운 feature 만들기!\n",
        "\n",
        "data = [train_df, test_df]\n",
        "for dataset in data:\n",
        "    dataset['Age_Class']= dataset['Age']* dataset['Pclass']"
      ],
      "metadata": {
        "id": "djBQ_LXGfmpt"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for dataset in data:\n",
        "    dataset['Fare_Per_Person'] = dataset['Fare']/(dataset['relatives']+1)\n",
        "    dataset['Fare_Per_Person'] = dataset['Fare_Per_Person'].astype(int)\n",
        "# Let's take a last look at the training set, before we start training the models.\n",
        "train_df.head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "_j1L-k7BgJzN",
        "outputId": "d25da5f5-94e4-448e-cf6d-03f87adbbc30"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-e2a4d302-387e-472d-9b4f-aa4601392874\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Embarked</th>\n",
              "      <th>relatives</th>\n",
              "      <th>not_alone</th>\n",
              "      <th>Deck</th>\n",
              "      <th>Title</th>\n",
              "      <th>Age_Class</th>\n",
              "      <th>Fare_Per_Person</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>2</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>15</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>15</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>3</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e2a4d302-387e-472d-9b4f-aa4601392874')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e2a4d302-387e-472d-9b4f-aa4601392874 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e2a4d302-387e-472d-9b4f-aa4601392874');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   Survived  Pclass  Sex  Age  ...  Deck  Title  Age_Class  Fare_Per_Person\n",
              "0         0       3    0    2  ...     8      1          6                0\n",
              "1         1       1    1    5  ...     3      3          5                2\n",
              "2         1       3    1    3  ...     8      2          9                0\n",
              "3         1       1    1    5  ...     3      3          5                2\n",
              "4         0       3    0    5  ...     8      1         15                1\n",
              "5         0       3    0    5  ...     8      1         15                1\n",
              "6         0       1    0    6  ...     5      1          6                4\n",
              "7         0       3    0    0  ...     8      4          0                0\n",
              "8         1       3    1    3  ...     8      3          9                0\n",
              "9         1       2    1    1  ...     8      3          2                2\n",
              "\n",
              "[10 rows x 14 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_df.head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "GRhKK9-VhY_E",
        "outputId": "07719c68-5528-42c8-f231-ca8fbf6d9b79"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-0750e6cf-7e2f-4167-ab57-f9e3c484c593\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Embarked</th>\n",
              "      <th>relatives</th>\n",
              "      <th>not_alone</th>\n",
              "      <th>Deck</th>\n",
              "      <th>Title</th>\n",
              "      <th>Age_Class</th>\n",
              "      <th>Fare_Per_Person</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>892</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>15</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>893</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>3</td>\n",
              "      <td>18</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>894</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>12</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>895</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>896</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>897</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>898</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>2</td>\n",
              "      <td>12</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>899</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>900</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>901</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0750e6cf-7e2f-4167-ab57-f9e3c484c593')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0750e6cf-7e2f-4167-ab57-f9e3c484c593 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0750e6cf-7e2f-4167-ab57-f9e3c484c593');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   PassengerId  Pclass  Sex  Age  ...  Deck  Title  Age_Class  Fare_Per_Person\n",
              "0          892       3    0    5  ...     8      1         15                0\n",
              "1          893       3    1    6  ...     8      3         18                0\n",
              "2          894       2    0    6  ...     8      1         12                2\n",
              "3          895       3    0    3  ...     8      1          9                1\n",
              "4          896       3    1    2  ...     8      3          6                0\n",
              "5          897       3    0    1  ...     8      1          3                2\n",
              "6          898       3    1    4  ...     8      2         12                0\n",
              "7          899       2    0    3  ...     8      1          6                1\n",
              "8          900       3    1    1  ...     8      3          3                0\n",
              "9          901       3    0    2  ...     8      1          6                1\n",
              "\n",
              "[10 rows x 14 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df  = train_df.drop(\"not_alone\", axis=1)\n",
        "test_df  = test_df.drop(\"not_alone\", axis=1)\n",
        "\n",
        "train_df  = train_df.drop(\"Parch\", axis=1)\n",
        "test_df  = test_df.drop(\"Parch\", axis=1)"
      ],
      "metadata": {
        "id": "mqFWDhv8lYn2"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "featuredf = train_df.drop(['Survived'], axis = 1)\n",
        "labeldf = train_df['Survived']"
      ],
      "metadata": {
        "id": "g-uc0COa2Jfm"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train,X_val,Y_train,Y_val = sklearn.model_selection.train_test_split(featuredf,labeldf, test_size = 0.2,random_state = 42)"
      ],
      "metadata": {
        "id": "Qhy9Ca031f7e"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "KplgOWdEHYiy",
        "outputId": "a6a9fea9-639e-4bd7-807d-9d144cb51871"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-22bca883-2abe-4e84-88a6-dedb54c617cf\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Embarked</th>\n",
              "      <th>relatives</th>\n",
              "      <th>Deck</th>\n",
              "      <th>Title</th>\n",
              "      <th>Age_Class</th>\n",
              "      <th>Fare_Per_Person</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>331</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>733</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>382</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>12</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>704</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>813</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>8</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-22bca883-2abe-4e84-88a6-dedb54c617cf')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-22bca883-2abe-4e84-88a6-dedb54c617cf button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-22bca883-2abe-4e84-88a6-dedb54c617cf');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "     Pclass  Sex  Age  SibSp  ...  Deck  Title  Age_Class  Fare_Per_Person\n",
              "331       1    0    6      0  ...     3      1          6                4\n",
              "733       2    0    3      0  ...     8      1          6                2\n",
              "382       3    0    4      0  ...     8      1         12                0\n",
              "704       3    0    3      1  ...     8      1          9                0\n",
              "813       3    1    0      4  ...     8      2          0                0\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.shape[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HUaA3rcbyX9x",
        "outputId": "f93c9e87-d614-404d-d5d2-ddf6c39e430a"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Densemodel = tf.keras.models.Sequential([\n",
        "    \n",
        "    tf.keras.layers.Dense(32, input_shape = ((train_df.shape[1] - 1), ), activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.3),\n",
        "    tf.keras.layers.Dense(64, activation = 'relu'),\n",
        "    tf.keras.layers.Dropout(0.3),\n",
        "    tf.keras.layers.Dense(2, activation = 'softmax')\n",
        "    \n",
        "])"
      ],
      "metadata": {
        "id": "CnuxzByhoEct"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#from_logits = True, False 주의하기!\n",
        "\n",
        "Densemodel.compile(optimizer = 'adam',\n",
        "                   loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
        "                  metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "Z_IyKYcioLil"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Densemodel.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r_p7CIdnzqk1",
        "outputId": "4a98413b-9629-4fbc-92bb-5d86063fa107"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 32)                384       \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 32)                0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 64)                2112      \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 2)                 130       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,626\n",
            "Trainable params: 2,626\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 2000\n",
        "\n",
        "model_checkpoint = keras.callbacks.ModelCheckpoint(\n",
        "\"my_checkpoint.h5\", save_best_only = True)\n",
        "\n",
        "early_stopping = keras.callbacks.EarlyStopping(patience = 200)\n",
        "\n",
        "model = Densemodel.fit(X_train, Y_train, validation_data = (X_val, Y_val),\n",
        "               epochs = EPOCHS,\n",
        "               callbacks = [model_checkpoint, early_stopping])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5D1qdBqnoOGt",
        "outputId": "890087ee-c3a0-41a6-e086-d2a3ca531ef5"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2000\n",
            "23/23 [==============================] - 1s 17ms/step - loss: 1.0833 - accuracy: 0.5463 - val_loss: 0.6389 - val_accuracy: 0.5866\n",
            "Epoch 2/2000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.8521 - accuracy: 0.5730 - val_loss: 0.5824 - val_accuracy: 0.6480\n",
            "Epoch 3/2000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.7543 - accuracy: 0.5997 - val_loss: 0.5490 - val_accuracy: 0.7263\n",
            "Epoch 4/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.6354 - accuracy: 0.6728 - val_loss: 0.5312 - val_accuracy: 0.7430\n",
            "Epoch 5/2000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.6431 - accuracy: 0.6489 - val_loss: 0.5255 - val_accuracy: 0.8268\n",
            "Epoch 6/2000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.6307 - accuracy: 0.6587 - val_loss: 0.5137 - val_accuracy: 0.7486\n",
            "Epoch 7/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.5974 - accuracy: 0.6770 - val_loss: 0.5096 - val_accuracy: 0.8268\n",
            "Epoch 8/2000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.5751 - accuracy: 0.6938 - val_loss: 0.4976 - val_accuracy: 0.8045\n",
            "Epoch 9/2000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.5514 - accuracy: 0.7289 - val_loss: 0.4887 - val_accuracy: 0.8156\n",
            "Epoch 10/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.5475 - accuracy: 0.7247 - val_loss: 0.4785 - val_accuracy: 0.8324\n",
            "Epoch 11/2000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.5503 - accuracy: 0.7233 - val_loss: 0.4774 - val_accuracy: 0.8156\n",
            "Epoch 12/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.5408 - accuracy: 0.7528 - val_loss: 0.4723 - val_accuracy: 0.8436\n",
            "Epoch 13/2000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.5451 - accuracy: 0.7303 - val_loss: 0.4698 - val_accuracy: 0.8380\n",
            "Epoch 14/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.5238 - accuracy: 0.7697 - val_loss: 0.4640 - val_accuracy: 0.8156\n",
            "Epoch 15/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.5110 - accuracy: 0.7711 - val_loss: 0.4600 - val_accuracy: 0.8492\n",
            "Epoch 16/2000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.5105 - accuracy: 0.7640 - val_loss: 0.4513 - val_accuracy: 0.8603\n",
            "Epoch 17/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.5196 - accuracy: 0.7584 - val_loss: 0.4470 - val_accuracy: 0.8547\n",
            "Epoch 18/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.5102 - accuracy: 0.7711 - val_loss: 0.4468 - val_accuracy: 0.8547\n",
            "Epoch 19/2000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.5117 - accuracy: 0.7472 - val_loss: 0.4456 - val_accuracy: 0.8436\n",
            "Epoch 20/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.5050 - accuracy: 0.7697 - val_loss: 0.4443 - val_accuracy: 0.8436\n",
            "Epoch 21/2000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.5107 - accuracy: 0.7669 - val_loss: 0.4424 - val_accuracy: 0.8436\n",
            "Epoch 22/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.5048 - accuracy: 0.7795 - val_loss: 0.4403 - val_accuracy: 0.8547\n",
            "Epoch 23/2000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.4697 - accuracy: 0.7809 - val_loss: 0.4367 - val_accuracy: 0.8492\n",
            "Epoch 24/2000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.4878 - accuracy: 0.7879 - val_loss: 0.4307 - val_accuracy: 0.8603\n",
            "Epoch 25/2000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.4841 - accuracy: 0.7879 - val_loss: 0.4294 - val_accuracy: 0.8492\n",
            "Epoch 26/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.4854 - accuracy: 0.7767 - val_loss: 0.4314 - val_accuracy: 0.8492\n",
            "Epoch 27/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.4878 - accuracy: 0.7992 - val_loss: 0.4300 - val_accuracy: 0.8436\n",
            "Epoch 28/2000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.4832 - accuracy: 0.7963 - val_loss: 0.4288 - val_accuracy: 0.8436\n",
            "Epoch 29/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.4874 - accuracy: 0.7865 - val_loss: 0.4256 - val_accuracy: 0.8436\n",
            "Epoch 30/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.4800 - accuracy: 0.7949 - val_loss: 0.4257 - val_accuracy: 0.8492\n",
            "Epoch 31/2000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.4683 - accuracy: 0.8090 - val_loss: 0.4230 - val_accuracy: 0.8380\n",
            "Epoch 32/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.4694 - accuracy: 0.7963 - val_loss: 0.4192 - val_accuracy: 0.8492\n",
            "Epoch 33/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.4804 - accuracy: 0.7851 - val_loss: 0.4225 - val_accuracy: 0.8603\n",
            "Epoch 34/2000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.4664 - accuracy: 0.8062 - val_loss: 0.4186 - val_accuracy: 0.8436\n",
            "Epoch 35/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.4598 - accuracy: 0.7963 - val_loss: 0.4194 - val_accuracy: 0.8659\n",
            "Epoch 36/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.4651 - accuracy: 0.7879 - val_loss: 0.4140 - val_accuracy: 0.8436\n",
            "Epoch 37/2000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.4471 - accuracy: 0.8146 - val_loss: 0.4133 - val_accuracy: 0.8380\n",
            "Epoch 38/2000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.4414 - accuracy: 0.8118 - val_loss: 0.4109 - val_accuracy: 0.8492\n",
            "Epoch 39/2000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.4554 - accuracy: 0.8062 - val_loss: 0.4080 - val_accuracy: 0.8436\n",
            "Epoch 40/2000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.4409 - accuracy: 0.8202 - val_loss: 0.4036 - val_accuracy: 0.8436\n",
            "Epoch 41/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.4447 - accuracy: 0.8076 - val_loss: 0.4046 - val_accuracy: 0.8436\n",
            "Epoch 42/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.4471 - accuracy: 0.8090 - val_loss: 0.4073 - val_accuracy: 0.8492\n",
            "Epoch 43/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.4462 - accuracy: 0.8132 - val_loss: 0.4049 - val_accuracy: 0.8324\n",
            "Epoch 44/2000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.4230 - accuracy: 0.8329 - val_loss: 0.3959 - val_accuracy: 0.8380\n",
            "Epoch 45/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.4512 - accuracy: 0.8118 - val_loss: 0.3938 - val_accuracy: 0.8436\n",
            "Epoch 46/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.4354 - accuracy: 0.8146 - val_loss: 0.3970 - val_accuracy: 0.8268\n",
            "Epoch 47/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.4343 - accuracy: 0.8188 - val_loss: 0.3981 - val_accuracy: 0.8324\n",
            "Epoch 48/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.4315 - accuracy: 0.8287 - val_loss: 0.3970 - val_accuracy: 0.8324\n",
            "Epoch 49/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.4258 - accuracy: 0.8244 - val_loss: 0.3938 - val_accuracy: 0.8380\n",
            "Epoch 50/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.4152 - accuracy: 0.8329 - val_loss: 0.3941 - val_accuracy: 0.8324\n",
            "Epoch 51/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.4321 - accuracy: 0.8287 - val_loss: 0.3956 - val_accuracy: 0.8380\n",
            "Epoch 52/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.4209 - accuracy: 0.8272 - val_loss: 0.3988 - val_accuracy: 0.8324\n",
            "Epoch 53/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.4408 - accuracy: 0.8174 - val_loss: 0.3991 - val_accuracy: 0.8380\n",
            "Epoch 54/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.4076 - accuracy: 0.8301 - val_loss: 0.3952 - val_accuracy: 0.8268\n",
            "Epoch 55/2000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.4178 - accuracy: 0.8399 - val_loss: 0.3929 - val_accuracy: 0.8324\n",
            "Epoch 56/2000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.4253 - accuracy: 0.8258 - val_loss: 0.3877 - val_accuracy: 0.8380\n",
            "Epoch 57/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.4362 - accuracy: 0.8230 - val_loss: 0.3932 - val_accuracy: 0.8324\n",
            "Epoch 58/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.4176 - accuracy: 0.8343 - val_loss: 0.3983 - val_accuracy: 0.8380\n",
            "Epoch 59/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.4059 - accuracy: 0.8343 - val_loss: 0.3959 - val_accuracy: 0.8324\n",
            "Epoch 60/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.4054 - accuracy: 0.8343 - val_loss: 0.3994 - val_accuracy: 0.8324\n",
            "Epoch 61/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.4179 - accuracy: 0.8230 - val_loss: 0.3965 - val_accuracy: 0.8324\n",
            "Epoch 62/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.3997 - accuracy: 0.8315 - val_loss: 0.3989 - val_accuracy: 0.8324\n",
            "Epoch 63/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.4142 - accuracy: 0.8272 - val_loss: 0.3927 - val_accuracy: 0.8324\n",
            "Epoch 64/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.4160 - accuracy: 0.8132 - val_loss: 0.3974 - val_accuracy: 0.8324\n",
            "Epoch 65/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.4083 - accuracy: 0.8343 - val_loss: 0.3959 - val_accuracy: 0.8324\n",
            "Epoch 66/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.4182 - accuracy: 0.8272 - val_loss: 0.3990 - val_accuracy: 0.8324\n",
            "Epoch 67/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.4162 - accuracy: 0.8427 - val_loss: 0.3979 - val_accuracy: 0.8324\n",
            "Epoch 68/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.3907 - accuracy: 0.8399 - val_loss: 0.3890 - val_accuracy: 0.8324\n",
            "Epoch 69/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.4173 - accuracy: 0.8287 - val_loss: 0.3991 - val_accuracy: 0.8268\n",
            "Epoch 70/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.4210 - accuracy: 0.8272 - val_loss: 0.3921 - val_accuracy: 0.8268\n",
            "Epoch 71/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.4006 - accuracy: 0.8427 - val_loss: 0.3905 - val_accuracy: 0.8212\n",
            "Epoch 72/2000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.3987 - accuracy: 0.8287 - val_loss: 0.3870 - val_accuracy: 0.8268\n",
            "Epoch 73/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.3975 - accuracy: 0.8427 - val_loss: 0.3922 - val_accuracy: 0.8268\n",
            "Epoch 74/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.3920 - accuracy: 0.8385 - val_loss: 0.3930 - val_accuracy: 0.8324\n",
            "Epoch 75/2000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.3961 - accuracy: 0.8301 - val_loss: 0.3870 - val_accuracy: 0.8268\n",
            "Epoch 76/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.4072 - accuracy: 0.8427 - val_loss: 0.3926 - val_accuracy: 0.8268\n",
            "Epoch 77/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.4006 - accuracy: 0.8385 - val_loss: 0.3931 - val_accuracy: 0.8268\n",
            "Epoch 78/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.3875 - accuracy: 0.8343 - val_loss: 0.3898 - val_accuracy: 0.8324\n",
            "Epoch 79/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.3945 - accuracy: 0.8287 - val_loss: 0.3936 - val_accuracy: 0.8324\n",
            "Epoch 80/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.4029 - accuracy: 0.8469 - val_loss: 0.3931 - val_accuracy: 0.8268\n",
            "Epoch 81/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.3935 - accuracy: 0.8371 - val_loss: 0.3900 - val_accuracy: 0.8324\n",
            "Epoch 82/2000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.4020 - accuracy: 0.8357 - val_loss: 0.3962 - val_accuracy: 0.8324\n",
            "Epoch 83/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.3905 - accuracy: 0.8357 - val_loss: 0.3882 - val_accuracy: 0.8268\n",
            "Epoch 84/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.3794 - accuracy: 0.8371 - val_loss: 0.3908 - val_accuracy: 0.8324\n",
            "Epoch 85/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.3916 - accuracy: 0.8497 - val_loss: 0.3911 - val_accuracy: 0.8268\n",
            "Epoch 86/2000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.3891 - accuracy: 0.8455 - val_loss: 0.3851 - val_accuracy: 0.8268\n",
            "Epoch 87/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.3893 - accuracy: 0.8441 - val_loss: 0.3947 - val_accuracy: 0.8268\n",
            "Epoch 88/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.3938 - accuracy: 0.8329 - val_loss: 0.3907 - val_accuracy: 0.8268\n",
            "Epoch 89/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.3820 - accuracy: 0.8455 - val_loss: 0.3953 - val_accuracy: 0.8268\n",
            "Epoch 90/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.3835 - accuracy: 0.8399 - val_loss: 0.3932 - val_accuracy: 0.8156\n",
            "Epoch 91/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.3751 - accuracy: 0.8469 - val_loss: 0.3906 - val_accuracy: 0.8268\n",
            "Epoch 92/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.3961 - accuracy: 0.8511 - val_loss: 0.3947 - val_accuracy: 0.8268\n",
            "Epoch 93/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.3989 - accuracy: 0.8483 - val_loss: 0.3981 - val_accuracy: 0.8268\n",
            "Epoch 94/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.3848 - accuracy: 0.8385 - val_loss: 0.3972 - val_accuracy: 0.8268\n",
            "Epoch 95/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.3756 - accuracy: 0.8399 - val_loss: 0.3881 - val_accuracy: 0.8268\n",
            "Epoch 96/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.3845 - accuracy: 0.8511 - val_loss: 0.3916 - val_accuracy: 0.8268\n",
            "Epoch 97/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.3803 - accuracy: 0.8596 - val_loss: 0.3966 - val_accuracy: 0.8268\n",
            "Epoch 98/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.3913 - accuracy: 0.8483 - val_loss: 0.4043 - val_accuracy: 0.8268\n",
            "Epoch 99/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.3836 - accuracy: 0.8497 - val_loss: 0.3994 - val_accuracy: 0.8212\n",
            "Epoch 100/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.3889 - accuracy: 0.8441 - val_loss: 0.3999 - val_accuracy: 0.8212\n",
            "Epoch 101/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.3931 - accuracy: 0.8483 - val_loss: 0.3982 - val_accuracy: 0.8268\n",
            "Epoch 102/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.3847 - accuracy: 0.8483 - val_loss: 0.3962 - val_accuracy: 0.8268\n",
            "Epoch 103/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.3691 - accuracy: 0.8455 - val_loss: 0.3964 - val_accuracy: 0.8268\n",
            "Epoch 104/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.3850 - accuracy: 0.8483 - val_loss: 0.3915 - val_accuracy: 0.8268\n",
            "Epoch 105/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.3819 - accuracy: 0.8455 - val_loss: 0.3963 - val_accuracy: 0.8212\n",
            "Epoch 106/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.3792 - accuracy: 0.8455 - val_loss: 0.3977 - val_accuracy: 0.8268\n",
            "Epoch 107/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.3838 - accuracy: 0.8497 - val_loss: 0.3970 - val_accuracy: 0.8101\n",
            "Epoch 108/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.3857 - accuracy: 0.8497 - val_loss: 0.3984 - val_accuracy: 0.8268\n",
            "Epoch 109/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.3828 - accuracy: 0.8441 - val_loss: 0.3980 - val_accuracy: 0.8268\n",
            "Epoch 110/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.3766 - accuracy: 0.8553 - val_loss: 0.3923 - val_accuracy: 0.8268\n",
            "Epoch 111/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.3793 - accuracy: 0.8553 - val_loss: 0.3892 - val_accuracy: 0.8268\n",
            "Epoch 112/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.3850 - accuracy: 0.8371 - val_loss: 0.3944 - val_accuracy: 0.8268\n",
            "Epoch 113/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.3804 - accuracy: 0.8483 - val_loss: 0.3948 - val_accuracy: 0.8268\n",
            "Epoch 114/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.3751 - accuracy: 0.8497 - val_loss: 0.4000 - val_accuracy: 0.8212\n",
            "Epoch 115/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.3744 - accuracy: 0.8427 - val_loss: 0.4021 - val_accuracy: 0.8268\n",
            "Epoch 116/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.3826 - accuracy: 0.8385 - val_loss: 0.3965 - val_accuracy: 0.8156\n",
            "Epoch 117/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.3906 - accuracy: 0.8469 - val_loss: 0.3981 - val_accuracy: 0.8268\n",
            "Epoch 118/2000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.3674 - accuracy: 0.8483 - val_loss: 0.3980 - val_accuracy: 0.8268\n",
            "Epoch 119/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.3778 - accuracy: 0.8427 - val_loss: 0.3980 - val_accuracy: 0.8268\n",
            "Epoch 120/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.3789 - accuracy: 0.8567 - val_loss: 0.3922 - val_accuracy: 0.8268\n",
            "Epoch 121/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.3694 - accuracy: 0.8483 - val_loss: 0.3970 - val_accuracy: 0.8268\n",
            "Epoch 122/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.3840 - accuracy: 0.8497 - val_loss: 0.3991 - val_accuracy: 0.8268\n",
            "Epoch 123/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.3753 - accuracy: 0.8553 - val_loss: 0.4017 - val_accuracy: 0.8268\n",
            "Epoch 124/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.3830 - accuracy: 0.8441 - val_loss: 0.4014 - val_accuracy: 0.8212\n",
            "Epoch 125/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.3852 - accuracy: 0.8413 - val_loss: 0.3953 - val_accuracy: 0.8212\n",
            "Epoch 126/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.3613 - accuracy: 0.8722 - val_loss: 0.3961 - val_accuracy: 0.8380\n",
            "Epoch 127/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.3634 - accuracy: 0.8497 - val_loss: 0.3926 - val_accuracy: 0.8324\n",
            "Epoch 128/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.3806 - accuracy: 0.8441 - val_loss: 0.3996 - val_accuracy: 0.8101\n",
            "Epoch 129/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.3672 - accuracy: 0.8553 - val_loss: 0.3987 - val_accuracy: 0.8156\n",
            "Epoch 130/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.3770 - accuracy: 0.8357 - val_loss: 0.4000 - val_accuracy: 0.8156\n",
            "Epoch 131/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.3671 - accuracy: 0.8427 - val_loss: 0.4055 - val_accuracy: 0.8268\n",
            "Epoch 132/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.3648 - accuracy: 0.8469 - val_loss: 0.4047 - val_accuracy: 0.8212\n",
            "Epoch 133/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.3803 - accuracy: 0.8441 - val_loss: 0.4012 - val_accuracy: 0.8212\n",
            "Epoch 134/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.3805 - accuracy: 0.8427 - val_loss: 0.4069 - val_accuracy: 0.8156\n",
            "Epoch 135/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.3738 - accuracy: 0.8455 - val_loss: 0.4027 - val_accuracy: 0.8212\n",
            "Epoch 136/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.3643 - accuracy: 0.8483 - val_loss: 0.4008 - val_accuracy: 0.8156\n",
            "Epoch 137/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.3777 - accuracy: 0.8399 - val_loss: 0.4006 - val_accuracy: 0.8156\n",
            "Epoch 138/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.3712 - accuracy: 0.8680 - val_loss: 0.4004 - val_accuracy: 0.8212\n",
            "Epoch 139/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.3636 - accuracy: 0.8230 - val_loss: 0.4012 - val_accuracy: 0.8156\n",
            "Epoch 140/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.3704 - accuracy: 0.8581 - val_loss: 0.4125 - val_accuracy: 0.8212\n",
            "Epoch 141/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.3581 - accuracy: 0.8483 - val_loss: 0.4017 - val_accuracy: 0.8268\n",
            "Epoch 142/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.3758 - accuracy: 0.8525 - val_loss: 0.3965 - val_accuracy: 0.8212\n",
            "Epoch 143/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.3846 - accuracy: 0.8596 - val_loss: 0.3960 - val_accuracy: 0.8268\n",
            "Epoch 144/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.3840 - accuracy: 0.8371 - val_loss: 0.3999 - val_accuracy: 0.8156\n",
            "Epoch 145/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.3674 - accuracy: 0.8497 - val_loss: 0.4005 - val_accuracy: 0.8156\n",
            "Epoch 146/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.3731 - accuracy: 0.8483 - val_loss: 0.3993 - val_accuracy: 0.8101\n",
            "Epoch 147/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.3666 - accuracy: 0.8357 - val_loss: 0.4015 - val_accuracy: 0.8101\n",
            "Epoch 148/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.3845 - accuracy: 0.8539 - val_loss: 0.4049 - val_accuracy: 0.8212\n",
            "Epoch 149/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.3690 - accuracy: 0.8455 - val_loss: 0.4045 - val_accuracy: 0.8212\n",
            "Epoch 150/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.3649 - accuracy: 0.8539 - val_loss: 0.3981 - val_accuracy: 0.8101\n",
            "Epoch 151/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.3671 - accuracy: 0.8511 - val_loss: 0.3983 - val_accuracy: 0.8212\n",
            "Epoch 152/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.3600 - accuracy: 0.8525 - val_loss: 0.4063 - val_accuracy: 0.8156\n",
            "Epoch 153/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.3786 - accuracy: 0.8455 - val_loss: 0.4047 - val_accuracy: 0.8156\n",
            "Epoch 154/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.3638 - accuracy: 0.8638 - val_loss: 0.4060 - val_accuracy: 0.8156\n",
            "Epoch 155/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.3718 - accuracy: 0.8624 - val_loss: 0.3985 - val_accuracy: 0.8212\n",
            "Epoch 156/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.3682 - accuracy: 0.8511 - val_loss: 0.4058 - val_accuracy: 0.8156\n",
            "Epoch 157/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.3670 - accuracy: 0.8596 - val_loss: 0.3979 - val_accuracy: 0.8212\n",
            "Epoch 158/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.3829 - accuracy: 0.8596 - val_loss: 0.3959 - val_accuracy: 0.8324\n",
            "Epoch 159/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.3454 - accuracy: 0.8722 - val_loss: 0.4021 - val_accuracy: 0.8268\n",
            "Epoch 160/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.3609 - accuracy: 0.8511 - val_loss: 0.3990 - val_accuracy: 0.8212\n",
            "Epoch 161/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.3750 - accuracy: 0.8469 - val_loss: 0.3976 - val_accuracy: 0.8212\n",
            "Epoch 162/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.3606 - accuracy: 0.8455 - val_loss: 0.3920 - val_accuracy: 0.8436\n",
            "Epoch 163/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.3589 - accuracy: 0.8553 - val_loss: 0.3991 - val_accuracy: 0.8380\n",
            "Epoch 164/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.3623 - accuracy: 0.8511 - val_loss: 0.4027 - val_accuracy: 0.8268\n",
            "Epoch 165/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.3642 - accuracy: 0.8483 - val_loss: 0.4081 - val_accuracy: 0.8101\n",
            "Epoch 166/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.3630 - accuracy: 0.8525 - val_loss: 0.4094 - val_accuracy: 0.8156\n",
            "Epoch 167/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.3643 - accuracy: 0.8553 - val_loss: 0.4040 - val_accuracy: 0.8156\n",
            "Epoch 168/2000\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 0.3779 - accuracy: 0.8525 - val_loss: 0.4097 - val_accuracy: 0.8101\n",
            "Epoch 169/2000\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.3787 - accuracy: 0.8511 - val_loss: 0.4003 - val_accuracy: 0.8268\n",
            "Epoch 170/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.3503 - accuracy: 0.8581 - val_loss: 0.4066 - val_accuracy: 0.8324\n",
            "Epoch 171/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.3650 - accuracy: 0.8652 - val_loss: 0.4136 - val_accuracy: 0.8268\n",
            "Epoch 172/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.3704 - accuracy: 0.8539 - val_loss: 0.4107 - val_accuracy: 0.8324\n",
            "Epoch 173/2000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.3700 - accuracy: 0.8581 - val_loss: 0.4119 - val_accuracy: 0.8212\n",
            "Epoch 174/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.3484 - accuracy: 0.8539 - val_loss: 0.4078 - val_accuracy: 0.8268\n",
            "Epoch 175/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.3543 - accuracy: 0.8525 - val_loss: 0.4141 - val_accuracy: 0.8324\n",
            "Epoch 176/2000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.3542 - accuracy: 0.8652 - val_loss: 0.4103 - val_accuracy: 0.8324\n",
            "Epoch 177/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.3680 - accuracy: 0.8581 - val_loss: 0.4042 - val_accuracy: 0.8436\n",
            "Epoch 178/2000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.3677 - accuracy: 0.8511 - val_loss: 0.4043 - val_accuracy: 0.8268\n",
            "Epoch 179/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.3644 - accuracy: 0.8553 - val_loss: 0.4113 - val_accuracy: 0.8268\n",
            "Epoch 180/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.3751 - accuracy: 0.8553 - val_loss: 0.4095 - val_accuracy: 0.8324\n",
            "Epoch 181/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.3630 - accuracy: 0.8553 - val_loss: 0.4029 - val_accuracy: 0.8324\n",
            "Epoch 182/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.3567 - accuracy: 0.8455 - val_loss: 0.4040 - val_accuracy: 0.8268\n",
            "Epoch 183/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.3662 - accuracy: 0.8581 - val_loss: 0.4104 - val_accuracy: 0.8212\n",
            "Epoch 184/2000\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 0.3582 - accuracy: 0.8539 - val_loss: 0.4095 - val_accuracy: 0.8268\n",
            "Epoch 185/2000\n",
            "23/23 [==============================] - 0s 14ms/step - loss: 0.3515 - accuracy: 0.8581 - val_loss: 0.4041 - val_accuracy: 0.8380\n",
            "Epoch 186/2000\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.3654 - accuracy: 0.8539 - val_loss: 0.4034 - val_accuracy: 0.8324\n",
            "Epoch 187/2000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.3623 - accuracy: 0.8483 - val_loss: 0.4058 - val_accuracy: 0.8268\n",
            "Epoch 188/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.3507 - accuracy: 0.8567 - val_loss: 0.4081 - val_accuracy: 0.8380\n",
            "Epoch 189/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.3581 - accuracy: 0.8567 - val_loss: 0.4096 - val_accuracy: 0.8324\n",
            "Epoch 190/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.3589 - accuracy: 0.8624 - val_loss: 0.4094 - val_accuracy: 0.8380\n",
            "Epoch 191/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.3486 - accuracy: 0.8666 - val_loss: 0.4114 - val_accuracy: 0.8492\n",
            "Epoch 192/2000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.3632 - accuracy: 0.8497 - val_loss: 0.4101 - val_accuracy: 0.8324\n",
            "Epoch 193/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.3594 - accuracy: 0.8610 - val_loss: 0.4123 - val_accuracy: 0.8268\n",
            "Epoch 194/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.3539 - accuracy: 0.8610 - val_loss: 0.4124 - val_accuracy: 0.8380\n",
            "Epoch 195/2000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.3475 - accuracy: 0.8638 - val_loss: 0.4063 - val_accuracy: 0.8436\n",
            "Epoch 196/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.3571 - accuracy: 0.8413 - val_loss: 0.4092 - val_accuracy: 0.8324\n",
            "Epoch 197/2000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.3605 - accuracy: 0.8624 - val_loss: 0.4150 - val_accuracy: 0.8380\n",
            "Epoch 198/2000\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.3574 - accuracy: 0.8539 - val_loss: 0.4069 - val_accuracy: 0.8324\n",
            "Epoch 199/2000\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.3568 - accuracy: 0.8581 - val_loss: 0.3992 - val_accuracy: 0.8380\n",
            "Epoch 200/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.3558 - accuracy: 0.8610 - val_loss: 0.4009 - val_accuracy: 0.8380\n",
            "Epoch 201/2000\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.3539 - accuracy: 0.8525 - val_loss: 0.4100 - val_accuracy: 0.8380\n",
            "Epoch 202/2000\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 0.3644 - accuracy: 0.8511 - val_loss: 0.4154 - val_accuracy: 0.8268\n",
            "Epoch 203/2000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.3503 - accuracy: 0.8652 - val_loss: 0.4188 - val_accuracy: 0.8324\n",
            "Epoch 204/2000\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 0.3598 - accuracy: 0.8525 - val_loss: 0.4075 - val_accuracy: 0.8268\n",
            "Epoch 205/2000\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.3548 - accuracy: 0.8567 - val_loss: 0.4120 - val_accuracy: 0.8380\n",
            "Epoch 206/2000\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.3614 - accuracy: 0.8511 - val_loss: 0.4193 - val_accuracy: 0.8436\n",
            "Epoch 207/2000\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.3546 - accuracy: 0.8596 - val_loss: 0.4052 - val_accuracy: 0.8436\n",
            "Epoch 208/2000\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.3489 - accuracy: 0.8610 - val_loss: 0.4156 - val_accuracy: 0.8380\n",
            "Epoch 209/2000\n",
            "23/23 [==============================] - 0s 19ms/step - loss: 0.3611 - accuracy: 0.8553 - val_loss: 0.4162 - val_accuracy: 0.8324\n",
            "Epoch 210/2000\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.3591 - accuracy: 0.8539 - val_loss: 0.4108 - val_accuracy: 0.8380\n",
            "Epoch 211/2000\n",
            "23/23 [==============================] - 0s 15ms/step - loss: 0.3516 - accuracy: 0.8581 - val_loss: 0.4158 - val_accuracy: 0.8324\n",
            "Epoch 212/2000\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 0.3515 - accuracy: 0.8610 - val_loss: 0.4166 - val_accuracy: 0.8436\n",
            "Epoch 213/2000\n",
            "23/23 [==============================] - 0s 14ms/step - loss: 0.3519 - accuracy: 0.8553 - val_loss: 0.4096 - val_accuracy: 0.8380\n",
            "Epoch 214/2000\n",
            "23/23 [==============================] - 0s 19ms/step - loss: 0.3491 - accuracy: 0.8581 - val_loss: 0.4104 - val_accuracy: 0.8324\n",
            "Epoch 215/2000\n",
            "23/23 [==============================] - 0s 14ms/step - loss: 0.3463 - accuracy: 0.8638 - val_loss: 0.4218 - val_accuracy: 0.8436\n",
            "Epoch 216/2000\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 0.3581 - accuracy: 0.8525 - val_loss: 0.4078 - val_accuracy: 0.8212\n",
            "Epoch 217/2000\n",
            "23/23 [==============================] - 0s 14ms/step - loss: 0.3571 - accuracy: 0.8581 - val_loss: 0.4189 - val_accuracy: 0.8436\n",
            "Epoch 218/2000\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 0.3498 - accuracy: 0.8553 - val_loss: 0.4169 - val_accuracy: 0.8436\n",
            "Epoch 219/2000\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 0.3580 - accuracy: 0.8581 - val_loss: 0.4102 - val_accuracy: 0.8324\n",
            "Epoch 220/2000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.3513 - accuracy: 0.8638 - val_loss: 0.4093 - val_accuracy: 0.8380\n",
            "Epoch 221/2000\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.3401 - accuracy: 0.8581 - val_loss: 0.4062 - val_accuracy: 0.8436\n",
            "Epoch 222/2000\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 0.3592 - accuracy: 0.8553 - val_loss: 0.4089 - val_accuracy: 0.8436\n",
            "Epoch 223/2000\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 0.3505 - accuracy: 0.8624 - val_loss: 0.4168 - val_accuracy: 0.8380\n",
            "Epoch 224/2000\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.3537 - accuracy: 0.8610 - val_loss: 0.4160 - val_accuracy: 0.8380\n",
            "Epoch 225/2000\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 0.3454 - accuracy: 0.8596 - val_loss: 0.4134 - val_accuracy: 0.8436\n",
            "Epoch 226/2000\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 0.3446 - accuracy: 0.8610 - val_loss: 0.4221 - val_accuracy: 0.8436\n",
            "Epoch 227/2000\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.3500 - accuracy: 0.8511 - val_loss: 0.4164 - val_accuracy: 0.8268\n",
            "Epoch 228/2000\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.3550 - accuracy: 0.8638 - val_loss: 0.4205 - val_accuracy: 0.8380\n",
            "Epoch 229/2000\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.3500 - accuracy: 0.8666 - val_loss: 0.4250 - val_accuracy: 0.8436\n",
            "Epoch 230/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.3510 - accuracy: 0.8553 - val_loss: 0.4142 - val_accuracy: 0.8324\n",
            "Epoch 231/2000\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 0.3547 - accuracy: 0.8567 - val_loss: 0.4132 - val_accuracy: 0.8436\n",
            "Epoch 232/2000\n",
            "23/23 [==============================] - 0s 13ms/step - loss: 0.3510 - accuracy: 0.8610 - val_loss: 0.4158 - val_accuracy: 0.8436\n",
            "Epoch 233/2000\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 0.3516 - accuracy: 0.8624 - val_loss: 0.4071 - val_accuracy: 0.8436\n",
            "Epoch 234/2000\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.3452 - accuracy: 0.8511 - val_loss: 0.4136 - val_accuracy: 0.8380\n",
            "Epoch 235/2000\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 0.3549 - accuracy: 0.8596 - val_loss: 0.4252 - val_accuracy: 0.8324\n",
            "Epoch 236/2000\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.3499 - accuracy: 0.8455 - val_loss: 0.4227 - val_accuracy: 0.8324\n",
            "Epoch 237/2000\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.3459 - accuracy: 0.8596 - val_loss: 0.4189 - val_accuracy: 0.8380\n",
            "Epoch 238/2000\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.3454 - accuracy: 0.8652 - val_loss: 0.4172 - val_accuracy: 0.8324\n",
            "Epoch 239/2000\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 0.3674 - accuracy: 0.8469 - val_loss: 0.4192 - val_accuracy: 0.8380\n",
            "Epoch 240/2000\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 0.3572 - accuracy: 0.8610 - val_loss: 0.4196 - val_accuracy: 0.8268\n",
            "Epoch 241/2000\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.3552 - accuracy: 0.8581 - val_loss: 0.4208 - val_accuracy: 0.8268\n",
            "Epoch 242/2000\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.3570 - accuracy: 0.8539 - val_loss: 0.4149 - val_accuracy: 0.8380\n",
            "Epoch 243/2000\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.3449 - accuracy: 0.8722 - val_loss: 0.4174 - val_accuracy: 0.8436\n",
            "Epoch 244/2000\n",
            "23/23 [==============================] - 0s 13ms/step - loss: 0.3376 - accuracy: 0.8666 - val_loss: 0.4215 - val_accuracy: 0.8324\n",
            "Epoch 245/2000\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.3479 - accuracy: 0.8624 - val_loss: 0.4296 - val_accuracy: 0.8380\n",
            "Epoch 246/2000\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.3480 - accuracy: 0.8539 - val_loss: 0.4217 - val_accuracy: 0.8324\n",
            "Epoch 247/2000\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.3472 - accuracy: 0.8581 - val_loss: 0.4223 - val_accuracy: 0.8324\n",
            "Epoch 248/2000\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.3394 - accuracy: 0.8567 - val_loss: 0.4187 - val_accuracy: 0.8380\n",
            "Epoch 249/2000\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.3490 - accuracy: 0.8567 - val_loss: 0.4167 - val_accuracy: 0.8324\n",
            "Epoch 250/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.3561 - accuracy: 0.8624 - val_loss: 0.4219 - val_accuracy: 0.8324\n",
            "Epoch 251/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.3482 - accuracy: 0.8497 - val_loss: 0.4214 - val_accuracy: 0.8324\n",
            "Epoch 252/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.3394 - accuracy: 0.8567 - val_loss: 0.4286 - val_accuracy: 0.8268\n",
            "Epoch 253/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.3364 - accuracy: 0.8567 - val_loss: 0.4201 - val_accuracy: 0.8380\n",
            "Epoch 254/2000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.3604 - accuracy: 0.8497 - val_loss: 0.4108 - val_accuracy: 0.8380\n",
            "Epoch 255/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.3476 - accuracy: 0.8680 - val_loss: 0.4212 - val_accuracy: 0.8436\n",
            "Epoch 256/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.3346 - accuracy: 0.8750 - val_loss: 0.4275 - val_accuracy: 0.8380\n",
            "Epoch 257/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.3398 - accuracy: 0.8469 - val_loss: 0.4375 - val_accuracy: 0.8436\n",
            "Epoch 258/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.3660 - accuracy: 0.8567 - val_loss: 0.4209 - val_accuracy: 0.8436\n",
            "Epoch 259/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.3466 - accuracy: 0.8610 - val_loss: 0.4232 - val_accuracy: 0.8324\n",
            "Epoch 260/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.3439 - accuracy: 0.8638 - val_loss: 0.4230 - val_accuracy: 0.8436\n",
            "Epoch 261/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.3499 - accuracy: 0.8581 - val_loss: 0.4184 - val_accuracy: 0.8324\n",
            "Epoch 262/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.3446 - accuracy: 0.8581 - val_loss: 0.4200 - val_accuracy: 0.8436\n",
            "Epoch 263/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.3373 - accuracy: 0.8567 - val_loss: 0.4160 - val_accuracy: 0.8324\n",
            "Epoch 264/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.3574 - accuracy: 0.8539 - val_loss: 0.4205 - val_accuracy: 0.8268\n",
            "Epoch 265/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.3420 - accuracy: 0.8581 - val_loss: 0.4146 - val_accuracy: 0.8268\n",
            "Epoch 266/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.3316 - accuracy: 0.8680 - val_loss: 0.4156 - val_accuracy: 0.8380\n",
            "Epoch 267/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.3526 - accuracy: 0.8596 - val_loss: 0.4256 - val_accuracy: 0.8324\n",
            "Epoch 268/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.3503 - accuracy: 0.8666 - val_loss: 0.4191 - val_accuracy: 0.8380\n",
            "Epoch 269/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.3307 - accuracy: 0.8638 - val_loss: 0.4150 - val_accuracy: 0.8492\n",
            "Epoch 270/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.3453 - accuracy: 0.8511 - val_loss: 0.4138 - val_accuracy: 0.8492\n",
            "Epoch 271/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.3439 - accuracy: 0.8483 - val_loss: 0.4289 - val_accuracy: 0.8268\n",
            "Epoch 272/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.3525 - accuracy: 0.8666 - val_loss: 0.4165 - val_accuracy: 0.8380\n",
            "Epoch 273/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.3428 - accuracy: 0.8596 - val_loss: 0.4208 - val_accuracy: 0.8324\n",
            "Epoch 274/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.3478 - accuracy: 0.8553 - val_loss: 0.4201 - val_accuracy: 0.8436\n",
            "Epoch 275/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.3562 - accuracy: 0.8581 - val_loss: 0.4232 - val_accuracy: 0.8380\n",
            "Epoch 276/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.3352 - accuracy: 0.8680 - val_loss: 0.4266 - val_accuracy: 0.8380\n",
            "Epoch 277/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.3303 - accuracy: 0.8736 - val_loss: 0.4257 - val_accuracy: 0.8324\n",
            "Epoch 278/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.3476 - accuracy: 0.8553 - val_loss: 0.4228 - val_accuracy: 0.8380\n",
            "Epoch 279/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.3335 - accuracy: 0.8624 - val_loss: 0.4172 - val_accuracy: 0.8324\n",
            "Epoch 280/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.3411 - accuracy: 0.8652 - val_loss: 0.4169 - val_accuracy: 0.8436\n",
            "Epoch 281/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.3360 - accuracy: 0.8652 - val_loss: 0.4205 - val_accuracy: 0.8380\n",
            "Epoch 282/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.3330 - accuracy: 0.8596 - val_loss: 0.4117 - val_accuracy: 0.8324\n",
            "Epoch 283/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.3605 - accuracy: 0.8525 - val_loss: 0.4147 - val_accuracy: 0.8324\n",
            "Epoch 284/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.3629 - accuracy: 0.8539 - val_loss: 0.4220 - val_accuracy: 0.8324\n",
            "Epoch 285/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.3491 - accuracy: 0.8483 - val_loss: 0.4172 - val_accuracy: 0.8436\n",
            "Epoch 286/2000\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.3361 - accuracy: 0.8567 - val_loss: 0.4264 - val_accuracy: 0.8380\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "acc = model.history['accuracy']\n",
        "val_acc = model.history['val_accuracy']\n",
        "\n",
        "loss = model.history['loss']\n",
        "val_loss = model.history['val_loss']\n",
        "\n",
        "#실 훈련 epoch으로 바꿔주기!\n",
        "epochs_range = range(286)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 709
        },
        "id": "MuGSq_lzoSZA",
        "outputId": "6a8f9893-10eb-4973-c453-4ce7e1b884a9"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception ignored in: 'zmq.backend.cython.message.Frame.__dealloc__'\n",
            "Traceback (most recent call last):\n",
            "  File \"zmq/backend/cython/checkrc.pxd\", line 13, in zmq.backend.cython.checkrc._check_rc\n",
            "KeyboardInterrupt\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x576 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_df.head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "DQYF1bix7aYu",
        "outputId": "d54862ca-2769-4112-a5f6-4936139f4993"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-6c1872b9-9351-4ff5-a82b-880d8c2c6e19\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Embarked</th>\n",
              "      <th>relatives</th>\n",
              "      <th>Deck</th>\n",
              "      <th>Title</th>\n",
              "      <th>Age_Class</th>\n",
              "      <th>Fare_Per_Person</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>892</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>15</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>893</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>3</td>\n",
              "      <td>18</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>894</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>12</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>895</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>896</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>8</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6c1872b9-9351-4ff5-a82b-880d8c2c6e19')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6c1872b9-9351-4ff5-a82b-880d8c2c6e19 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6c1872b9-9351-4ff5-a82b-880d8c2c6e19');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   PassengerId  Pclass  Sex  Age  ...  Deck  Title  Age_Class  Fare_Per_Person\n",
              "0          892       3    0    5  ...     8      1         15                0\n",
              "1          893       3    1    6  ...     8      3         18                0\n",
              "2          894       2    0    6  ...     8      1         12                2\n",
              "3          895       3    0    3  ...     8      1          9                1\n",
              "4          896       3    1    2  ...     8      3          6                0\n",
              "\n",
              "[5 rows x 12 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test = test_df.drop(['PassengerId'], axis = 1)\n",
        "test.head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "rxf_Nc8J8AKM",
        "outputId": "32fc318f-169c-467c-a8b7-7824787e7104"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-53c2b82d-8fdf-445a-af9b-79c294cc9862\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Embarked</th>\n",
              "      <th>relatives</th>\n",
              "      <th>Deck</th>\n",
              "      <th>Title</th>\n",
              "      <th>Age_Class</th>\n",
              "      <th>Fare_Per_Person</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>15</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>3</td>\n",
              "      <td>18</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>12</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>8</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-53c2b82d-8fdf-445a-af9b-79c294cc9862')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-53c2b82d-8fdf-445a-af9b-79c294cc9862 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-53c2b82d-8fdf-445a-af9b-79c294cc9862');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   Pclass  Sex  Age  SibSp  ...  Deck  Title  Age_Class  Fare_Per_Person\n",
              "0       3    0    5      0  ...     8      1         15                0\n",
              "1       3    1    6      1  ...     8      3         18                0\n",
              "2       2    0    6      0  ...     8      1         12                2\n",
              "3       3    0    3      0  ...     8      1          9                1\n",
              "4       3    1    2      1  ...     8      3          6                0\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prediction = Densemodel.predict(test)\n",
        "\n",
        "test_label = ['Dead', 'Survived']\n",
        "test_label[np.argmax(prediction[0])]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "njWx3iuSoXy1",
        "outputId": "627bdece-46ba-49fa-c956-93710d8be873"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Dead'"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "testlist = []\n",
        "\n",
        "for i in range(418):\n",
        "    print('Passenger No. {} - {} '.format(i+1, test_label[np.argmax(prediction[i])]))\n",
        "    testlist.append(np.argmax(prediction[i]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LtW1J_p-odPd",
        "outputId": "b18d9720-22f8-4e1e-a3fc-7ff3af5ee7eb"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Passenger No. 1 - Dead \n",
            "Passenger No. 2 - Dead \n",
            "Passenger No. 3 - Dead \n",
            "Passenger No. 4 - Dead \n",
            "Passenger No. 5 - Survived \n",
            "Passenger No. 6 - Dead \n",
            "Passenger No. 7 - Dead \n",
            "Passenger No. 8 - Dead \n",
            "Passenger No. 9 - Survived \n",
            "Passenger No. 10 - Dead \n",
            "Passenger No. 11 - Dead \n",
            "Passenger No. 12 - Dead \n",
            "Passenger No. 13 - Survived \n",
            "Passenger No. 14 - Dead \n",
            "Passenger No. 15 - Survived \n",
            "Passenger No. 16 - Survived \n",
            "Passenger No. 17 - Dead \n",
            "Passenger No. 18 - Dead \n",
            "Passenger No. 19 - Dead \n",
            "Passenger No. 20 - Dead \n",
            "Passenger No. 21 - Dead \n",
            "Passenger No. 22 - Survived \n",
            "Passenger No. 23 - Survived \n",
            "Passenger No. 24 - Dead \n",
            "Passenger No. 25 - Survived \n",
            "Passenger No. 26 - Dead \n",
            "Passenger No. 27 - Survived \n",
            "Passenger No. 28 - Dead \n",
            "Passenger No. 29 - Dead \n",
            "Passenger No. 30 - Dead \n",
            "Passenger No. 31 - Dead \n",
            "Passenger No. 32 - Dead \n",
            "Passenger No. 33 - Dead \n",
            "Passenger No. 34 - Dead \n",
            "Passenger No. 35 - Dead \n",
            "Passenger No. 36 - Dead \n",
            "Passenger No. 37 - Dead \n",
            "Passenger No. 38 - Dead \n",
            "Passenger No. 39 - Dead \n",
            "Passenger No. 40 - Survived \n",
            "Passenger No. 41 - Dead \n",
            "Passenger No. 42 - Dead \n",
            "Passenger No. 43 - Dead \n",
            "Passenger No. 44 - Survived \n",
            "Passenger No. 45 - Survived \n",
            "Passenger No. 46 - Dead \n",
            "Passenger No. 47 - Dead \n",
            "Passenger No. 48 - Dead \n",
            "Passenger No. 49 - Survived \n",
            "Passenger No. 50 - Dead \n",
            "Passenger No. 51 - Survived \n",
            "Passenger No. 52 - Dead \n",
            "Passenger No. 53 - Survived \n",
            "Passenger No. 54 - Survived \n",
            "Passenger No. 55 - Dead \n",
            "Passenger No. 56 - Dead \n",
            "Passenger No. 57 - Dead \n",
            "Passenger No. 58 - Dead \n",
            "Passenger No. 59 - Dead \n",
            "Passenger No. 60 - Survived \n",
            "Passenger No. 61 - Dead \n",
            "Passenger No. 62 - Dead \n",
            "Passenger No. 63 - Dead \n",
            "Passenger No. 64 - Dead \n",
            "Passenger No. 65 - Dead \n",
            "Passenger No. 66 - Survived \n",
            "Passenger No. 67 - Survived \n",
            "Passenger No. 68 - Dead \n",
            "Passenger No. 69 - Dead \n",
            "Passenger No. 70 - Survived \n",
            "Passenger No. 71 - Dead \n",
            "Passenger No. 72 - Dead \n",
            "Passenger No. 73 - Dead \n",
            "Passenger No. 74 - Dead \n",
            "Passenger No. 75 - Survived \n",
            "Passenger No. 76 - Survived \n",
            "Passenger No. 77 - Dead \n",
            "Passenger No. 78 - Survived \n",
            "Passenger No. 79 - Dead \n",
            "Passenger No. 80 - Dead \n",
            "Passenger No. 81 - Survived \n",
            "Passenger No. 82 - Dead \n",
            "Passenger No. 83 - Dead \n",
            "Passenger No. 84 - Dead \n",
            "Passenger No. 85 - Dead \n",
            "Passenger No. 86 - Dead \n",
            "Passenger No. 87 - Dead \n",
            "Passenger No. 88 - Dead \n",
            "Passenger No. 89 - Dead \n",
            "Passenger No. 90 - Survived \n",
            "Passenger No. 91 - Survived \n",
            "Passenger No. 92 - Dead \n",
            "Passenger No. 93 - Survived \n",
            "Passenger No. 94 - Dead \n",
            "Passenger No. 95 - Dead \n",
            "Passenger No. 96 - Dead \n",
            "Passenger No. 97 - Survived \n",
            "Passenger No. 98 - Dead \n",
            "Passenger No. 99 - Survived \n",
            "Passenger No. 100 - Dead \n",
            "Passenger No. 101 - Survived \n",
            "Passenger No. 102 - Dead \n",
            "Passenger No. 103 - Dead \n",
            "Passenger No. 104 - Dead \n",
            "Passenger No. 105 - Survived \n",
            "Passenger No. 106 - Dead \n",
            "Passenger No. 107 - Dead \n",
            "Passenger No. 108 - Dead \n",
            "Passenger No. 109 - Dead \n",
            "Passenger No. 110 - Dead \n",
            "Passenger No. 111 - Dead \n",
            "Passenger No. 112 - Dead \n",
            "Passenger No. 113 - Survived \n",
            "Passenger No. 114 - Survived \n",
            "Passenger No. 115 - Survived \n",
            "Passenger No. 116 - Dead \n",
            "Passenger No. 117 - Dead \n",
            "Passenger No. 118 - Survived \n",
            "Passenger No. 119 - Dead \n",
            "Passenger No. 120 - Survived \n",
            "Passenger No. 121 - Survived \n",
            "Passenger No. 122 - Dead \n",
            "Passenger No. 123 - Survived \n",
            "Passenger No. 124 - Dead \n",
            "Passenger No. 125 - Dead \n",
            "Passenger No. 126 - Survived \n",
            "Passenger No. 127 - Dead \n",
            "Passenger No. 128 - Dead \n",
            "Passenger No. 129 - Dead \n",
            "Passenger No. 130 - Dead \n",
            "Passenger No. 131 - Dead \n",
            "Passenger No. 132 - Survived \n",
            "Passenger No. 133 - Dead \n",
            "Passenger No. 134 - Dead \n",
            "Passenger No. 135 - Dead \n",
            "Passenger No. 136 - Dead \n",
            "Passenger No. 137 - Dead \n",
            "Passenger No. 138 - Dead \n",
            "Passenger No. 139 - Dead \n",
            "Passenger No. 140 - Dead \n",
            "Passenger No. 141 - Dead \n",
            "Passenger No. 142 - Survived \n",
            "Passenger No. 143 - Dead \n",
            "Passenger No. 144 - Dead \n",
            "Passenger No. 145 - Dead \n",
            "Passenger No. 146 - Dead \n",
            "Passenger No. 147 - Dead \n",
            "Passenger No. 148 - Dead \n",
            "Passenger No. 149 - Dead \n",
            "Passenger No. 150 - Dead \n",
            "Passenger No. 151 - Survived \n",
            "Passenger No. 152 - Dead \n",
            "Passenger No. 153 - Dead \n",
            "Passenger No. 154 - Dead \n",
            "Passenger No. 155 - Dead \n",
            "Passenger No. 156 - Dead \n",
            "Passenger No. 157 - Survived \n",
            "Passenger No. 158 - Dead \n",
            "Passenger No. 159 - Dead \n",
            "Passenger No. 160 - Survived \n",
            "Passenger No. 161 - Dead \n",
            "Passenger No. 162 - Survived \n",
            "Passenger No. 163 - Survived \n",
            "Passenger No. 164 - Dead \n",
            "Passenger No. 165 - Dead \n",
            "Passenger No. 166 - Survived \n",
            "Passenger No. 167 - Dead \n",
            "Passenger No. 168 - Dead \n",
            "Passenger No. 169 - Survived \n",
            "Passenger No. 170 - Dead \n",
            "Passenger No. 171 - Dead \n",
            "Passenger No. 172 - Dead \n",
            "Passenger No. 173 - Dead \n",
            "Passenger No. 174 - Dead \n",
            "Passenger No. 175 - Dead \n",
            "Passenger No. 176 - Survived \n",
            "Passenger No. 177 - Survived \n",
            "Passenger No. 178 - Survived \n",
            "Passenger No. 179 - Survived \n",
            "Passenger No. 180 - Survived \n",
            "Passenger No. 181 - Dead \n",
            "Passenger No. 182 - Dead \n",
            "Passenger No. 183 - Survived \n",
            "Passenger No. 184 - Dead \n",
            "Passenger No. 185 - Survived \n",
            "Passenger No. 186 - Dead \n",
            "Passenger No. 187 - Survived \n",
            "Passenger No. 188 - Dead \n",
            "Passenger No. 189 - Dead \n",
            "Passenger No. 190 - Dead \n",
            "Passenger No. 191 - Dead \n",
            "Passenger No. 192 - Dead \n",
            "Passenger No. 193 - Survived \n",
            "Passenger No. 194 - Dead \n",
            "Passenger No. 195 - Survived \n",
            "Passenger No. 196 - Dead \n",
            "Passenger No. 197 - Survived \n",
            "Passenger No. 198 - Survived \n",
            "Passenger No. 199 - Dead \n",
            "Passenger No. 200 - Survived \n",
            "Passenger No. 201 - Survived \n",
            "Passenger No. 202 - Survived \n",
            "Passenger No. 203 - Dead \n",
            "Passenger No. 204 - Survived \n",
            "Passenger No. 205 - Dead \n",
            "Passenger No. 206 - Dead \n",
            "Passenger No. 207 - Dead \n",
            "Passenger No. 208 - Dead \n",
            "Passenger No. 209 - Survived \n",
            "Passenger No. 210 - Dead \n",
            "Passenger No. 211 - Dead \n",
            "Passenger No. 212 - Dead \n",
            "Passenger No. 213 - Dead \n",
            "Passenger No. 214 - Survived \n",
            "Passenger No. 215 - Dead \n",
            "Passenger No. 216 - Dead \n",
            "Passenger No. 217 - Dead \n",
            "Passenger No. 218 - Dead \n",
            "Passenger No. 219 - Survived \n",
            "Passenger No. 220 - Dead \n",
            "Passenger No. 221 - Survived \n",
            "Passenger No. 222 - Dead \n",
            "Passenger No. 223 - Survived \n",
            "Passenger No. 224 - Dead \n",
            "Passenger No. 225 - Survived \n",
            "Passenger No. 226 - Survived \n",
            "Passenger No. 227 - Dead \n",
            "Passenger No. 228 - Dead \n",
            "Passenger No. 229 - Dead \n",
            "Passenger No. 230 - Dead \n",
            "Passenger No. 231 - Dead \n",
            "Passenger No. 232 - Survived \n",
            "Passenger No. 233 - Dead \n",
            "Passenger No. 234 - Dead \n",
            "Passenger No. 235 - Survived \n",
            "Passenger No. 236 - Dead \n",
            "Passenger No. 237 - Dead \n",
            "Passenger No. 238 - Dead \n",
            "Passenger No. 239 - Survived \n",
            "Passenger No. 240 - Survived \n",
            "Passenger No. 241 - Survived \n",
            "Passenger No. 242 - Survived \n",
            "Passenger No. 243 - Dead \n",
            "Passenger No. 244 - Dead \n",
            "Passenger No. 245 - Dead \n",
            "Passenger No. 246 - Dead \n",
            "Passenger No. 247 - Survived \n",
            "Passenger No. 248 - Dead \n",
            "Passenger No. 249 - Survived \n",
            "Passenger No. 250 - Survived \n",
            "Passenger No. 251 - Survived \n",
            "Passenger No. 252 - Dead \n",
            "Passenger No. 253 - Survived \n",
            "Passenger No. 254 - Dead \n",
            "Passenger No. 255 - Dead \n",
            "Passenger No. 256 - Dead \n",
            "Passenger No. 257 - Dead \n",
            "Passenger No. 258 - Dead \n",
            "Passenger No. 259 - Survived \n",
            "Passenger No. 260 - Dead \n",
            "Passenger No. 261 - Dead \n",
            "Passenger No. 262 - Dead \n",
            "Passenger No. 263 - Survived \n",
            "Passenger No. 264 - Survived \n",
            "Passenger No. 265 - Dead \n",
            "Passenger No. 266 - Dead \n",
            "Passenger No. 267 - Dead \n",
            "Passenger No. 268 - Dead \n",
            "Passenger No. 269 - Dead \n",
            "Passenger No. 270 - Dead \n",
            "Passenger No. 271 - Dead \n",
            "Passenger No. 272 - Dead \n",
            "Passenger No. 273 - Survived \n",
            "Passenger No. 274 - Survived \n",
            "Passenger No. 275 - Dead \n",
            "Passenger No. 276 - Survived \n",
            "Passenger No. 277 - Dead \n",
            "Passenger No. 278 - Dead \n",
            "Passenger No. 279 - Dead \n",
            "Passenger No. 280 - Dead \n",
            "Passenger No. 281 - Dead \n",
            "Passenger No. 282 - Survived \n",
            "Passenger No. 283 - Dead \n",
            "Passenger No. 284 - Survived \n",
            "Passenger No. 285 - Survived \n",
            "Passenger No. 286 - Dead \n",
            "Passenger No. 287 - Dead \n",
            "Passenger No. 288 - Survived \n",
            "Passenger No. 289 - Dead \n",
            "Passenger No. 290 - Dead \n",
            "Passenger No. 291 - Dead \n",
            "Passenger No. 292 - Dead \n",
            "Passenger No. 293 - Dead \n",
            "Passenger No. 294 - Dead \n",
            "Passenger No. 295 - Dead \n",
            "Passenger No. 296 - Dead \n",
            "Passenger No. 297 - Survived \n",
            "Passenger No. 298 - Dead \n",
            "Passenger No. 299 - Dead \n",
            "Passenger No. 300 - Dead \n",
            "Passenger No. 301 - Dead \n",
            "Passenger No. 302 - Dead \n",
            "Passenger No. 303 - Dead \n",
            "Passenger No. 304 - Dead \n",
            "Passenger No. 305 - Dead \n",
            "Passenger No. 306 - Survived \n",
            "Passenger No. 307 - Dead \n",
            "Passenger No. 308 - Survived \n",
            "Passenger No. 309 - Dead \n",
            "Passenger No. 310 - Dead \n",
            "Passenger No. 311 - Dead \n",
            "Passenger No. 312 - Dead \n",
            "Passenger No. 313 - Dead \n",
            "Passenger No. 314 - Dead \n",
            "Passenger No. 315 - Survived \n",
            "Passenger No. 316 - Survived \n",
            "Passenger No. 317 - Dead \n",
            "Passenger No. 318 - Dead \n",
            "Passenger No. 319 - Dead \n",
            "Passenger No. 320 - Dead \n",
            "Passenger No. 321 - Dead \n",
            "Passenger No. 322 - Dead \n",
            "Passenger No. 323 - Dead \n",
            "Passenger No. 324 - Dead \n",
            "Passenger No. 325 - Survived \n",
            "Passenger No. 326 - Dead \n",
            "Passenger No. 327 - Survived \n",
            "Passenger No. 328 - Dead \n",
            "Passenger No. 329 - Dead \n",
            "Passenger No. 330 - Dead \n",
            "Passenger No. 331 - Survived \n",
            "Passenger No. 332 - Dead \n",
            "Passenger No. 333 - Dead \n",
            "Passenger No. 334 - Survived \n",
            "Passenger No. 335 - Dead \n",
            "Passenger No. 336 - Dead \n",
            "Passenger No. 337 - Dead \n",
            "Passenger No. 338 - Dead \n",
            "Passenger No. 339 - Dead \n",
            "Passenger No. 340 - Dead \n",
            "Passenger No. 341 - Dead \n",
            "Passenger No. 342 - Dead \n",
            "Passenger No. 343 - Dead \n",
            "Passenger No. 344 - Survived \n",
            "Passenger No. 345 - Dead \n",
            "Passenger No. 346 - Survived \n",
            "Passenger No. 347 - Dead \n",
            "Passenger No. 348 - Dead \n",
            "Passenger No. 349 - Dead \n",
            "Passenger No. 350 - Survived \n",
            "Passenger No. 351 - Survived \n",
            "Passenger No. 352 - Dead \n",
            "Passenger No. 353 - Dead \n",
            "Passenger No. 354 - Dead \n",
            "Passenger No. 355 - Survived \n",
            "Passenger No. 356 - Dead \n",
            "Passenger No. 357 - Survived \n",
            "Passenger No. 358 - Dead \n",
            "Passenger No. 359 - Dead \n",
            "Passenger No. 360 - Survived \n",
            "Passenger No. 361 - Dead \n",
            "Passenger No. 362 - Survived \n",
            "Passenger No. 363 - Survived \n",
            "Passenger No. 364 - Dead \n",
            "Passenger No. 365 - Survived \n",
            "Passenger No. 366 - Dead \n",
            "Passenger No. 367 - Dead \n",
            "Passenger No. 368 - Dead \n",
            "Passenger No. 369 - Survived \n",
            "Passenger No. 370 - Dead \n",
            "Passenger No. 371 - Dead \n",
            "Passenger No. 372 - Survived \n",
            "Passenger No. 373 - Dead \n",
            "Passenger No. 374 - Dead \n",
            "Passenger No. 375 - Survived \n",
            "Passenger No. 376 - Survived \n",
            "Passenger No. 377 - Dead \n",
            "Passenger No. 378 - Dead \n",
            "Passenger No. 379 - Dead \n",
            "Passenger No. 380 - Dead \n",
            "Passenger No. 381 - Dead \n",
            "Passenger No. 382 - Dead \n",
            "Passenger No. 383 - Survived \n",
            "Passenger No. 384 - Survived \n",
            "Passenger No. 385 - Dead \n",
            "Passenger No. 386 - Survived \n",
            "Passenger No. 387 - Dead \n",
            "Passenger No. 388 - Dead \n",
            "Passenger No. 389 - Dead \n",
            "Passenger No. 390 - Dead \n",
            "Passenger No. 391 - Survived \n",
            "Passenger No. 392 - Survived \n",
            "Passenger No. 393 - Survived \n",
            "Passenger No. 394 - Dead \n",
            "Passenger No. 395 - Dead \n",
            "Passenger No. 396 - Survived \n",
            "Passenger No. 397 - Dead \n",
            "Passenger No. 398 - Survived \n",
            "Passenger No. 399 - Dead \n",
            "Passenger No. 400 - Dead \n",
            "Passenger No. 401 - Survived \n",
            "Passenger No. 402 - Dead \n",
            "Passenger No. 403 - Survived \n",
            "Passenger No. 404 - Dead \n",
            "Passenger No. 405 - Dead \n",
            "Passenger No. 406 - Dead \n",
            "Passenger No. 407 - Dead \n",
            "Passenger No. 408 - Dead \n",
            "Passenger No. 409 - Dead \n",
            "Passenger No. 410 - Survived \n",
            "Passenger No. 411 - Dead \n",
            "Passenger No. 412 - Survived \n",
            "Passenger No. 413 - Dead \n",
            "Passenger No. 414 - Dead \n",
            "Passenger No. 415 - Survived \n",
            "Passenger No. 416 - Dead \n",
            "Passenger No. 417 - Dead \n",
            "Passenger No. 418 - Dead \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output = pd.DataFrame({'PassengerID': test_df['PassengerId'].values.tolist(), 'Survived': testlist})\n",
        "output.to_csv('submission_Dense3.csv', index = False)"
      ],
      "metadata": {
        "id": "KNtnLJtpog-c"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "HyperParameter Tuning"
      ],
      "metadata": {
        "id": "rvKD6lQeIrc6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers\n",
        "from keras_tuner.tuners import RandomSearch"
      ],
      "metadata": {
        "id": "ulnF4ZbcBjqN"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(mi):\n",
        "  model = tf.keras.Sequential()\n",
        "  for i in range(mi.Int('num_layers', 2, 20)):\n",
        "    model.add(layers.Dense(units = mi.Int('units_' + str(i),\n",
        "                                          min_value = 16,\n",
        "                                          max_value = 512,\n",
        "                                          step = 16),\n",
        "                           activation = 'relu'))\n",
        "    model.add(layers.Dropout(mi.Choice('dropoutprob_', [0.1, 0.2, 0.3, 0.4, 0.5])))\n",
        "  model.add(layers.Dense(2, activation = 'softmax'))\n",
        "  model.compile(\n",
        "      optimizer = tf.keras.optimizers.Adam(mi.Choice('learning_rate', [1e-2, 1e-3, 1e-4, 1e-5, 1e-6])),\n",
        "      loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
        "      metrics = ['accuracy']\n",
        "  )\n",
        "  return model"
      ],
      "metadata": {
        "id": "2C3jzFwbB4ku"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tuner = RandomSearch(\n",
        "    build_model,\n",
        "    objective = 'val_accuracy',\n",
        "    max_trials = 5,\n",
        "    executions_per_trial = 3,\n",
        "    directory = 'project2',\n",
        "    project_name = 'Titanic2'\n",
        ")"
      ],
      "metadata": {
        "id": "Idrak55EDj62"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tuner.search_space_summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vQqANIu5Endl",
        "outputId": "ad091599-c22c-4fe4-8e6f-9ff03e1e64eb"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Search space summary\n",
            "Default search space size: 5\n",
            "num_layers (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 2, 'max_value': 20, 'step': 1, 'sampling': None}\n",
            "units_0 (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 16, 'max_value': 512, 'step': 16, 'sampling': None}\n",
            "dropoutprob_ (Choice)\n",
            "{'default': 0.1, 'conditions': [], 'values': [0.1, 0.2, 0.3, 0.4, 0.5], 'ordered': True}\n",
            "units_1 (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 16, 'max_value': 512, 'step': 16, 'sampling': None}\n",
            "learning_rate (Choice)\n",
            "{'default': 0.01, 'conditions': [], 'values': [0.01, 0.001, 0.0001, 1e-05, 1e-06], 'ordered': True}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tuner.search(X_train, Y_train, epochs = 200, validation_data = (X_val, Y_val))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q_hkumWGGjHT",
        "outputId": "8ce2e7e8-72a4-40d3-e6d0-1735ddd26545"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 5 Complete [00h 03m 28s]\n",
            "val_accuracy: 0.858472983042399\n",
            "\n",
            "Best val_accuracy So Far: 0.858472983042399\n",
            "Total elapsed time: 00h 17m 25s\n",
            "INFO:tensorflow:Oracle triggered exit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tuner.results_summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CAEperP9JhZE",
        "outputId": "fdac5e62-ba15-40f3-c1bd-928a5112b10e"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results summary\n",
            "Results in project2/Titanic2\n",
            "Showing 10 best trials\n",
            "Objective(name='val_accuracy', direction='max')\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "num_layers: 19\n",
            "units_0: 432\n",
            "dropoutprob_: 0.4\n",
            "units_1: 224\n",
            "learning_rate: 0.001\n",
            "units_2: 192\n",
            "units_3: 288\n",
            "units_4: 80\n",
            "units_5: 272\n",
            "units_6: 272\n",
            "units_7: 368\n",
            "units_8: 128\n",
            "units_9: 416\n",
            "units_10: 48\n",
            "units_11: 512\n",
            "units_12: 352\n",
            "units_13: 512\n",
            "units_14: 288\n",
            "units_15: 432\n",
            "units_16: 192\n",
            "units_17: 16\n",
            "units_18: 16\n",
            "Score: 0.858472983042399\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "num_layers: 8\n",
            "units_0: 336\n",
            "dropoutprob_: 0.3\n",
            "units_1: 288\n",
            "learning_rate: 0.0001\n",
            "units_2: 16\n",
            "units_3: 16\n",
            "units_4: 16\n",
            "units_5: 16\n",
            "units_6: 16\n",
            "units_7: 16\n",
            "Score: 0.8454376061757406\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "num_layers: 6\n",
            "units_0: 112\n",
            "dropoutprob_: 0.1\n",
            "units_1: 96\n",
            "learning_rate: 1e-06\n",
            "units_2: 304\n",
            "units_3: 160\n",
            "units_4: 320\n",
            "units_5: 224\n",
            "units_6: 288\n",
            "units_7: 272\n",
            "Score: 0.6759776473045349\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "num_layers: 13\n",
            "units_0: 112\n",
            "dropoutprob_: 0.5\n",
            "units_1: 448\n",
            "learning_rate: 1e-06\n",
            "units_2: 336\n",
            "units_3: 48\n",
            "units_4: 64\n",
            "units_5: 208\n",
            "units_6: 432\n",
            "units_7: 16\n",
            "units_8: 16\n",
            "units_9: 16\n",
            "units_10: 16\n",
            "units_11: 16\n",
            "units_12: 16\n",
            "Score: 0.6312849322954813\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "num_layers: 17\n",
            "units_0: 304\n",
            "dropoutprob_: 0.5\n",
            "units_1: 224\n",
            "learning_rate: 0.0001\n",
            "units_2: 144\n",
            "units_3: 128\n",
            "units_4: 496\n",
            "units_5: 272\n",
            "units_6: 304\n",
            "units_7: 80\n",
            "units_8: 432\n",
            "units_9: 304\n",
            "units_10: 304\n",
            "units_11: 160\n",
            "units_12: 208\n",
            "units_13: 16\n",
            "units_14: 16\n",
            "units_15: 16\n",
            "units_16: 16\n",
            "Score: 0.5865921974182129\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "가장 정확도가 높은 trial은 19개의 레이어가 있어 너무 많으므로, 그 다음으로 좋은 trial 사용하기!\n",
        "\n",
        "Trial summary\n",
        "\n",
        "Hyperparameters:\n",
        "\n",
        "num_layers: 8\n",
        "\n",
        "units_0: 336\n",
        "\n",
        "dropoutprob_: 0.3\n",
        "\n",
        "units_1: 288\n",
        "\n",
        "learning_rate: 0.0001\n",
        "\n",
        "units_2: 16\n",
        "\n",
        "units_3: 16\n",
        "\n",
        "units_4: 16\n",
        "\n",
        "units_5: 16\n",
        "\n",
        "units_6: 16\n",
        "\n",
        "units_7: 16\n",
        "\n",
        "Score: 0.8454376061757406"
      ],
      "metadata": {
        "id": "MQ3ZYNJXOu3q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Tunedmodel = tf.keras.models.Sequential([\n",
        "    \n",
        "    tf.keras.layers.Dense(336, input_shape = ((train_df.shape[1] - 1), ), activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.3),\n",
        "    tf.keras.layers.Dense(288, activation = 'relu'),\n",
        "    tf.keras.layers.Dropout(0.3),\n",
        "    tf.keras.layers.Dense(16, activation = 'relu'),\n",
        "    tf.keras.layers.Dropout(0.3),\n",
        "    tf.keras.layers.Dense(16, activation = 'relu'),\n",
        "    tf.keras.layers.Dropout(0.3),\n",
        "    tf.keras.layers.Dense(16, activation = 'relu'),\n",
        "    tf.keras.layers.Dropout(0.3),\n",
        "    tf.keras.layers.Dense(16, activation = 'relu'),\n",
        "    tf.keras.layers.Dropout(0.3),\n",
        "    tf.keras.layers.Dense(16, activation = 'relu'),\n",
        "    tf.keras.layers.Dropout(0.3),\n",
        "    tf.keras.layers.Dense(16, activation = 'relu'),\n",
        "    tf.keras.layers.Dropout(0.3),\n",
        "    tf.keras.layers.Dense(2, activation = 'softmax')\n",
        "    \n",
        "])"
      ],
      "metadata": {
        "id": "X16rETBqO-kB"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Tunedmodel.compile(\n",
        "      optimizer = tf.keras.optimizers.Adam(learning_rate = 0.0001),\n",
        "      loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
        "      metrics = ['accuracy']\n",
        "  )"
      ],
      "metadata": {
        "id": "87GJ24OePibx"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 2000\n",
        "\n",
        "model_checkpoint = keras.callbacks.ModelCheckpoint(\n",
        "\"my_checkpoint.h5\", save_best_only = True)\n",
        "\n",
        "early_stopping = keras.callbacks.EarlyStopping(patience = 200)\n",
        "\n",
        "Tunedhistory = Tunedmodel.fit(X_train, Y_train, validation_data = (X_val, Y_val),\n",
        "               epochs = EPOCHS,\n",
        "               callbacks = [model_checkpoint, early_stopping])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L3GyYzKSP6NR",
        "outputId": "4a33cd30-6d84-408a-abc7-0277db1306cd"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2000\n",
            "23/23 [==============================] - 1s 21ms/step - loss: 0.7471 - accuracy: 0.5534 - val_loss: 0.6759 - val_accuracy: 0.5866\n",
            "Epoch 2/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.7019 - accuracy: 0.5435 - val_loss: 0.6809 - val_accuracy: 0.5866\n",
            "Epoch 3/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.6987 - accuracy: 0.5309 - val_loss: 0.6833 - val_accuracy: 0.5866\n",
            "Epoch 4/2000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.6907 - accuracy: 0.5295 - val_loss: 0.6795 - val_accuracy: 0.5866\n",
            "Epoch 5/2000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.6835 - accuracy: 0.5604 - val_loss: 0.6777 - val_accuracy: 0.5866\n",
            "Epoch 6/2000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.6775 - accuracy: 0.5393 - val_loss: 0.6810 - val_accuracy: 0.5866\n",
            "Epoch 7/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.6717 - accuracy: 0.5758 - val_loss: 0.6761 - val_accuracy: 0.5866\n",
            "Epoch 8/2000\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.6855 - accuracy: 0.5478 - val_loss: 0.6692 - val_accuracy: 0.5866\n",
            "Epoch 9/2000\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.6646 - accuracy: 0.5927 - val_loss: 0.6641 - val_accuracy: 0.5866\n",
            "Epoch 10/2000\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.6722 - accuracy: 0.5829 - val_loss: 0.6575 - val_accuracy: 0.5866\n",
            "Epoch 11/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.6726 - accuracy: 0.5815 - val_loss: 0.6639 - val_accuracy: 0.5866\n",
            "Epoch 12/2000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.6592 - accuracy: 0.5730 - val_loss: 0.6636 - val_accuracy: 0.5866\n",
            "Epoch 13/2000\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 0.6667 - accuracy: 0.5913 - val_loss: 0.6563 - val_accuracy: 0.5866\n",
            "Epoch 14/2000\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.6561 - accuracy: 0.5913 - val_loss: 0.6515 - val_accuracy: 0.5866\n",
            "Epoch 15/2000\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.6758 - accuracy: 0.5716 - val_loss: 0.6500 - val_accuracy: 0.5866\n",
            "Epoch 16/2000\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.6469 - accuracy: 0.6011 - val_loss: 0.6438 - val_accuracy: 0.5866\n",
            "Epoch 17/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.6698 - accuracy: 0.5716 - val_loss: 0.6440 - val_accuracy: 0.5866\n",
            "Epoch 18/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.6690 - accuracy: 0.5899 - val_loss: 0.6445 - val_accuracy: 0.5866\n",
            "Epoch 19/2000\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.6585 - accuracy: 0.5829 - val_loss: 0.6431 - val_accuracy: 0.5866\n",
            "Epoch 20/2000\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.6478 - accuracy: 0.5969 - val_loss: 0.6387 - val_accuracy: 0.5866\n",
            "Epoch 21/2000\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.6336 - accuracy: 0.6053 - val_loss: 0.6321 - val_accuracy: 0.5866\n",
            "Epoch 22/2000\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.6423 - accuracy: 0.6025 - val_loss: 0.6258 - val_accuracy: 0.5866\n",
            "Epoch 23/2000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.6453 - accuracy: 0.6011 - val_loss: 0.6312 - val_accuracy: 0.5866\n",
            "Epoch 24/2000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.6275 - accuracy: 0.6025 - val_loss: 0.6260 - val_accuracy: 0.5866\n",
            "Epoch 25/2000\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.6325 - accuracy: 0.6081 - val_loss: 0.6197 - val_accuracy: 0.5866\n",
            "Epoch 26/2000\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.6332 - accuracy: 0.6124 - val_loss: 0.6090 - val_accuracy: 0.5866\n",
            "Epoch 27/2000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.6432 - accuracy: 0.5969 - val_loss: 0.6147 - val_accuracy: 0.5866\n",
            "Epoch 28/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.6315 - accuracy: 0.5969 - val_loss: 0.6173 - val_accuracy: 0.5866\n",
            "Epoch 29/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.6352 - accuracy: 0.6039 - val_loss: 0.6224 - val_accuracy: 0.5866\n",
            "Epoch 30/2000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.6378 - accuracy: 0.6081 - val_loss: 0.6197 - val_accuracy: 0.5866\n",
            "Epoch 31/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.6329 - accuracy: 0.5983 - val_loss: 0.6175 - val_accuracy: 0.5866\n",
            "Epoch 32/2000\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.6180 - accuracy: 0.6138 - val_loss: 0.6022 - val_accuracy: 0.5866\n",
            "Epoch 33/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.6516 - accuracy: 0.6067 - val_loss: 0.6174 - val_accuracy: 0.5866\n",
            "Epoch 34/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.6384 - accuracy: 0.6152 - val_loss: 0.6180 - val_accuracy: 0.5866\n",
            "Epoch 35/2000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.6264 - accuracy: 0.6124 - val_loss: 0.6125 - val_accuracy: 0.5866\n",
            "Epoch 36/2000\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.6187 - accuracy: 0.6096 - val_loss: 0.5982 - val_accuracy: 0.5866\n",
            "Epoch 37/2000\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.6306 - accuracy: 0.6110 - val_loss: 0.5942 - val_accuracy: 0.5866\n",
            "Epoch 38/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.6378 - accuracy: 0.6124 - val_loss: 0.5956 - val_accuracy: 0.5866\n",
            "Epoch 39/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.6223 - accuracy: 0.6081 - val_loss: 0.6020 - val_accuracy: 0.5866\n",
            "Epoch 40/2000\n",
            "23/23 [==============================] - 1s 29ms/step - loss: 0.6042 - accuracy: 0.6081 - val_loss: 0.5815 - val_accuracy: 0.5866\n",
            "Epoch 41/2000\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 0.6352 - accuracy: 0.6081 - val_loss: 0.5890 - val_accuracy: 0.5866\n",
            "Epoch 42/2000\n",
            "23/23 [==============================] - 0s 14ms/step - loss: 0.6082 - accuracy: 0.6152 - val_loss: 0.5966 - val_accuracy: 0.5866\n",
            "Epoch 43/2000\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.6277 - accuracy: 0.6138 - val_loss: 0.6081 - val_accuracy: 0.5866\n",
            "Epoch 44/2000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.6162 - accuracy: 0.6166 - val_loss: 0.5977 - val_accuracy: 0.5866\n",
            "Epoch 45/2000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.6205 - accuracy: 0.6138 - val_loss: 0.5966 - val_accuracy: 0.5866\n",
            "Epoch 46/2000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.6159 - accuracy: 0.6180 - val_loss: 0.5855 - val_accuracy: 0.5866\n",
            "Epoch 47/2000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.6282 - accuracy: 0.6138 - val_loss: 0.6029 - val_accuracy: 0.5866\n",
            "Epoch 48/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.6270 - accuracy: 0.6152 - val_loss: 0.6065 - val_accuracy: 0.5866\n",
            "Epoch 49/2000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.6054 - accuracy: 0.6152 - val_loss: 0.5848 - val_accuracy: 0.5866\n",
            "Epoch 50/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.6225 - accuracy: 0.6138 - val_loss: 0.5936 - val_accuracy: 0.5866\n",
            "Epoch 51/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.6061 - accuracy: 0.6180 - val_loss: 0.5871 - val_accuracy: 0.5866\n",
            "Epoch 52/2000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.6005 - accuracy: 0.6180 - val_loss: 0.5876 - val_accuracy: 0.5866\n",
            "Epoch 53/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.6066 - accuracy: 0.6096 - val_loss: 0.5878 - val_accuracy: 0.5866\n",
            "Epoch 54/2000\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.6067 - accuracy: 0.6222 - val_loss: 0.5787 - val_accuracy: 0.5866\n",
            "Epoch 55/2000\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 0.5934 - accuracy: 0.6166 - val_loss: 0.5698 - val_accuracy: 0.5866\n",
            "Epoch 56/2000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.6202 - accuracy: 0.6208 - val_loss: 0.5778 - val_accuracy: 0.5866\n",
            "Epoch 57/2000\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.5946 - accuracy: 0.6194 - val_loss: 0.5658 - val_accuracy: 0.5866\n",
            "Epoch 58/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.6032 - accuracy: 0.6166 - val_loss: 0.5660 - val_accuracy: 0.5866\n",
            "Epoch 59/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.5928 - accuracy: 0.6194 - val_loss: 0.5717 - val_accuracy: 0.5866\n",
            "Epoch 60/2000\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.5964 - accuracy: 0.6180 - val_loss: 0.5616 - val_accuracy: 0.5866\n",
            "Epoch 61/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.6034 - accuracy: 0.6180 - val_loss: 0.5742 - val_accuracy: 0.5866\n",
            "Epoch 62/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.5999 - accuracy: 0.6194 - val_loss: 0.5718 - val_accuracy: 0.5866\n",
            "Epoch 63/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.5943 - accuracy: 0.6194 - val_loss: 0.5694 - val_accuracy: 0.5866\n",
            "Epoch 64/2000\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.5789 - accuracy: 0.6180 - val_loss: 0.5598 - val_accuracy: 0.5866\n",
            "Epoch 65/2000\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.5965 - accuracy: 0.6180 - val_loss: 0.5477 - val_accuracy: 0.5866\n",
            "Epoch 66/2000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.5986 - accuracy: 0.6166 - val_loss: 0.5580 - val_accuracy: 0.5866\n",
            "Epoch 67/2000\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.5752 - accuracy: 0.6180 - val_loss: 0.5304 - val_accuracy: 0.5866\n",
            "Epoch 68/2000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.5906 - accuracy: 0.6194 - val_loss: 0.5416 - val_accuracy: 0.5866\n",
            "Epoch 69/2000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.5817 - accuracy: 0.6208 - val_loss: 0.5620 - val_accuracy: 0.5866\n",
            "Epoch 70/2000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.5743 - accuracy: 0.6250 - val_loss: 0.5505 - val_accuracy: 0.5866\n",
            "Epoch 71/2000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.5740 - accuracy: 0.6208 - val_loss: 0.5538 - val_accuracy: 0.5866\n",
            "Epoch 72/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.5746 - accuracy: 0.6208 - val_loss: 0.5435 - val_accuracy: 0.5866\n",
            "Epoch 73/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.5828 - accuracy: 0.6194 - val_loss: 0.5433 - val_accuracy: 0.5866\n",
            "Epoch 74/2000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.5979 - accuracy: 0.6194 - val_loss: 0.5672 - val_accuracy: 0.5866\n",
            "Epoch 75/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.5987 - accuracy: 0.6194 - val_loss: 0.5579 - val_accuracy: 0.5866\n",
            "Epoch 76/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.5664 - accuracy: 0.6194 - val_loss: 0.5479 - val_accuracy: 0.5866\n",
            "Epoch 77/2000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.6004 - accuracy: 0.6222 - val_loss: 0.5627 - val_accuracy: 0.5866\n",
            "Epoch 78/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.5918 - accuracy: 0.6222 - val_loss: 0.5658 - val_accuracy: 0.5866\n",
            "Epoch 79/2000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.5879 - accuracy: 0.6222 - val_loss: 0.5572 - val_accuracy: 0.5866\n",
            "Epoch 80/2000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.5900 - accuracy: 0.6166 - val_loss: 0.5551 - val_accuracy: 0.5866\n",
            "Epoch 81/2000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.5737 - accuracy: 0.6236 - val_loss: 0.5610 - val_accuracy: 0.5866\n",
            "Epoch 82/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.5604 - accuracy: 0.6236 - val_loss: 0.5428 - val_accuracy: 0.5866\n",
            "Epoch 83/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.5885 - accuracy: 0.6194 - val_loss: 0.5733 - val_accuracy: 0.5866\n",
            "Epoch 84/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.5711 - accuracy: 0.6194 - val_loss: 0.5707 - val_accuracy: 0.5866\n",
            "Epoch 85/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.5648 - accuracy: 0.6236 - val_loss: 0.5478 - val_accuracy: 0.5866\n",
            "Epoch 86/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.5565 - accuracy: 0.6194 - val_loss: 0.5428 - val_accuracy: 0.5866\n",
            "Epoch 87/2000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.5891 - accuracy: 0.6208 - val_loss: 0.5497 - val_accuracy: 0.5866\n",
            "Epoch 88/2000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.5663 - accuracy: 0.6194 - val_loss: 0.5445 - val_accuracy: 0.5866\n",
            "Epoch 89/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.6070 - accuracy: 0.6222 - val_loss: 0.5567 - val_accuracy: 0.5866\n",
            "Epoch 90/2000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.6022 - accuracy: 0.6236 - val_loss: 0.5562 - val_accuracy: 0.5866\n",
            "Epoch 91/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.5794 - accuracy: 0.6208 - val_loss: 0.5503 - val_accuracy: 0.5866\n",
            "Epoch 92/2000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.5603 - accuracy: 0.6222 - val_loss: 0.5440 - val_accuracy: 0.5866\n",
            "Epoch 93/2000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.5694 - accuracy: 0.6208 - val_loss: 0.5430 - val_accuracy: 0.5866\n",
            "Epoch 94/2000\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.5603 - accuracy: 0.6152 - val_loss: 0.5292 - val_accuracy: 0.5866\n",
            "Epoch 95/2000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.5697 - accuracy: 0.6222 - val_loss: 0.5296 - val_accuracy: 0.5866\n",
            "Epoch 96/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.5547 - accuracy: 0.6180 - val_loss: 0.5410 - val_accuracy: 0.5866\n",
            "Epoch 97/2000\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 0.5413 - accuracy: 0.6208 - val_loss: 0.5263 - val_accuracy: 0.5866\n",
            "Epoch 98/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.5811 - accuracy: 0.6222 - val_loss: 0.5448 - val_accuracy: 0.5866\n",
            "Epoch 99/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.5836 - accuracy: 0.6222 - val_loss: 0.5521 - val_accuracy: 0.5866\n",
            "Epoch 100/2000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.5491 - accuracy: 0.6236 - val_loss: 0.5417 - val_accuracy: 0.5866\n",
            "Epoch 101/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.5692 - accuracy: 0.6236 - val_loss: 0.5480 - val_accuracy: 0.5866\n",
            "Epoch 102/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.5703 - accuracy: 0.6208 - val_loss: 0.5438 - val_accuracy: 0.5866\n",
            "Epoch 103/2000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.5374 - accuracy: 0.6587 - val_loss: 0.5327 - val_accuracy: 0.5866\n",
            "Epoch 104/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.5671 - accuracy: 0.7093 - val_loss: 0.5304 - val_accuracy: 0.8101\n",
            "Epoch 105/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.5645 - accuracy: 0.7317 - val_loss: 0.5403 - val_accuracy: 0.8268\n",
            "Epoch 106/2000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.5659 - accuracy: 0.7135 - val_loss: 0.5428 - val_accuracy: 0.8268\n",
            "Epoch 107/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.5880 - accuracy: 0.7556 - val_loss: 0.5526 - val_accuracy: 0.8324\n",
            "Epoch 108/2000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.5660 - accuracy: 0.7317 - val_loss: 0.5435 - val_accuracy: 0.8156\n",
            "Epoch 109/2000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.5868 - accuracy: 0.7247 - val_loss: 0.5465 - val_accuracy: 0.8101\n",
            "Epoch 110/2000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.5889 - accuracy: 0.7275 - val_loss: 0.5450 - val_accuracy: 0.8156\n",
            "Epoch 111/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.5605 - accuracy: 0.7388 - val_loss: 0.5473 - val_accuracy: 0.8212\n",
            "Epoch 112/2000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.5597 - accuracy: 0.7360 - val_loss: 0.5452 - val_accuracy: 0.8101\n",
            "Epoch 113/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.5676 - accuracy: 0.7472 - val_loss: 0.5420 - val_accuracy: 0.8045\n",
            "Epoch 114/2000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.5507 - accuracy: 0.7346 - val_loss: 0.5428 - val_accuracy: 0.8045\n",
            "Epoch 115/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.5766 - accuracy: 0.7458 - val_loss: 0.5478 - val_accuracy: 0.8156\n",
            "Epoch 116/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.5560 - accuracy: 0.7570 - val_loss: 0.5327 - val_accuracy: 0.8045\n",
            "Epoch 117/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.5466 - accuracy: 0.7388 - val_loss: 0.5388 - val_accuracy: 0.8156\n",
            "Epoch 118/2000\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.5481 - accuracy: 0.7626 - val_loss: 0.5262 - val_accuracy: 0.8156\n",
            "Epoch 119/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.5500 - accuracy: 0.7542 - val_loss: 0.5276 - val_accuracy: 0.8156\n",
            "Epoch 120/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.5741 - accuracy: 0.7767 - val_loss: 0.5312 - val_accuracy: 0.8268\n",
            "Epoch 121/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.5708 - accuracy: 0.7626 - val_loss: 0.5548 - val_accuracy: 0.8156\n",
            "Epoch 122/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.5684 - accuracy: 0.7683 - val_loss: 0.5399 - val_accuracy: 0.8101\n",
            "Epoch 123/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.5405 - accuracy: 0.7935 - val_loss: 0.5307 - val_accuracy: 0.8101\n",
            "Epoch 124/2000\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.5509 - accuracy: 0.7879 - val_loss: 0.5234 - val_accuracy: 0.8101\n",
            "Epoch 125/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.5518 - accuracy: 0.7893 - val_loss: 0.5415 - val_accuracy: 0.8045\n",
            "Epoch 126/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.5525 - accuracy: 0.7823 - val_loss: 0.5319 - val_accuracy: 0.8156\n",
            "Epoch 127/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.5425 - accuracy: 0.7978 - val_loss: 0.5253 - val_accuracy: 0.8101\n",
            "Epoch 128/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.5448 - accuracy: 0.8118 - val_loss: 0.5234 - val_accuracy: 0.8045\n",
            "Epoch 129/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.5517 - accuracy: 0.7978 - val_loss: 0.5282 - val_accuracy: 0.7989\n",
            "Epoch 130/2000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.5487 - accuracy: 0.7921 - val_loss: 0.5294 - val_accuracy: 0.8045\n",
            "Epoch 131/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.5555 - accuracy: 0.7851 - val_loss: 0.5462 - val_accuracy: 0.7933\n",
            "Epoch 132/2000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.5355 - accuracy: 0.8118 - val_loss: 0.5371 - val_accuracy: 0.8045\n",
            "Epoch 133/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.5598 - accuracy: 0.7921 - val_loss: 0.5464 - val_accuracy: 0.7989\n",
            "Epoch 134/2000\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.5703 - accuracy: 0.7865 - val_loss: 0.5459 - val_accuracy: 0.8156\n",
            "Epoch 135/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.5529 - accuracy: 0.7907 - val_loss: 0.5487 - val_accuracy: 0.8156\n",
            "Epoch 136/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.5670 - accuracy: 0.7949 - val_loss: 0.5526 - val_accuracy: 0.8156\n",
            "Epoch 137/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.5436 - accuracy: 0.8006 - val_loss: 0.5412 - val_accuracy: 0.8268\n",
            "Epoch 138/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.5392 - accuracy: 0.7795 - val_loss: 0.5264 - val_accuracy: 0.8045\n",
            "Epoch 139/2000\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.5833 - accuracy: 0.7935 - val_loss: 0.5418 - val_accuracy: 0.8101\n",
            "Epoch 140/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.5314 - accuracy: 0.7992 - val_loss: 0.5330 - val_accuracy: 0.8268\n",
            "Epoch 141/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.5505 - accuracy: 0.7992 - val_loss: 0.5335 - val_accuracy: 0.8212\n",
            "Epoch 142/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.5529 - accuracy: 0.7935 - val_loss: 0.5341 - val_accuracy: 0.8101\n",
            "Epoch 143/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.5490 - accuracy: 0.8020 - val_loss: 0.5377 - val_accuracy: 0.8101\n",
            "Epoch 144/2000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.5659 - accuracy: 0.7851 - val_loss: 0.5380 - val_accuracy: 0.8156\n",
            "Epoch 145/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.5457 - accuracy: 0.7963 - val_loss: 0.5310 - val_accuracy: 0.8101\n",
            "Epoch 146/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.5353 - accuracy: 0.7978 - val_loss: 0.5344 - val_accuracy: 0.7989\n",
            "Epoch 147/2000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.5375 - accuracy: 0.7992 - val_loss: 0.5283 - val_accuracy: 0.7933\n",
            "Epoch 148/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.5567 - accuracy: 0.7949 - val_loss: 0.5282 - val_accuracy: 0.8045\n",
            "Epoch 149/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.5518 - accuracy: 0.8090 - val_loss: 0.5338 - val_accuracy: 0.8101\n",
            "Epoch 150/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.5475 - accuracy: 0.7795 - val_loss: 0.5356 - val_accuracy: 0.8101\n",
            "Epoch 151/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.5476 - accuracy: 0.7963 - val_loss: 0.5345 - val_accuracy: 0.8101\n",
            "Epoch 152/2000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.5464 - accuracy: 0.7935 - val_loss: 0.5337 - val_accuracy: 0.8156\n",
            "Epoch 153/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.5249 - accuracy: 0.7935 - val_loss: 0.5307 - val_accuracy: 0.8045\n",
            "Epoch 154/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.5460 - accuracy: 0.8118 - val_loss: 0.5291 - val_accuracy: 0.7933\n",
            "Epoch 155/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.5410 - accuracy: 0.8118 - val_loss: 0.5362 - val_accuracy: 0.7989\n",
            "Epoch 156/2000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.5194 - accuracy: 0.7935 - val_loss: 0.5270 - val_accuracy: 0.8212\n",
            "Epoch 157/2000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.5297 - accuracy: 0.8104 - val_loss: 0.5245 - val_accuracy: 0.7989\n",
            "Epoch 158/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.5528 - accuracy: 0.7823 - val_loss: 0.5294 - val_accuracy: 0.7989\n",
            "Epoch 159/2000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.5210 - accuracy: 0.7949 - val_loss: 0.5277 - val_accuracy: 0.8156\n",
            "Epoch 160/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.5627 - accuracy: 0.8020 - val_loss: 0.5331 - val_accuracy: 0.7989\n",
            "Epoch 161/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.5500 - accuracy: 0.7963 - val_loss: 0.5279 - val_accuracy: 0.8045\n",
            "Epoch 162/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.5534 - accuracy: 0.8090 - val_loss: 0.5272 - val_accuracy: 0.7933\n",
            "Epoch 163/2000\n",
            "23/23 [==============================] - 0s 13ms/step - loss: 0.5277 - accuracy: 0.8062 - val_loss: 0.5204 - val_accuracy: 0.8156\n",
            "Epoch 164/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.5465 - accuracy: 0.7963 - val_loss: 0.5333 - val_accuracy: 0.7989\n",
            "Epoch 165/2000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.5185 - accuracy: 0.7879 - val_loss: 0.5435 - val_accuracy: 0.8156\n",
            "Epoch 166/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.5191 - accuracy: 0.8048 - val_loss: 0.5262 - val_accuracy: 0.7933\n",
            "Epoch 167/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.5470 - accuracy: 0.8160 - val_loss: 0.5318 - val_accuracy: 0.7989\n",
            "Epoch 168/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.5288 - accuracy: 0.7963 - val_loss: 0.5314 - val_accuracy: 0.7933\n",
            "Epoch 169/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.5400 - accuracy: 0.8132 - val_loss: 0.5269 - val_accuracy: 0.7933\n",
            "Epoch 170/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.5431 - accuracy: 0.8090 - val_loss: 0.5241 - val_accuracy: 0.7933\n",
            "Epoch 171/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.5301 - accuracy: 0.7992 - val_loss: 0.5332 - val_accuracy: 0.7933\n",
            "Epoch 172/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.5292 - accuracy: 0.7992 - val_loss: 0.5266 - val_accuracy: 0.7989\n",
            "Epoch 173/2000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.5289 - accuracy: 0.7978 - val_loss: 0.5212 - val_accuracy: 0.8045\n",
            "Epoch 174/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.5547 - accuracy: 0.8146 - val_loss: 0.5274 - val_accuracy: 0.8045\n",
            "Epoch 175/2000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.5123 - accuracy: 0.7992 - val_loss: 0.5256 - val_accuracy: 0.7989\n",
            "Epoch 176/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.5361 - accuracy: 0.7893 - val_loss: 0.5331 - val_accuracy: 0.8101\n",
            "Epoch 177/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.5324 - accuracy: 0.7978 - val_loss: 0.5311 - val_accuracy: 0.8101\n",
            "Epoch 178/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.5546 - accuracy: 0.7879 - val_loss: 0.5335 - val_accuracy: 0.8045\n",
            "Epoch 179/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.5438 - accuracy: 0.7963 - val_loss: 0.5266 - val_accuracy: 0.8101\n",
            "Epoch 180/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.5305 - accuracy: 0.8020 - val_loss: 0.5268 - val_accuracy: 0.8045\n",
            "Epoch 181/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.5576 - accuracy: 0.8034 - val_loss: 0.5303 - val_accuracy: 0.7989\n",
            "Epoch 182/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.5276 - accuracy: 0.7992 - val_loss: 0.5353 - val_accuracy: 0.7933\n",
            "Epoch 183/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.5205 - accuracy: 0.7963 - val_loss: 0.5262 - val_accuracy: 0.7989\n",
            "Epoch 184/2000\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.5333 - accuracy: 0.8006 - val_loss: 0.5228 - val_accuracy: 0.7989\n",
            "Epoch 185/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.5239 - accuracy: 0.8020 - val_loss: 0.5252 - val_accuracy: 0.7989\n",
            "Epoch 186/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.5331 - accuracy: 0.7992 - val_loss: 0.5285 - val_accuracy: 0.7989\n",
            "Epoch 187/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.5349 - accuracy: 0.8104 - val_loss: 0.5267 - val_accuracy: 0.8045\n",
            "Epoch 188/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.5410 - accuracy: 0.8160 - val_loss: 0.5321 - val_accuracy: 0.8101\n",
            "Epoch 189/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.5236 - accuracy: 0.8062 - val_loss: 0.5225 - val_accuracy: 0.7989\n",
            "Epoch 190/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.5324 - accuracy: 0.8076 - val_loss: 0.5287 - val_accuracy: 0.7989\n",
            "Epoch 191/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.5445 - accuracy: 0.7992 - val_loss: 0.5360 - val_accuracy: 0.8045\n",
            "Epoch 192/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.5228 - accuracy: 0.7992 - val_loss: 0.5311 - val_accuracy: 0.8156\n",
            "Epoch 193/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.5182 - accuracy: 0.7921 - val_loss: 0.5303 - val_accuracy: 0.7989\n",
            "Epoch 194/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.5138 - accuracy: 0.8118 - val_loss: 0.5279 - val_accuracy: 0.7933\n",
            "Epoch 195/2000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.5354 - accuracy: 0.8062 - val_loss: 0.5358 - val_accuracy: 0.7989\n",
            "Epoch 196/2000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.5336 - accuracy: 0.8034 - val_loss: 0.5279 - val_accuracy: 0.7989\n",
            "Epoch 197/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.5334 - accuracy: 0.8146 - val_loss: 0.5312 - val_accuracy: 0.8045\n",
            "Epoch 198/2000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.5431 - accuracy: 0.8090 - val_loss: 0.5324 - val_accuracy: 0.8045\n",
            "Epoch 199/2000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.5104 - accuracy: 0.8202 - val_loss: 0.5344 - val_accuracy: 0.8156\n",
            "Epoch 200/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.5396 - accuracy: 0.7992 - val_loss: 0.5245 - val_accuracy: 0.8156\n",
            "Epoch 201/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.5494 - accuracy: 0.8020 - val_loss: 0.5387 - val_accuracy: 0.8045\n",
            "Epoch 202/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.5021 - accuracy: 0.8104 - val_loss: 0.5288 - val_accuracy: 0.8268\n",
            "Epoch 203/2000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.5391 - accuracy: 0.8160 - val_loss: 0.5313 - val_accuracy: 0.8045\n",
            "Epoch 204/2000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.5517 - accuracy: 0.8006 - val_loss: 0.5413 - val_accuracy: 0.8101\n",
            "Epoch 205/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.5612 - accuracy: 0.7978 - val_loss: 0.5494 - val_accuracy: 0.8045\n",
            "Epoch 206/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.5181 - accuracy: 0.8118 - val_loss: 0.5449 - val_accuracy: 0.7933\n",
            "Epoch 207/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.5071 - accuracy: 0.7963 - val_loss: 0.5334 - val_accuracy: 0.8045\n",
            "Epoch 208/2000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.5271 - accuracy: 0.8020 - val_loss: 0.5394 - val_accuracy: 0.8101\n",
            "Epoch 209/2000\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.5359 - accuracy: 0.7935 - val_loss: 0.5368 - val_accuracy: 0.8101\n",
            "Epoch 210/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.5250 - accuracy: 0.7978 - val_loss: 0.5391 - val_accuracy: 0.8101\n",
            "Epoch 211/2000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.5182 - accuracy: 0.8118 - val_loss: 0.5369 - val_accuracy: 0.8212\n",
            "Epoch 212/2000\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.5347 - accuracy: 0.7978 - val_loss: 0.5345 - val_accuracy: 0.8268\n",
            "Epoch 213/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.5134 - accuracy: 0.8202 - val_loss: 0.5250 - val_accuracy: 0.8101\n",
            "Epoch 214/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.5054 - accuracy: 0.8202 - val_loss: 0.5209 - val_accuracy: 0.8045\n",
            "Epoch 215/2000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.5119 - accuracy: 0.8090 - val_loss: 0.5239 - val_accuracy: 0.8101\n",
            "Epoch 216/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.5478 - accuracy: 0.7921 - val_loss: 0.5349 - val_accuracy: 0.8156\n",
            "Epoch 217/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.5343 - accuracy: 0.8062 - val_loss: 0.5391 - val_accuracy: 0.8268\n",
            "Epoch 218/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.5207 - accuracy: 0.7949 - val_loss: 0.5299 - val_accuracy: 0.8324\n",
            "Epoch 219/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.5311 - accuracy: 0.8076 - val_loss: 0.5281 - val_accuracy: 0.8212\n",
            "Epoch 220/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.5243 - accuracy: 0.8020 - val_loss: 0.5264 - val_accuracy: 0.8268\n",
            "Epoch 221/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.5224 - accuracy: 0.8048 - val_loss: 0.5221 - val_accuracy: 0.8268\n",
            "Epoch 222/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.5442 - accuracy: 0.8090 - val_loss: 0.5364 - val_accuracy: 0.8212\n",
            "Epoch 223/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.5044 - accuracy: 0.8202 - val_loss: 0.5222 - val_accuracy: 0.8101\n",
            "Epoch 224/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.5291 - accuracy: 0.7992 - val_loss: 0.5252 - val_accuracy: 0.8268\n",
            "Epoch 225/2000\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.5155 - accuracy: 0.8174 - val_loss: 0.5292 - val_accuracy: 0.8156\n",
            "Epoch 226/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.5145 - accuracy: 0.7963 - val_loss: 0.5223 - val_accuracy: 0.8212\n",
            "Epoch 227/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.5278 - accuracy: 0.8118 - val_loss: 0.5240 - val_accuracy: 0.8212\n",
            "Epoch 228/2000\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.4847 - accuracy: 0.8202 - val_loss: 0.5149 - val_accuracy: 0.8212\n",
            "Epoch 229/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.5260 - accuracy: 0.8216 - val_loss: 0.5176 - val_accuracy: 0.8324\n",
            "Epoch 230/2000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.5368 - accuracy: 0.8118 - val_loss: 0.5155 - val_accuracy: 0.8380\n",
            "Epoch 231/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.5158 - accuracy: 0.8188 - val_loss: 0.5188 - val_accuracy: 0.8380\n",
            "Epoch 232/2000\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.5105 - accuracy: 0.8160 - val_loss: 0.5213 - val_accuracy: 0.8380\n",
            "Epoch 233/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.5504 - accuracy: 0.8090 - val_loss: 0.5287 - val_accuracy: 0.8156\n",
            "Epoch 234/2000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.5215 - accuracy: 0.8020 - val_loss: 0.5286 - val_accuracy: 0.8212\n",
            "Epoch 235/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.5181 - accuracy: 0.8132 - val_loss: 0.5369 - val_accuracy: 0.8156\n",
            "Epoch 236/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.5222 - accuracy: 0.8020 - val_loss: 0.5378 - val_accuracy: 0.8268\n",
            "Epoch 237/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.5363 - accuracy: 0.8048 - val_loss: 0.5311 - val_accuracy: 0.8268\n",
            "Epoch 238/2000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.5190 - accuracy: 0.7949 - val_loss: 0.5342 - val_accuracy: 0.8212\n",
            "Epoch 239/2000\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.5228 - accuracy: 0.7978 - val_loss: 0.5237 - val_accuracy: 0.8212\n",
            "Epoch 240/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.5222 - accuracy: 0.7992 - val_loss: 0.5321 - val_accuracy: 0.8101\n",
            "Epoch 241/2000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.5161 - accuracy: 0.8090 - val_loss: 0.5264 - val_accuracy: 0.8101\n",
            "Epoch 242/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.5275 - accuracy: 0.7963 - val_loss: 0.5357 - val_accuracy: 0.8212\n",
            "Epoch 243/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.5378 - accuracy: 0.7935 - val_loss: 0.5411 - val_accuracy: 0.8212\n",
            "Epoch 244/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.5363 - accuracy: 0.8006 - val_loss: 0.5331 - val_accuracy: 0.8212\n",
            "Epoch 245/2000\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.5271 - accuracy: 0.8062 - val_loss: 0.5348 - val_accuracy: 0.8212\n",
            "Epoch 246/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.5263 - accuracy: 0.8118 - val_loss: 0.5377 - val_accuracy: 0.8268\n",
            "Epoch 247/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.5185 - accuracy: 0.8132 - val_loss: 0.5406 - val_accuracy: 0.8268\n",
            "Epoch 248/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.4986 - accuracy: 0.8090 - val_loss: 0.5334 - val_accuracy: 0.8212\n",
            "Epoch 249/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.5002 - accuracy: 0.8090 - val_loss: 0.5292 - val_accuracy: 0.8101\n",
            "Epoch 250/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.5149 - accuracy: 0.8118 - val_loss: 0.5290 - val_accuracy: 0.8101\n",
            "Epoch 251/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.5128 - accuracy: 0.8020 - val_loss: 0.5429 - val_accuracy: 0.8156\n",
            "Epoch 252/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.5305 - accuracy: 0.8160 - val_loss: 0.5302 - val_accuracy: 0.8156\n",
            "Epoch 253/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.5219 - accuracy: 0.8076 - val_loss: 0.5363 - val_accuracy: 0.8156\n",
            "Epoch 254/2000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.5056 - accuracy: 0.8048 - val_loss: 0.5321 - val_accuracy: 0.8045\n",
            "Epoch 255/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.4978 - accuracy: 0.8160 - val_loss: 0.5259 - val_accuracy: 0.8045\n",
            "Epoch 256/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.5163 - accuracy: 0.7879 - val_loss: 0.5264 - val_accuracy: 0.8268\n",
            "Epoch 257/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.5046 - accuracy: 0.8034 - val_loss: 0.5335 - val_accuracy: 0.8268\n",
            "Epoch 258/2000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.5093 - accuracy: 0.8146 - val_loss: 0.5327 - val_accuracy: 0.8268\n",
            "Epoch 259/2000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.5054 - accuracy: 0.8076 - val_loss: 0.5349 - val_accuracy: 0.8268\n",
            "Epoch 260/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.5338 - accuracy: 0.7963 - val_loss: 0.5382 - val_accuracy: 0.8268\n",
            "Epoch 261/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.5172 - accuracy: 0.8118 - val_loss: 0.5378 - val_accuracy: 0.8268\n",
            "Epoch 262/2000\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.5106 - accuracy: 0.8202 - val_loss: 0.5302 - val_accuracy: 0.8212\n",
            "Epoch 263/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.5065 - accuracy: 0.7893 - val_loss: 0.5329 - val_accuracy: 0.8156\n",
            "Epoch 264/2000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.5311 - accuracy: 0.8090 - val_loss: 0.5413 - val_accuracy: 0.8268\n",
            "Epoch 265/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.4899 - accuracy: 0.8132 - val_loss: 0.5349 - val_accuracy: 0.8324\n",
            "Epoch 266/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.5081 - accuracy: 0.8118 - val_loss: 0.5308 - val_accuracy: 0.8156\n",
            "Epoch 267/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.4956 - accuracy: 0.8034 - val_loss: 0.5274 - val_accuracy: 0.8324\n",
            "Epoch 268/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.5235 - accuracy: 0.8160 - val_loss: 0.5323 - val_accuracy: 0.8324\n",
            "Epoch 269/2000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.5175 - accuracy: 0.8020 - val_loss: 0.5341 - val_accuracy: 0.8268\n",
            "Epoch 270/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.5354 - accuracy: 0.7907 - val_loss: 0.5400 - val_accuracy: 0.8212\n",
            "Epoch 271/2000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.5050 - accuracy: 0.8048 - val_loss: 0.5319 - val_accuracy: 0.8268\n",
            "Epoch 272/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.5051 - accuracy: 0.8020 - val_loss: 0.5221 - val_accuracy: 0.8268\n",
            "Epoch 273/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.5059 - accuracy: 0.8104 - val_loss: 0.5351 - val_accuracy: 0.8324\n",
            "Epoch 274/2000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.5075 - accuracy: 0.8048 - val_loss: 0.5330 - val_accuracy: 0.8156\n",
            "Epoch 275/2000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.5047 - accuracy: 0.8188 - val_loss: 0.5355 - val_accuracy: 0.8324\n",
            "Epoch 276/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.4916 - accuracy: 0.8146 - val_loss: 0.5409 - val_accuracy: 0.8212\n",
            "Epoch 277/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.4960 - accuracy: 0.8020 - val_loss: 0.5356 - val_accuracy: 0.8212\n",
            "Epoch 278/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.4776 - accuracy: 0.8090 - val_loss: 0.5241 - val_accuracy: 0.8268\n",
            "Epoch 279/2000\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.5021 - accuracy: 0.8118 - val_loss: 0.5299 - val_accuracy: 0.8268\n",
            "Epoch 280/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.5117 - accuracy: 0.8104 - val_loss: 0.5449 - val_accuracy: 0.8212\n",
            "Epoch 281/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.5092 - accuracy: 0.8076 - val_loss: 0.5401 - val_accuracy: 0.8212\n",
            "Epoch 282/2000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.5097 - accuracy: 0.8034 - val_loss: 0.5361 - val_accuracy: 0.8212\n",
            "Epoch 283/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.4924 - accuracy: 0.8216 - val_loss: 0.5330 - val_accuracy: 0.8268\n",
            "Epoch 284/2000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.4975 - accuracy: 0.8216 - val_loss: 0.5345 - val_accuracy: 0.8212\n",
            "Epoch 285/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.4879 - accuracy: 0.8202 - val_loss: 0.5259 - val_accuracy: 0.8156\n",
            "Epoch 286/2000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.5051 - accuracy: 0.8287 - val_loss: 0.5327 - val_accuracy: 0.8156\n",
            "Epoch 287/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.5156 - accuracy: 0.8076 - val_loss: 0.5542 - val_accuracy: 0.8212\n",
            "Epoch 288/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.5069 - accuracy: 0.8076 - val_loss: 0.5358 - val_accuracy: 0.8156\n",
            "Epoch 289/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.4940 - accuracy: 0.7963 - val_loss: 0.5335 - val_accuracy: 0.8324\n",
            "Epoch 290/2000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.5204 - accuracy: 0.8076 - val_loss: 0.5288 - val_accuracy: 0.8268\n",
            "Epoch 291/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.5135 - accuracy: 0.8118 - val_loss: 0.5344 - val_accuracy: 0.8268\n",
            "Epoch 292/2000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.5114 - accuracy: 0.8272 - val_loss: 0.5405 - val_accuracy: 0.8212\n",
            "Epoch 293/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.4881 - accuracy: 0.8048 - val_loss: 0.5287 - val_accuracy: 0.8268\n",
            "Epoch 294/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.4775 - accuracy: 0.8034 - val_loss: 0.5236 - val_accuracy: 0.8268\n",
            "Epoch 295/2000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.4937 - accuracy: 0.8160 - val_loss: 0.5235 - val_accuracy: 0.8212\n",
            "Epoch 296/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.5018 - accuracy: 0.8006 - val_loss: 0.5304 - val_accuracy: 0.8268\n",
            "Epoch 297/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.4913 - accuracy: 0.8188 - val_loss: 0.5270 - val_accuracy: 0.8212\n",
            "Epoch 298/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.5110 - accuracy: 0.8230 - val_loss: 0.5263 - val_accuracy: 0.8212\n",
            "Epoch 299/2000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.5184 - accuracy: 0.7992 - val_loss: 0.5274 - val_accuracy: 0.8268\n",
            "Epoch 300/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.4863 - accuracy: 0.8048 - val_loss: 0.5239 - val_accuracy: 0.8212\n",
            "Epoch 301/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.5183 - accuracy: 0.8076 - val_loss: 0.5260 - val_accuracy: 0.8212\n",
            "Epoch 302/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.4992 - accuracy: 0.8216 - val_loss: 0.5271 - val_accuracy: 0.8212\n",
            "Epoch 303/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.5157 - accuracy: 0.8062 - val_loss: 0.5308 - val_accuracy: 0.8212\n",
            "Epoch 304/2000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.4995 - accuracy: 0.8104 - val_loss: 0.5292 - val_accuracy: 0.8212\n",
            "Epoch 305/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.5021 - accuracy: 0.8160 - val_loss: 0.5329 - val_accuracy: 0.8212\n",
            "Epoch 306/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.4735 - accuracy: 0.8160 - val_loss: 0.5223 - val_accuracy: 0.8156\n",
            "Epoch 307/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.4946 - accuracy: 0.8146 - val_loss: 0.5280 - val_accuracy: 0.8212\n",
            "Epoch 308/2000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.4957 - accuracy: 0.7992 - val_loss: 0.5218 - val_accuracy: 0.8212\n",
            "Epoch 309/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.4951 - accuracy: 0.8104 - val_loss: 0.5244 - val_accuracy: 0.8212\n",
            "Epoch 310/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.4934 - accuracy: 0.8230 - val_loss: 0.5209 - val_accuracy: 0.8268\n",
            "Epoch 311/2000\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.5101 - accuracy: 0.8048 - val_loss: 0.5351 - val_accuracy: 0.8212\n",
            "Epoch 312/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.4926 - accuracy: 0.8132 - val_loss: 0.5458 - val_accuracy: 0.8156\n",
            "Epoch 313/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.4956 - accuracy: 0.8006 - val_loss: 0.5249 - val_accuracy: 0.8212\n",
            "Epoch 314/2000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.5146 - accuracy: 0.8076 - val_loss: 0.5246 - val_accuracy: 0.8212\n",
            "Epoch 315/2000\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.4811 - accuracy: 0.8020 - val_loss: 0.5113 - val_accuracy: 0.8268\n",
            "Epoch 316/2000\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 0.4653 - accuracy: 0.8287 - val_loss: 0.5110 - val_accuracy: 0.8268\n",
            "Epoch 317/2000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.5230 - accuracy: 0.8104 - val_loss: 0.5388 - val_accuracy: 0.8268\n",
            "Epoch 318/2000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.4809 - accuracy: 0.8034 - val_loss: 0.5283 - val_accuracy: 0.8268\n",
            "Epoch 319/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.5125 - accuracy: 0.8062 - val_loss: 0.5269 - val_accuracy: 0.8212\n",
            "Epoch 320/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.5019 - accuracy: 0.8076 - val_loss: 0.5388 - val_accuracy: 0.8212\n",
            "Epoch 321/2000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.5218 - accuracy: 0.8174 - val_loss: 0.5355 - val_accuracy: 0.8212\n",
            "Epoch 322/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.4997 - accuracy: 0.8188 - val_loss: 0.5279 - val_accuracy: 0.8268\n",
            "Epoch 323/2000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.4956 - accuracy: 0.8118 - val_loss: 0.5161 - val_accuracy: 0.8324\n",
            "Epoch 324/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.5009 - accuracy: 0.8188 - val_loss: 0.5188 - val_accuracy: 0.8324\n",
            "Epoch 325/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.5226 - accuracy: 0.7992 - val_loss: 0.5291 - val_accuracy: 0.8268\n",
            "Epoch 326/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.5295 - accuracy: 0.8062 - val_loss: 0.5257 - val_accuracy: 0.8268\n",
            "Epoch 327/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.4982 - accuracy: 0.8006 - val_loss: 0.5260 - val_accuracy: 0.8268\n",
            "Epoch 328/2000\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.5026 - accuracy: 0.8034 - val_loss: 0.5240 - val_accuracy: 0.8324\n",
            "Epoch 329/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.5041 - accuracy: 0.8287 - val_loss: 0.5210 - val_accuracy: 0.8268\n",
            "Epoch 330/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.5184 - accuracy: 0.8146 - val_loss: 0.5181 - val_accuracy: 0.8268\n",
            "Epoch 331/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.4887 - accuracy: 0.8385 - val_loss: 0.5271 - val_accuracy: 0.8268\n",
            "Epoch 332/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.4927 - accuracy: 0.8132 - val_loss: 0.5275 - val_accuracy: 0.8268\n",
            "Epoch 333/2000\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.5047 - accuracy: 0.8076 - val_loss: 0.5306 - val_accuracy: 0.8212\n",
            "Epoch 334/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.5055 - accuracy: 0.7935 - val_loss: 0.5420 - val_accuracy: 0.8156\n",
            "Epoch 335/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.5108 - accuracy: 0.8020 - val_loss: 0.5365 - val_accuracy: 0.8212\n",
            "Epoch 336/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.4894 - accuracy: 0.8244 - val_loss: 0.5331 - val_accuracy: 0.8268\n",
            "Epoch 337/2000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.4818 - accuracy: 0.8258 - val_loss: 0.5230 - val_accuracy: 0.8212\n",
            "Epoch 338/2000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.4980 - accuracy: 0.8174 - val_loss: 0.5209 - val_accuracy: 0.8156\n",
            "Epoch 339/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.5063 - accuracy: 0.7978 - val_loss: 0.5299 - val_accuracy: 0.8268\n",
            "Epoch 340/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.5076 - accuracy: 0.8244 - val_loss: 0.5243 - val_accuracy: 0.8101\n",
            "Epoch 341/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.4874 - accuracy: 0.8104 - val_loss: 0.5359 - val_accuracy: 0.8156\n",
            "Epoch 342/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.4983 - accuracy: 0.8160 - val_loss: 0.5268 - val_accuracy: 0.8212\n",
            "Epoch 343/2000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.4931 - accuracy: 0.8062 - val_loss: 0.5296 - val_accuracy: 0.8212\n",
            "Epoch 344/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.4932 - accuracy: 0.8188 - val_loss: 0.5370 - val_accuracy: 0.8212\n",
            "Epoch 345/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.4888 - accuracy: 0.8287 - val_loss: 0.5251 - val_accuracy: 0.8212\n",
            "Epoch 346/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.4838 - accuracy: 0.8216 - val_loss: 0.5188 - val_accuracy: 0.8212\n",
            "Epoch 347/2000\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.5196 - accuracy: 0.8062 - val_loss: 0.5361 - val_accuracy: 0.8268\n",
            "Epoch 348/2000\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.4740 - accuracy: 0.8216 - val_loss: 0.5285 - val_accuracy: 0.8212\n",
            "Epoch 349/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.4851 - accuracy: 0.8160 - val_loss: 0.5253 - val_accuracy: 0.8212\n",
            "Epoch 350/2000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.4897 - accuracy: 0.8216 - val_loss: 0.5188 - val_accuracy: 0.8212\n",
            "Epoch 351/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.5010 - accuracy: 0.8230 - val_loss: 0.5202 - val_accuracy: 0.8324\n",
            "Epoch 352/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.4876 - accuracy: 0.8160 - val_loss: 0.5339 - val_accuracy: 0.8268\n",
            "Epoch 353/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.5178 - accuracy: 0.8048 - val_loss: 0.5402 - val_accuracy: 0.8212\n",
            "Epoch 354/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.4984 - accuracy: 0.8118 - val_loss: 0.5338 - val_accuracy: 0.8324\n",
            "Epoch 355/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.5039 - accuracy: 0.8034 - val_loss: 0.5320 - val_accuracy: 0.8324\n",
            "Epoch 356/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.4723 - accuracy: 0.8202 - val_loss: 0.5311 - val_accuracy: 0.8324\n",
            "Epoch 357/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.4881 - accuracy: 0.8104 - val_loss: 0.5235 - val_accuracy: 0.8268\n",
            "Epoch 358/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.5290 - accuracy: 0.7978 - val_loss: 0.5306 - val_accuracy: 0.8324\n",
            "Epoch 359/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.5068 - accuracy: 0.8048 - val_loss: 0.5404 - val_accuracy: 0.8324\n",
            "Epoch 360/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.4751 - accuracy: 0.8258 - val_loss: 0.5433 - val_accuracy: 0.8268\n",
            "Epoch 361/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.5037 - accuracy: 0.8076 - val_loss: 0.5383 - val_accuracy: 0.8324\n",
            "Epoch 362/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.4939 - accuracy: 0.8216 - val_loss: 0.5305 - val_accuracy: 0.8324\n",
            "Epoch 363/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.4704 - accuracy: 0.8146 - val_loss: 0.5181 - val_accuracy: 0.8212\n",
            "Epoch 364/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.4695 - accuracy: 0.8343 - val_loss: 0.5203 - val_accuracy: 0.8212\n",
            "Epoch 365/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.4879 - accuracy: 0.8216 - val_loss: 0.5328 - val_accuracy: 0.8324\n",
            "Epoch 366/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.4954 - accuracy: 0.8230 - val_loss: 0.5382 - val_accuracy: 0.8212\n",
            "Epoch 367/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.5089 - accuracy: 0.8202 - val_loss: 0.5424 - val_accuracy: 0.8268\n",
            "Epoch 368/2000\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.5001 - accuracy: 0.8090 - val_loss: 0.5398 - val_accuracy: 0.8268\n",
            "Epoch 369/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.4640 - accuracy: 0.8258 - val_loss: 0.5318 - val_accuracy: 0.8156\n",
            "Epoch 370/2000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.4842 - accuracy: 0.8090 - val_loss: 0.5287 - val_accuracy: 0.8212\n",
            "Epoch 371/2000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.4899 - accuracy: 0.8230 - val_loss: 0.5254 - val_accuracy: 0.8212\n",
            "Epoch 372/2000\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.4743 - accuracy: 0.8160 - val_loss: 0.5344 - val_accuracy: 0.8268\n",
            "Epoch 373/2000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.5007 - accuracy: 0.8104 - val_loss: 0.5303 - val_accuracy: 0.8268\n",
            "Epoch 374/2000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.4819 - accuracy: 0.8258 - val_loss: 0.5319 - val_accuracy: 0.8268\n",
            "Epoch 375/2000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.5107 - accuracy: 0.7949 - val_loss: 0.5389 - val_accuracy: 0.8212\n",
            "Epoch 376/2000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.4897 - accuracy: 0.8202 - val_loss: 0.5375 - val_accuracy: 0.8212\n",
            "Epoch 377/2000\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.4858 - accuracy: 0.8104 - val_loss: 0.5351 - val_accuracy: 0.8212\n",
            "Epoch 378/2000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.4927 - accuracy: 0.8048 - val_loss: 0.5372 - val_accuracy: 0.8268\n",
            "Epoch 379/2000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.4811 - accuracy: 0.8272 - val_loss: 0.5328 - val_accuracy: 0.8212\n",
            "Epoch 380/2000\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.4761 - accuracy: 0.8160 - val_loss: 0.5273 - val_accuracy: 0.8212\n",
            "Epoch 381/2000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.5032 - accuracy: 0.8160 - val_loss: 0.5344 - val_accuracy: 0.8212\n",
            "Epoch 382/2000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.4962 - accuracy: 0.8132 - val_loss: 0.5466 - val_accuracy: 0.8212\n",
            "Epoch 383/2000\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.4712 - accuracy: 0.8315 - val_loss: 0.5350 - val_accuracy: 0.8268\n",
            "Epoch 384/2000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.4726 - accuracy: 0.8132 - val_loss: 0.5424 - val_accuracy: 0.8268\n",
            "Epoch 385/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.4802 - accuracy: 0.8160 - val_loss: 0.5335 - val_accuracy: 0.8156\n",
            "Epoch 386/2000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.4904 - accuracy: 0.8357 - val_loss: 0.5336 - val_accuracy: 0.8156\n",
            "Epoch 387/2000\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.4792 - accuracy: 0.8146 - val_loss: 0.5438 - val_accuracy: 0.8101\n",
            "Epoch 388/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.4809 - accuracy: 0.7992 - val_loss: 0.5330 - val_accuracy: 0.8212\n",
            "Epoch 389/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.4779 - accuracy: 0.8174 - val_loss: 0.5279 - val_accuracy: 0.8212\n",
            "Epoch 390/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.4535 - accuracy: 0.8315 - val_loss: 0.5206 - val_accuracy: 0.8212\n",
            "Epoch 391/2000\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 0.4968 - accuracy: 0.8146 - val_loss: 0.5297 - val_accuracy: 0.8268\n",
            "Epoch 392/2000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.4728 - accuracy: 0.8343 - val_loss: 0.5318 - val_accuracy: 0.8268\n",
            "Epoch 393/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.4751 - accuracy: 0.8160 - val_loss: 0.5334 - val_accuracy: 0.8212\n",
            "Epoch 394/2000\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.4940 - accuracy: 0.8160 - val_loss: 0.5379 - val_accuracy: 0.8156\n",
            "Epoch 395/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.5070 - accuracy: 0.8188 - val_loss: 0.5317 - val_accuracy: 0.8212\n",
            "Epoch 396/2000\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.4940 - accuracy: 0.8174 - val_loss: 0.5384 - val_accuracy: 0.8212\n",
            "Epoch 397/2000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.4650 - accuracy: 0.8343 - val_loss: 0.5318 - val_accuracy: 0.8156\n",
            "Epoch 398/2000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.4767 - accuracy: 0.8118 - val_loss: 0.5283 - val_accuracy: 0.8268\n",
            "Epoch 399/2000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.4874 - accuracy: 0.8258 - val_loss: 0.5349 - val_accuracy: 0.8156\n",
            "Epoch 400/2000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.4585 - accuracy: 0.8188 - val_loss: 0.5254 - val_accuracy: 0.8156\n",
            "Epoch 401/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.4978 - accuracy: 0.8118 - val_loss: 0.5391 - val_accuracy: 0.8212\n",
            "Epoch 402/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.4805 - accuracy: 0.8244 - val_loss: 0.5331 - val_accuracy: 0.8268\n",
            "Epoch 403/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.5115 - accuracy: 0.8174 - val_loss: 0.5387 - val_accuracy: 0.8268\n",
            "Epoch 404/2000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.4928 - accuracy: 0.8160 - val_loss: 0.5450 - val_accuracy: 0.8212\n",
            "Epoch 405/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.4930 - accuracy: 0.8216 - val_loss: 0.5404 - val_accuracy: 0.8268\n",
            "Epoch 406/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.4820 - accuracy: 0.8216 - val_loss: 0.5389 - val_accuracy: 0.8156\n",
            "Epoch 407/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.4928 - accuracy: 0.8160 - val_loss: 0.5372 - val_accuracy: 0.8212\n",
            "Epoch 408/2000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.5020 - accuracy: 0.8132 - val_loss: 0.5400 - val_accuracy: 0.8212\n",
            "Epoch 409/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.4938 - accuracy: 0.8146 - val_loss: 0.5383 - val_accuracy: 0.8212\n",
            "Epoch 410/2000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.5046 - accuracy: 0.8343 - val_loss: 0.5356 - val_accuracy: 0.8212\n",
            "Epoch 411/2000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.4795 - accuracy: 0.8244 - val_loss: 0.5335 - val_accuracy: 0.8156\n",
            "Epoch 412/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.4521 - accuracy: 0.8385 - val_loss: 0.5289 - val_accuracy: 0.8156\n",
            "Epoch 413/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.4968 - accuracy: 0.8076 - val_loss: 0.5462 - val_accuracy: 0.8212\n",
            "Epoch 414/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.4692 - accuracy: 0.8230 - val_loss: 0.5377 - val_accuracy: 0.8212\n",
            "Epoch 415/2000\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.4812 - accuracy: 0.8132 - val_loss: 0.5313 - val_accuracy: 0.8212\n",
            "Epoch 416/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.4854 - accuracy: 0.8244 - val_loss: 0.5452 - val_accuracy: 0.8156\n",
            "Epoch 417/2000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.4846 - accuracy: 0.8287 - val_loss: 0.5409 - val_accuracy: 0.8268\n",
            "Epoch 418/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.4792 - accuracy: 0.8287 - val_loss: 0.5513 - val_accuracy: 0.7821\n",
            "Epoch 419/2000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.4779 - accuracy: 0.8216 - val_loss: 0.5428 - val_accuracy: 0.8212\n",
            "Epoch 420/2000\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.4674 - accuracy: 0.8469 - val_loss: 0.5375 - val_accuracy: 0.8212\n",
            "Epoch 421/2000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.4539 - accuracy: 0.8329 - val_loss: 0.5319 - val_accuracy: 0.8212\n",
            "Epoch 422/2000\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.4981 - accuracy: 0.8076 - val_loss: 0.5305 - val_accuracy: 0.8268\n",
            "Epoch 423/2000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.4714 - accuracy: 0.8343 - val_loss: 0.5305 - val_accuracy: 0.8212\n",
            "Epoch 424/2000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.4566 - accuracy: 0.8146 - val_loss: 0.5329 - val_accuracy: 0.8156\n",
            "Epoch 425/2000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.5008 - accuracy: 0.8230 - val_loss: 0.5376 - val_accuracy: 0.8212\n",
            "Epoch 426/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.4963 - accuracy: 0.8230 - val_loss: 0.5438 - val_accuracy: 0.8101\n",
            "Epoch 427/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.4954 - accuracy: 0.8174 - val_loss: 0.5480 - val_accuracy: 0.8156\n",
            "Epoch 428/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.4765 - accuracy: 0.8329 - val_loss: 0.5426 - val_accuracy: 0.8156\n",
            "Epoch 429/2000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.4695 - accuracy: 0.8258 - val_loss: 0.5407 - val_accuracy: 0.8156\n",
            "Epoch 430/2000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.4778 - accuracy: 0.8272 - val_loss: 0.5410 - val_accuracy: 0.8101\n",
            "Epoch 431/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.4842 - accuracy: 0.8315 - val_loss: 0.5460 - val_accuracy: 0.8045\n",
            "Epoch 432/2000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.4933 - accuracy: 0.8188 - val_loss: 0.5433 - val_accuracy: 0.8156\n",
            "Epoch 433/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.4664 - accuracy: 0.8301 - val_loss: 0.5425 - val_accuracy: 0.7821\n",
            "Epoch 434/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.4779 - accuracy: 0.8216 - val_loss: 0.5414 - val_accuracy: 0.8156\n",
            "Epoch 435/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.4987 - accuracy: 0.8371 - val_loss: 0.5441 - val_accuracy: 0.8101\n",
            "Epoch 436/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.4607 - accuracy: 0.8244 - val_loss: 0.5456 - val_accuracy: 0.8212\n",
            "Epoch 437/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.4577 - accuracy: 0.8427 - val_loss: 0.5335 - val_accuracy: 0.8268\n",
            "Epoch 438/2000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.4638 - accuracy: 0.8076 - val_loss: 0.5298 - val_accuracy: 0.8268\n",
            "Epoch 439/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.4661 - accuracy: 0.8357 - val_loss: 0.5328 - val_accuracy: 0.8212\n",
            "Epoch 440/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.4627 - accuracy: 0.8329 - val_loss: 0.5245 - val_accuracy: 0.8212\n",
            "Epoch 441/2000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.4707 - accuracy: 0.8399 - val_loss: 0.5223 - val_accuracy: 0.8212\n",
            "Epoch 442/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.4684 - accuracy: 0.8371 - val_loss: 0.5316 - val_accuracy: 0.8212\n",
            "Epoch 443/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.4897 - accuracy: 0.8329 - val_loss: 0.5392 - val_accuracy: 0.8101\n",
            "Epoch 444/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.5103 - accuracy: 0.8272 - val_loss: 0.5501 - val_accuracy: 0.7821\n",
            "Epoch 445/2000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.4769 - accuracy: 0.8315 - val_loss: 0.5493 - val_accuracy: 0.8101\n",
            "Epoch 446/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.4648 - accuracy: 0.8188 - val_loss: 0.5450 - val_accuracy: 0.8156\n",
            "Epoch 447/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.4906 - accuracy: 0.8216 - val_loss: 0.5530 - val_accuracy: 0.7765\n",
            "Epoch 448/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.4550 - accuracy: 0.8244 - val_loss: 0.5423 - val_accuracy: 0.8156\n",
            "Epoch 449/2000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.4642 - accuracy: 0.8385 - val_loss: 0.5371 - val_accuracy: 0.8268\n",
            "Epoch 450/2000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.4695 - accuracy: 0.8301 - val_loss: 0.5415 - val_accuracy: 0.8156\n",
            "Epoch 451/2000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.4775 - accuracy: 0.8230 - val_loss: 0.5379 - val_accuracy: 0.8268\n",
            "Epoch 452/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.4865 - accuracy: 0.8202 - val_loss: 0.5499 - val_accuracy: 0.8156\n",
            "Epoch 453/2000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.4827 - accuracy: 0.8301 - val_loss: 0.5485 - val_accuracy: 0.8156\n",
            "Epoch 454/2000\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.4765 - accuracy: 0.8090 - val_loss: 0.5467 - val_accuracy: 0.8156\n",
            "Epoch 455/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.4986 - accuracy: 0.8188 - val_loss: 0.5465 - val_accuracy: 0.8156\n",
            "Epoch 456/2000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.4809 - accuracy: 0.8174 - val_loss: 0.5468 - val_accuracy: 0.8101\n",
            "Epoch 457/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.4691 - accuracy: 0.8160 - val_loss: 0.5472 - val_accuracy: 0.8212\n",
            "Epoch 458/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.4672 - accuracy: 0.8287 - val_loss: 0.5447 - val_accuracy: 0.8156\n",
            "Epoch 459/2000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.4733 - accuracy: 0.8188 - val_loss: 0.5503 - val_accuracy: 0.8156\n",
            "Epoch 460/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.4565 - accuracy: 0.8174 - val_loss: 0.5416 - val_accuracy: 0.8156\n",
            "Epoch 461/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.4366 - accuracy: 0.8455 - val_loss: 0.5314 - val_accuracy: 0.8268\n",
            "Epoch 462/2000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.4596 - accuracy: 0.8272 - val_loss: 0.5377 - val_accuracy: 0.8212\n",
            "Epoch 463/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.4593 - accuracy: 0.8343 - val_loss: 0.5291 - val_accuracy: 0.8268\n",
            "Epoch 464/2000\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.4853 - accuracy: 0.8174 - val_loss: 0.5287 - val_accuracy: 0.8212\n",
            "Epoch 465/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.4486 - accuracy: 0.8160 - val_loss: 0.5260 - val_accuracy: 0.8212\n",
            "Epoch 466/2000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.5053 - accuracy: 0.8329 - val_loss: 0.5330 - val_accuracy: 0.8268\n",
            "Epoch 467/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.4741 - accuracy: 0.8230 - val_loss: 0.5457 - val_accuracy: 0.7709\n",
            "Epoch 468/2000\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.4861 - accuracy: 0.8202 - val_loss: 0.5492 - val_accuracy: 0.7709\n",
            "Epoch 469/2000\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.4692 - accuracy: 0.8160 - val_loss: 0.5537 - val_accuracy: 0.7709\n",
            "Epoch 470/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.4558 - accuracy: 0.8244 - val_loss: 0.5439 - val_accuracy: 0.7877\n",
            "Epoch 471/2000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.4705 - accuracy: 0.8287 - val_loss: 0.5453 - val_accuracy: 0.7765\n",
            "Epoch 472/2000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.4716 - accuracy: 0.8244 - val_loss: 0.5469 - val_accuracy: 0.7821\n",
            "Epoch 473/2000\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.4689 - accuracy: 0.8244 - val_loss: 0.5404 - val_accuracy: 0.8212\n",
            "Epoch 474/2000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.4568 - accuracy: 0.8174 - val_loss: 0.5327 - val_accuracy: 0.8212\n",
            "Epoch 475/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.4571 - accuracy: 0.8258 - val_loss: 0.5269 - val_accuracy: 0.8212\n",
            "Epoch 476/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.4468 - accuracy: 0.8385 - val_loss: 0.5308 - val_accuracy: 0.8156\n",
            "Epoch 477/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.4847 - accuracy: 0.8258 - val_loss: 0.5336 - val_accuracy: 0.8212\n",
            "Epoch 478/2000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.4619 - accuracy: 0.8244 - val_loss: 0.5454 - val_accuracy: 0.7709\n",
            "Epoch 479/2000\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.4590 - accuracy: 0.8343 - val_loss: 0.5416 - val_accuracy: 0.8101\n",
            "Epoch 480/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.4812 - accuracy: 0.8202 - val_loss: 0.5346 - val_accuracy: 0.8045\n",
            "Epoch 481/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.4661 - accuracy: 0.8525 - val_loss: 0.5369 - val_accuracy: 0.7765\n",
            "Epoch 482/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.4483 - accuracy: 0.8371 - val_loss: 0.5304 - val_accuracy: 0.8101\n",
            "Epoch 483/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.4853 - accuracy: 0.8343 - val_loss: 0.5380 - val_accuracy: 0.7709\n",
            "Epoch 484/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.4593 - accuracy: 0.8329 - val_loss: 0.5398 - val_accuracy: 0.7709\n",
            "Epoch 485/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.4652 - accuracy: 0.8230 - val_loss: 0.5382 - val_accuracy: 0.7765\n",
            "Epoch 486/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.4568 - accuracy: 0.8301 - val_loss: 0.5397 - val_accuracy: 0.7765\n",
            "Epoch 487/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.4789 - accuracy: 0.8202 - val_loss: 0.5402 - val_accuracy: 0.7765\n",
            "Epoch 488/2000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.4528 - accuracy: 0.8287 - val_loss: 0.5346 - val_accuracy: 0.7765\n",
            "Epoch 489/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.4788 - accuracy: 0.8287 - val_loss: 0.5384 - val_accuracy: 0.7654\n",
            "Epoch 490/2000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.4714 - accuracy: 0.8343 - val_loss: 0.5419 - val_accuracy: 0.7709\n",
            "Epoch 491/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.4647 - accuracy: 0.8301 - val_loss: 0.5434 - val_accuracy: 0.7654\n",
            "Epoch 492/2000\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.4596 - accuracy: 0.8188 - val_loss: 0.5393 - val_accuracy: 0.7765\n",
            "Epoch 493/2000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.4557 - accuracy: 0.8385 - val_loss: 0.5383 - val_accuracy: 0.7877\n",
            "Epoch 494/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.4710 - accuracy: 0.8174 - val_loss: 0.5384 - val_accuracy: 0.8212\n",
            "Epoch 495/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.4862 - accuracy: 0.8202 - val_loss: 0.5556 - val_accuracy: 0.7709\n",
            "Epoch 496/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.4715 - accuracy: 0.8146 - val_loss: 0.5478 - val_accuracy: 0.7765\n",
            "Epoch 497/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.4767 - accuracy: 0.8315 - val_loss: 0.5460 - val_accuracy: 0.7765\n",
            "Epoch 498/2000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.4618 - accuracy: 0.8385 - val_loss: 0.5471 - val_accuracy: 0.7821\n",
            "Epoch 499/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.4334 - accuracy: 0.8413 - val_loss: 0.5376 - val_accuracy: 0.7877\n",
            "Epoch 500/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.4416 - accuracy: 0.8343 - val_loss: 0.5316 - val_accuracy: 0.8156\n",
            "Epoch 501/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.4377 - accuracy: 0.8413 - val_loss: 0.5265 - val_accuracy: 0.8156\n",
            "Epoch 502/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.4353 - accuracy: 0.8329 - val_loss: 0.5155 - val_accuracy: 0.8212\n",
            "Epoch 503/2000\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.4768 - accuracy: 0.8343 - val_loss: 0.5380 - val_accuracy: 0.7765\n",
            "Epoch 504/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.4805 - accuracy: 0.8188 - val_loss: 0.5467 - val_accuracy: 0.7765\n",
            "Epoch 505/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.4620 - accuracy: 0.8230 - val_loss: 0.5442 - val_accuracy: 0.7765\n",
            "Epoch 506/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.4558 - accuracy: 0.8188 - val_loss: 0.5456 - val_accuracy: 0.7765\n",
            "Epoch 507/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.4561 - accuracy: 0.8287 - val_loss: 0.5389 - val_accuracy: 0.7821\n",
            "Epoch 508/2000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.4522 - accuracy: 0.8343 - val_loss: 0.5406 - val_accuracy: 0.7709\n",
            "Epoch 509/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.4597 - accuracy: 0.8216 - val_loss: 0.5331 - val_accuracy: 0.7709\n",
            "Epoch 510/2000\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.4648 - accuracy: 0.8301 - val_loss: 0.5338 - val_accuracy: 0.7765\n",
            "Epoch 511/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.4520 - accuracy: 0.8399 - val_loss: 0.5338 - val_accuracy: 0.7821\n",
            "Epoch 512/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.4462 - accuracy: 0.8258 - val_loss: 0.5272 - val_accuracy: 0.8045\n",
            "Epoch 513/2000\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.4501 - accuracy: 0.8301 - val_loss: 0.5296 - val_accuracy: 0.7709\n",
            "Epoch 514/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.4650 - accuracy: 0.8202 - val_loss: 0.5498 - val_accuracy: 0.7654\n",
            "Epoch 515/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.4564 - accuracy: 0.8315 - val_loss: 0.5332 - val_accuracy: 0.7765\n",
            "Epoch 516/2000\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.4737 - accuracy: 0.8244 - val_loss: 0.5328 - val_accuracy: 0.7709\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Tunedmodel = keras.models.load_model(\"my_checkpoint.h5\")"
      ],
      "metadata": {
        "id": "nW7lcHtfRDhg"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "GeiCZXd5SgCJ",
        "outputId": "d4adce48-d653-459b-8fdf-20b5d669b326"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-22b820e9-c0e0-456e-a16e-70bf0dafb44d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Embarked</th>\n",
              "      <th>relatives</th>\n",
              "      <th>Deck</th>\n",
              "      <th>Title</th>\n",
              "      <th>Age_Class</th>\n",
              "      <th>Fare_Per_Person</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>15</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>3</td>\n",
              "      <td>18</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>12</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>8</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-22b820e9-c0e0-456e-a16e-70bf0dafb44d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-22b820e9-c0e0-456e-a16e-70bf0dafb44d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-22b820e9-c0e0-456e-a16e-70bf0dafb44d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   Pclass  Sex  Age  SibSp  ...  Deck  Title  Age_Class  Fare_Per_Person\n",
              "0       3    0    5      0  ...     8      1         15                0\n",
              "1       3    1    6      1  ...     8      3         18                0\n",
              "2       2    0    6      0  ...     8      1         12                2\n",
              "3       3    0    3      0  ...     8      1          9                1\n",
              "4       3    1    2      1  ...     8      3          6                0\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prediction = Tunedmodel.predict(test)\n",
        "\n",
        "test_label = ['Dead', 'Survived']\n",
        "test_label[np.argmax(prediction[0])]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ggt-x7wySOyC",
        "outputId": "3bf25b32-edaa-4763-fe8b-43bf74d14aa1"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Dead'"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "testlist2 = []\n",
        "\n",
        "for i in range(418):\n",
        "    print('Passenger No. {} - {} '.format(i+1, test_label[np.argmax(prediction[i])]))\n",
        "    testlist2.append(np.argmax(prediction[i]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G2NrXS8gSp-C",
        "outputId": "e28f69dd-c394-44bf-e942-92fb5e3efaf2"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Passenger No. 1 - Dead \n",
            "Passenger No. 2 - Dead \n",
            "Passenger No. 3 - Dead \n",
            "Passenger No. 4 - Dead \n",
            "Passenger No. 5 - Survived \n",
            "Passenger No. 6 - Dead \n",
            "Passenger No. 7 - Survived \n",
            "Passenger No. 8 - Dead \n",
            "Passenger No. 9 - Survived \n",
            "Passenger No. 10 - Dead \n",
            "Passenger No. 11 - Dead \n",
            "Passenger No. 12 - Dead \n",
            "Passenger No. 13 - Survived \n",
            "Passenger No. 14 - Dead \n",
            "Passenger No. 15 - Survived \n",
            "Passenger No. 16 - Survived \n",
            "Passenger No. 17 - Dead \n",
            "Passenger No. 18 - Dead \n",
            "Passenger No. 19 - Survived \n",
            "Passenger No. 20 - Dead \n",
            "Passenger No. 21 - Dead \n",
            "Passenger No. 22 - Survived \n",
            "Passenger No. 23 - Survived \n",
            "Passenger No. 24 - Dead \n",
            "Passenger No. 25 - Survived \n",
            "Passenger No. 26 - Dead \n",
            "Passenger No. 27 - Survived \n",
            "Passenger No. 28 - Dead \n",
            "Passenger No. 29 - Dead \n",
            "Passenger No. 30 - Dead \n",
            "Passenger No. 31 - Dead \n",
            "Passenger No. 32 - Dead \n",
            "Passenger No. 33 - Survived \n",
            "Passenger No. 34 - Dead \n",
            "Passenger No. 35 - Survived \n",
            "Passenger No. 36 - Dead \n",
            "Passenger No. 37 - Survived \n",
            "Passenger No. 38 - Survived \n",
            "Passenger No. 39 - Dead \n",
            "Passenger No. 40 - Survived \n",
            "Passenger No. 41 - Dead \n",
            "Passenger No. 42 - Survived \n",
            "Passenger No. 43 - Dead \n",
            "Passenger No. 44 - Survived \n",
            "Passenger No. 45 - Survived \n",
            "Passenger No. 46 - Dead \n",
            "Passenger No. 47 - Dead \n",
            "Passenger No. 48 - Dead \n",
            "Passenger No. 49 - Survived \n",
            "Passenger No. 50 - Survived \n",
            "Passenger No. 51 - Survived \n",
            "Passenger No. 52 - Dead \n",
            "Passenger No. 53 - Survived \n",
            "Passenger No. 54 - Survived \n",
            "Passenger No. 55 - Dead \n",
            "Passenger No. 56 - Dead \n",
            "Passenger No. 57 - Dead \n",
            "Passenger No. 58 - Dead \n",
            "Passenger No. 59 - Dead \n",
            "Passenger No. 60 - Survived \n",
            "Passenger No. 61 - Dead \n",
            "Passenger No. 62 - Dead \n",
            "Passenger No. 63 - Dead \n",
            "Passenger No. 64 - Survived \n",
            "Passenger No. 65 - Survived \n",
            "Passenger No. 66 - Survived \n",
            "Passenger No. 67 - Survived \n",
            "Passenger No. 68 - Dead \n",
            "Passenger No. 69 - Survived \n",
            "Passenger No. 70 - Survived \n",
            "Passenger No. 71 - Survived \n",
            "Passenger No. 72 - Dead \n",
            "Passenger No. 73 - Survived \n",
            "Passenger No. 74 - Survived \n",
            "Passenger No. 75 - Survived \n",
            "Passenger No. 76 - Survived \n",
            "Passenger No. 77 - Dead \n",
            "Passenger No. 78 - Survived \n",
            "Passenger No. 79 - Dead \n",
            "Passenger No. 80 - Survived \n",
            "Passenger No. 81 - Survived \n",
            "Passenger No. 82 - Survived \n",
            "Passenger No. 83 - Dead \n",
            "Passenger No. 84 - Dead \n",
            "Passenger No. 85 - Dead \n",
            "Passenger No. 86 - Dead \n",
            "Passenger No. 87 - Survived \n",
            "Passenger No. 88 - Survived \n",
            "Passenger No. 89 - Survived \n",
            "Passenger No. 90 - Survived \n",
            "Passenger No. 91 - Survived \n",
            "Passenger No. 92 - Dead \n",
            "Passenger No. 93 - Survived \n",
            "Passenger No. 94 - Dead \n",
            "Passenger No. 95 - Dead \n",
            "Passenger No. 96 - Dead \n",
            "Passenger No. 97 - Survived \n",
            "Passenger No. 98 - Dead \n",
            "Passenger No. 99 - Survived \n",
            "Passenger No. 100 - Dead \n",
            "Passenger No. 101 - Survived \n",
            "Passenger No. 102 - Dead \n",
            "Passenger No. 103 - Dead \n",
            "Passenger No. 104 - Dead \n",
            "Passenger No. 105 - Survived \n",
            "Passenger No. 106 - Dead \n",
            "Passenger No. 107 - Dead \n",
            "Passenger No. 108 - Dead \n",
            "Passenger No. 109 - Dead \n",
            "Passenger No. 110 - Dead \n",
            "Passenger No. 111 - Dead \n",
            "Passenger No. 112 - Survived \n",
            "Passenger No. 113 - Survived \n",
            "Passenger No. 114 - Survived \n",
            "Passenger No. 115 - Survived \n",
            "Passenger No. 116 - Dead \n",
            "Passenger No. 117 - Dead \n",
            "Passenger No. 118 - Survived \n",
            "Passenger No. 119 - Survived \n",
            "Passenger No. 120 - Survived \n",
            "Passenger No. 121 - Survived \n",
            "Passenger No. 122 - Dead \n",
            "Passenger No. 123 - Survived \n",
            "Passenger No. 124 - Dead \n",
            "Passenger No. 125 - Dead \n",
            "Passenger No. 126 - Survived \n",
            "Passenger No. 127 - Dead \n",
            "Passenger No. 128 - Survived \n",
            "Passenger No. 129 - Dead \n",
            "Passenger No. 130 - Dead \n",
            "Passenger No. 131 - Dead \n",
            "Passenger No. 132 - Survived \n",
            "Passenger No. 133 - Dead \n",
            "Passenger No. 134 - Dead \n",
            "Passenger No. 135 - Dead \n",
            "Passenger No. 136 - Dead \n",
            "Passenger No. 137 - Dead \n",
            "Passenger No. 138 - Dead \n",
            "Passenger No. 139 - Survived \n",
            "Passenger No. 140 - Dead \n",
            "Passenger No. 141 - Dead \n",
            "Passenger No. 142 - Survived \n",
            "Passenger No. 143 - Survived \n",
            "Passenger No. 144 - Dead \n",
            "Passenger No. 145 - Dead \n",
            "Passenger No. 146 - Dead \n",
            "Passenger No. 147 - Survived \n",
            "Passenger No. 148 - Dead \n",
            "Passenger No. 149 - Dead \n",
            "Passenger No. 150 - Survived \n",
            "Passenger No. 151 - Survived \n",
            "Passenger No. 152 - Dead \n",
            "Passenger No. 153 - Dead \n",
            "Passenger No. 154 - Dead \n",
            "Passenger No. 155 - Dead \n",
            "Passenger No. 156 - Dead \n",
            "Passenger No. 157 - Survived \n",
            "Passenger No. 158 - Survived \n",
            "Passenger No. 159 - Dead \n",
            "Passenger No. 160 - Survived \n",
            "Passenger No. 161 - Survived \n",
            "Passenger No. 162 - Survived \n",
            "Passenger No. 163 - Survived \n",
            "Passenger No. 164 - Dead \n",
            "Passenger No. 165 - Survived \n",
            "Passenger No. 166 - Survived \n",
            "Passenger No. 167 - Dead \n",
            "Passenger No. 168 - Dead \n",
            "Passenger No. 169 - Survived \n",
            "Passenger No. 170 - Survived \n",
            "Passenger No. 171 - Dead \n",
            "Passenger No. 172 - Dead \n",
            "Passenger No. 173 - Dead \n",
            "Passenger No. 174 - Dead \n",
            "Passenger No. 175 - Dead \n",
            "Passenger No. 176 - Survived \n",
            "Passenger No. 177 - Survived \n",
            "Passenger No. 178 - Survived \n",
            "Passenger No. 179 - Survived \n",
            "Passenger No. 180 - Survived \n",
            "Passenger No. 181 - Dead \n",
            "Passenger No. 182 - Survived \n",
            "Passenger No. 183 - Survived \n",
            "Passenger No. 184 - Dead \n",
            "Passenger No. 185 - Survived \n",
            "Passenger No. 186 - Dead \n",
            "Passenger No. 187 - Survived \n",
            "Passenger No. 188 - Dead \n",
            "Passenger No. 189 - Dead \n",
            "Passenger No. 190 - Dead \n",
            "Passenger No. 191 - Dead \n",
            "Passenger No. 192 - Dead \n",
            "Passenger No. 193 - Survived \n",
            "Passenger No. 194 - Dead \n",
            "Passenger No. 195 - Survived \n",
            "Passenger No. 196 - Dead \n",
            "Passenger No. 197 - Survived \n",
            "Passenger No. 198 - Survived \n",
            "Passenger No. 199 - Dead \n",
            "Passenger No. 200 - Survived \n",
            "Passenger No. 201 - Survived \n",
            "Passenger No. 202 - Survived \n",
            "Passenger No. 203 - Survived \n",
            "Passenger No. 204 - Survived \n",
            "Passenger No. 205 - Dead \n",
            "Passenger No. 206 - Dead \n",
            "Passenger No. 207 - Dead \n",
            "Passenger No. 208 - Dead \n",
            "Passenger No. 209 - Survived \n",
            "Passenger No. 210 - Dead \n",
            "Passenger No. 211 - Dead \n",
            "Passenger No. 212 - Dead \n",
            "Passenger No. 213 - Dead \n",
            "Passenger No. 214 - Survived \n",
            "Passenger No. 215 - Dead \n",
            "Passenger No. 216 - Dead \n",
            "Passenger No. 217 - Survived \n",
            "Passenger No. 218 - Dead \n",
            "Passenger No. 219 - Survived \n",
            "Passenger No. 220 - Dead \n",
            "Passenger No. 221 - Survived \n",
            "Passenger No. 222 - Dead \n",
            "Passenger No. 223 - Survived \n",
            "Passenger No. 224 - Dead \n",
            "Passenger No. 225 - Survived \n",
            "Passenger No. 226 - Survived \n",
            "Passenger No. 227 - Dead \n",
            "Passenger No. 228 - Survived \n",
            "Passenger No. 229 - Dead \n",
            "Passenger No. 230 - Dead \n",
            "Passenger No. 231 - Dead \n",
            "Passenger No. 232 - Survived \n",
            "Passenger No. 233 - Dead \n",
            "Passenger No. 234 - Dead \n",
            "Passenger No. 235 - Survived \n",
            "Passenger No. 236 - Dead \n",
            "Passenger No. 237 - Survived \n",
            "Passenger No. 238 - Dead \n",
            "Passenger No. 239 - Survived \n",
            "Passenger No. 240 - Survived \n",
            "Passenger No. 241 - Survived \n",
            "Passenger No. 242 - Survived \n",
            "Passenger No. 243 - Dead \n",
            "Passenger No. 244 - Dead \n",
            "Passenger No. 245 - Dead \n",
            "Passenger No. 246 - Survived \n",
            "Passenger No. 247 - Survived \n",
            "Passenger No. 248 - Dead \n",
            "Passenger No. 249 - Survived \n",
            "Passenger No. 250 - Survived \n",
            "Passenger No. 251 - Survived \n",
            "Passenger No. 252 - Dead \n",
            "Passenger No. 253 - Survived \n",
            "Passenger No. 254 - Dead \n",
            "Passenger No. 255 - Dead \n",
            "Passenger No. 256 - Dead \n",
            "Passenger No. 257 - Dead \n",
            "Passenger No. 258 - Dead \n",
            "Passenger No. 259 - Survived \n",
            "Passenger No. 260 - Dead \n",
            "Passenger No. 261 - Dead \n",
            "Passenger No. 262 - Dead \n",
            "Passenger No. 263 - Survived \n",
            "Passenger No. 264 - Survived \n",
            "Passenger No. 265 - Dead \n",
            "Passenger No. 266 - Dead \n",
            "Passenger No. 267 - Dead \n",
            "Passenger No. 268 - Dead \n",
            "Passenger No. 269 - Survived \n",
            "Passenger No. 270 - Dead \n",
            "Passenger No. 271 - Survived \n",
            "Passenger No. 272 - Dead \n",
            "Passenger No. 273 - Survived \n",
            "Passenger No. 274 - Survived \n",
            "Passenger No. 275 - Dead \n",
            "Passenger No. 276 - Survived \n",
            "Passenger No. 277 - Dead \n",
            "Passenger No. 278 - Dead \n",
            "Passenger No. 279 - Dead \n",
            "Passenger No. 280 - Dead \n",
            "Passenger No. 281 - Survived \n",
            "Passenger No. 282 - Survived \n",
            "Passenger No. 283 - Survived \n",
            "Passenger No. 284 - Survived \n",
            "Passenger No. 285 - Survived \n",
            "Passenger No. 286 - Dead \n",
            "Passenger No. 287 - Dead \n",
            "Passenger No. 288 - Survived \n",
            "Passenger No. 289 - Dead \n",
            "Passenger No. 290 - Dead \n",
            "Passenger No. 291 - Dead \n",
            "Passenger No. 292 - Survived \n",
            "Passenger No. 293 - Dead \n",
            "Passenger No. 294 - Survived \n",
            "Passenger No. 295 - Dead \n",
            "Passenger No. 296 - Dead \n",
            "Passenger No. 297 - Survived \n",
            "Passenger No. 298 - Dead \n",
            "Passenger No. 299 - Dead \n",
            "Passenger No. 300 - Dead \n",
            "Passenger No. 301 - Dead \n",
            "Passenger No. 302 - Survived \n",
            "Passenger No. 303 - Dead \n",
            "Passenger No. 304 - Dead \n",
            "Passenger No. 305 - Survived \n",
            "Passenger No. 306 - Survived \n",
            "Passenger No. 307 - Survived \n",
            "Passenger No. 308 - Survived \n",
            "Passenger No. 309 - Dead \n",
            "Passenger No. 310 - Dead \n",
            "Passenger No. 311 - Dead \n",
            "Passenger No. 312 - Dead \n",
            "Passenger No. 313 - Dead \n",
            "Passenger No. 314 - Dead \n",
            "Passenger No. 315 - Survived \n",
            "Passenger No. 316 - Survived \n",
            "Passenger No. 317 - Survived \n",
            "Passenger No. 318 - Dead \n",
            "Passenger No. 319 - Dead \n",
            "Passenger No. 320 - Dead \n",
            "Passenger No. 321 - Dead \n",
            "Passenger No. 322 - Dead \n",
            "Passenger No. 323 - Dead \n",
            "Passenger No. 324 - Dead \n",
            "Passenger No. 325 - Survived \n",
            "Passenger No. 326 - Dead \n",
            "Passenger No. 327 - Survived \n",
            "Passenger No. 328 - Dead \n",
            "Passenger No. 329 - Dead \n",
            "Passenger No. 330 - Dead \n",
            "Passenger No. 331 - Survived \n",
            "Passenger No. 332 - Dead \n",
            "Passenger No. 333 - Dead \n",
            "Passenger No. 334 - Survived \n",
            "Passenger No. 335 - Dead \n",
            "Passenger No. 336 - Survived \n",
            "Passenger No. 337 - Dead \n",
            "Passenger No. 338 - Dead \n",
            "Passenger No. 339 - Dead \n",
            "Passenger No. 340 - Survived \n",
            "Passenger No. 341 - Dead \n",
            "Passenger No. 342 - Dead \n",
            "Passenger No. 343 - Dead \n",
            "Passenger No. 344 - Survived \n",
            "Passenger No. 345 - Survived \n",
            "Passenger No. 346 - Survived \n",
            "Passenger No. 347 - Dead \n",
            "Passenger No. 348 - Survived \n",
            "Passenger No. 349 - Dead \n",
            "Passenger No. 350 - Survived \n",
            "Passenger No. 351 - Survived \n",
            "Passenger No. 352 - Dead \n",
            "Passenger No. 353 - Dead \n",
            "Passenger No. 354 - Dead \n",
            "Passenger No. 355 - Survived \n",
            "Passenger No. 356 - Dead \n",
            "Passenger No. 357 - Survived \n",
            "Passenger No. 358 - Dead \n",
            "Passenger No. 359 - Dead \n",
            "Passenger No. 360 - Survived \n",
            "Passenger No. 361 - Dead \n",
            "Passenger No. 362 - Survived \n",
            "Passenger No. 363 - Survived \n",
            "Passenger No. 364 - Dead \n",
            "Passenger No. 365 - Survived \n",
            "Passenger No. 366 - Dead \n",
            "Passenger No. 367 - Dead \n",
            "Passenger No. 368 - Survived \n",
            "Passenger No. 369 - Survived \n",
            "Passenger No. 370 - Dead \n",
            "Passenger No. 371 - Dead \n",
            "Passenger No. 372 - Survived \n",
            "Passenger No. 373 - Dead \n",
            "Passenger No. 374 - Dead \n",
            "Passenger No. 375 - Survived \n",
            "Passenger No. 376 - Survived \n",
            "Passenger No. 377 - Survived \n",
            "Passenger No. 378 - Dead \n",
            "Passenger No. 379 - Dead \n",
            "Passenger No. 380 - Dead \n",
            "Passenger No. 381 - Dead \n",
            "Passenger No. 382 - Dead \n",
            "Passenger No. 383 - Survived \n",
            "Passenger No. 384 - Survived \n",
            "Passenger No. 385 - Dead \n",
            "Passenger No. 386 - Survived \n",
            "Passenger No. 387 - Dead \n",
            "Passenger No. 388 - Dead \n",
            "Passenger No. 389 - Dead \n",
            "Passenger No. 390 - Dead \n",
            "Passenger No. 391 - Survived \n",
            "Passenger No. 392 - Survived \n",
            "Passenger No. 393 - Survived \n",
            "Passenger No. 394 - Dead \n",
            "Passenger No. 395 - Dead \n",
            "Passenger No. 396 - Survived \n",
            "Passenger No. 397 - Dead \n",
            "Passenger No. 398 - Survived \n",
            "Passenger No. 399 - Dead \n",
            "Passenger No. 400 - Dead \n",
            "Passenger No. 401 - Survived \n",
            "Passenger No. 402 - Dead \n",
            "Passenger No. 403 - Survived \n",
            "Passenger No. 404 - Dead \n",
            "Passenger No. 405 - Survived \n",
            "Passenger No. 406 - Survived \n",
            "Passenger No. 407 - Dead \n",
            "Passenger No. 408 - Survived \n",
            "Passenger No. 409 - Survived \n",
            "Passenger No. 410 - Survived \n",
            "Passenger No. 411 - Survived \n",
            "Passenger No. 412 - Survived \n",
            "Passenger No. 413 - Survived \n",
            "Passenger No. 414 - Dead \n",
            "Passenger No. 415 - Survived \n",
            "Passenger No. 416 - Dead \n",
            "Passenger No. 417 - Dead \n",
            "Passenger No. 418 - Survived \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "testlist2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wu-ziMJNS6ht",
        "outputId": "4e83fd26-0203-43d7-99df-1a71a753f19b"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1]"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output = pd.DataFrame({'PassengerID': test_df['PassengerId'].values.tolist(), 'Survived': testlist2})\n",
        "output.to_csv('submission_TunedDense.csv', index = False)"
      ],
      "metadata": {
        "id": "DxLQR50AS8aQ"
      },
      "execution_count": 95,
      "outputs": []
    }
  ]
}